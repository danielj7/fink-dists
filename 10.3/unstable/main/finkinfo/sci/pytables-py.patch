--- pytables-0.9/tables/EArray.py 2004-10-05 14:30:31.000000000 +0200
+++ pytables-0.9/tables/EArray.py 2004-11-10 11:08:22.000000000 +0100
@@ -206,25 +206,16 @@
         The logic to do that is based purely in experiments playing
         with different buffer sizes, chunksize and compression
         flag. It is obvious that using big buffers optimize the I/O
-        speed when dealing with tables. This might (should) be further
-        optimized doing more experiments.
+        speed. This might (should) be further optimized doing more
+        experiments.
 
         """
 
         rowsize = atom.atomsize()
-        #bufmultfactor = int(1000 * 1.0)  # Optimum for Sorted objects
-        # An 1.0 factor makes the lookup in sorted arrays to
-        # decompress less, but, in exchange, the indexed dataset is
-        # almost 5 times larger than with a 10.0 factor.
-        # However, as the indexed arrays can be quite uncompressible
-        # the size of the compressed sorted list is negligible when compared
-        # against it.
-        # The improvement in time (overall) is reduced (~5%)
-        #bufmultfactor = int(1000 * 10.0) # Optimum for Index objects
-        #bufmultfactor = int(1000 * 2) # Is a good choice too,
-        # specially for very large tables and large available memory
-        #bufmultfactor = int(1000 * 1) # Optimum for sorted object
-        bufmultfactor = int(1000 * 1) # Optimum for sorted object
+        #bufmultfactor = int(1000 * 10) # Conservative value
+        bufmultfactor = int(1000 * 20)  # Medium value
+        #bufmultfactor = int(1000 * 50) # Aggresive value
+        #bufmultfactor = int(1000 * 100) # Very Aggresive value
         
         rowsizeinfile = rowsize
         expectedfsizeinKb = (expectedrows * rowsizeinfile) / 1024
@@ -235,40 +226,44 @@
         elif (expectedfsizeinKb > 100 and
             expectedfsizeinKb <= 1000):
             # Values for files less than 1 MB of size
-            buffersize = 20 * bufmultfactor
+            buffersize = 10 * bufmultfactor
         elif (expectedfsizeinKb > 1000 and
               expectedfsizeinKb <= 20 * 1000):
             # Values for sizes between 1 MB and 20 MB
-            buffersize = 40  * bufmultfactor
+            buffersize = 20  * bufmultfactor
         elif (expectedfsizeinKb > 20 * 1000 and
               expectedfsizeinKb <= 200 * 1000):
             # Values for sizes between 20 MB and 200 MB
+            buffersize = 40 * bufmultfactor
+        elif (expectedfsizeinKb > 200 * 1000 and
+              expectedfsizeinKb <= 2000 * 1000):
+            # Values for sizes between 200 MB and 2 GB
             buffersize = 50 * bufmultfactor
-        else:  # Greater than 200 MB
+        else:  # Greater than 2 GB
             buffersize = 60 * bufmultfactor
 
         # Max Tuples to fill the buffer
         maxTuples = buffersize // rowsize
         chunksizes = list(atom.shape)
-        # Check if at least 10 tuples fits in buffer
-        if maxTuples > 10:
+        # Check if at least 1 tuple fits in buffer
+        if maxTuples > 1:
             # Yes. So the chunk sizes for the non-extendeable dims will be
             # unchanged
-            chunksizes[extdim] = maxTuples // 10
+            chunksizes[extdim] = maxTuples
         else:
             # No. reduce other dimensions until we get a proper chunksizes
             # shape
-            chunksizes[extdim] = 1  # Only one row in extendeable dimension
+            chunksizes[extdim] = 1  # Only one row in extendeable dim
             for j in range(len(chunksizes)):
                 newrowsize = atom.itemsize
                 for i in chunksizes[j+1:]:
                     newrowsize *= i
                 maxTuples = buffersize // newrowsize
-                if maxTuples > 10:
+                if maxTuples > 1:
                     break
                 chunksizes[j] = 1
             # Compute the chunksizes correctly for this j index
-            chunksize = maxTuples // 10
+            chunksize = maxTuples
             if j < len(chunksizes):
                 # Only modify chunksizes[j] if needed
                 if chunksize < chunksizes[j]:
 
     def _open(self):
         """Get the metadata info for an array in file."""
