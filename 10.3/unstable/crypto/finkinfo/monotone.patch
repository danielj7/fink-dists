diff -ru monotone-0.15/ChangeLog monotone-0.15-patched/ChangeLog
--- monotone-0.15/ChangeLog	Mon Nov  8 21:42:13 2004
+++ monotone-0.15-patched/ChangeLog	Tue Dec  7 20:32:51 2004
@@ -1,3 +1,87 @@
+2004-11-17  Nathaniel Smith  <njs@codesourcery.com>
+
+	* netsync.cc (request_fwd_revisions): Rename 'first_attached_edge'
+	to 'an_attached_edge', because it does not represent the first
+	attached edge.  Likewise for 'first_attached_cset'.
+	(analyze_attachment): Remove early exit from loop; we want to
+	analyze the entire graph, not just some linear subgraphs.
+
+	* revision.cc (ensure_parents_loaded): Filter out the null
+	revision when calculating parents.
+	* change_set.hh (null_id): Define for 'revision_id's.
+
+	* tests/t_merge2_add.at: New test.
+	* tests/t_merge2_data.at: New test.
+	* tests/t_related_merge2_data.at: New test.
+	* tests/t_merge_add.at: New test.
+	* tests/t_netsync_pubkey.at: New test.
+	* tests/t_netsync_repeated.at: New test.
+	* tests/t_netsync_unrelated.at: New test.
+
+
+	* testsuite.at: Add new tests.
+	(NETSYNC_SETUP): New macro.
+	(MONOTONE2): New macro.
+	(RUN_NETSYNC): New macro.
+	(ADD_FILE): New macro.
+	(SET_FILE): New macro.
+	(COMMIT): New macro.
+	* tests/t_netsync.at: Use them.
+
+	* tests/t_singlenetsync.at: Add 'netsync' keyword'.  Rename to...
+	* tests/t_netsync_single.at: ...this.
+
+	* tests/t_heads_discontinuous_branch.at: XFAIL it.
+
+2004-11-17  Nathaniel Smith  <njs@codesourcery.com>
+
+	* netsync.cc: Remove hard tabs.
+
+2004-11-17  Nathaniel Smith  <njs@codesourcery.com>
+
+	* revision.cc: Remove hard tabs.
+	* change_set.hh: Likewise.
+
+2004-11-16  Nathaniel Smith  <njs@codesourcery.com>
+
+	* tests/t_heads.at: Replace last tricky case with a less tricky case.
+	* tests/t_heads_discontinuous_branch.at: New test for the really
+	tricky case.
+	* testsuite.at: Run it.
+
+2004-11-16  Nathaniel Smith  <njs@codesourcery.com>
+
+	* views.sql (trusted_parents_in_branch): Remove.
+	(trusted_children_in_branch): Remove.
+	(trusted_branch_members): New view.
+	(trusted_branch_parents): New view.
+	(branch_heads): Use the new views, not the removed ones.
+	
+	* database.cc (get_heads): Column name in 'branch_heads'
+	unavoidably changed from 'id' to 'parent'; adjust SELECT statement
+	to use new name.
+
+2004-11-16  Nathaniel Smith  <njs@codesourcery.com>
+
+	* database.cc: Remove hard tabs.
+
+2004-11-16  Nathaniel Smith  <njs@codesourcery.com>
+
+	* commands.cc (dump_diffs): Fetch delta destination, not source,
+	on new files.
+
+2004-11-13  Nathaniel Smith  <njs@codesourcery.com>
+
+	* tests/t_heads.at: New test.
+	* testsuite.at: Add it.
+	
+2004-11-13  Nathaniel Smith  <njs@codesourcery.com>
+
+	* monotone.texi: Fix various typos.
+	(Committing Work): Add missing command line argument.
+	(Branch Names): New section.
+	Add me to the copyright block.
+
 2004-11-08  graydon hoare  <graydon@pobox.com>
 
 	* monotone.texi: Some minor cleanups.
@@ -50,6 +134,16 @@
 
 	* figures/*: New figures.
 	* monotone.texi: Rewrite much of the tutorial.
+
+2004-10-30  Nathaniel Smith  <njs@codesourcery.com>
+
+	* netsync.cc (process_hello_cmd): Make clear that when the
+	server's key is unknown, we abort the connection.
+
+2004-10-29  Nathaniel Smith  <njs@codesourcery.com>
+
+	* sanity.cc (dump_buffer): Wrap bare string in call to string(),
+	to disambiguate conversions (required by Boost 1.30).
 
 2004-10-26  graydon hoare  <graydon@pobox.com>
 
diff -ru monotone-0.15/change_set.cc monotone-0.15-patched/change_set.cc
--- monotone-0.15/change_set.cc	Sun Oct 31 21:46:13 2004
+++ monotone-0.15-patched/change_set.cc	Tue Dec  7 20:22:54 2004
@@ -1464,9 +1464,9 @@
 			path_analysis & b_renumbered,
 			path_analysis & a_merged,
 			path_analysis & b_merged,
+                        tid_source &ts,
 			app_state & app)
 {
-  tid_source ts;
 
   // we have anc->a and anc->b and we want to construct a->merged and
   // b->merged, leading to the eventual identity concatenate(a,a_merged) ==
@@ -1500,7 +1500,7 @@
   {
     directory_map a_second_map, b_second_map;
     build_directory_map(a_tmp.second, a_second_map);
-    build_directory_map(a_tmp.second, b_second_map);
+    build_directory_map(b_tmp.second, b_second_map);
     ensure_entries_exist(a_tmp.first, a_second_map, a_tmp.second, ts);
     ensure_entries_exist(b_tmp.first, b_second_map, b_tmp.second, ts);
   }
@@ -1721,7 +1721,7 @@
   merge_disjoint_analyses(a_analysis, b_analysis,
 			  a_renumbered, b_renumbered,
 			  a_merged_analysis, b_merged_analysis, 
-			  app);
+			  ts,app);
 
   compose_rearrangement(a_merged_analysis, 
 			a_merged.rearrangement);
diff -ru monotone-0.15/change_set.hh monotone-0.15-patched/change_set.hh
--- monotone-0.15/change_set.hh	Thu Oct 28 12:25:37 2004
+++ monotone-0.15-patched/change_set.hh	Tue Dec  7 20:32:51 2004
@@ -73,8 +73,8 @@
   void add_file(file_path const & a);
   void add_file(file_path const & a, file_id const & ident);
   void apply_delta(file_path const & path, 
-		   file_id const & src, 
-		   file_id const & dst);
+                   file_id const & src, 
+                   file_id const & dst);
   void delete_file(file_path const & d);
   void delete_dir(file_path const & d);
   void rename_file(file_path const & a, file_path const & b);
@@ -93,6 +93,12 @@
   return i.inner()().empty();
 }
 
+inline bool 
+null_id(revision_id const & i)
+{
+  return i.inner()().empty();
+}
+
 inline file_path const & 
 delta_entry_path(change_set::delta_map::const_iterator i)
 {
@@ -113,7 +119,7 @@
 
 void
 apply_rearrangement_to_filesystem(change_set::path_rearrangement const & re,
-				  local_path const & temporary_root);
+                                  local_path const & temporary_root);
 
 
 // merging and concatenating 
@@ -123,70 +129,70 @@
 
 void
 concatenate_change_sets(change_set const & a,
-			change_set const & b,
-			change_set & concatenated);
+                        change_set const & b,
+                        change_set & concatenated);
 
 struct merge_provider;
 
 void
 merge_change_sets(change_set const & a,
-		  change_set const & b,
-		  change_set & a_merged,
-		  change_set & b_merged,
-		  merge_provider & merger,
-		  app_state & app);
+                  change_set const & b,
+                  change_set & a_merged,
+                  change_set & b_merged,
+                  merge_provider & merger,
+                  app_state & app);
 
 // value-oriented access to printers and parsers
 
 void
 read_path_rearrangement(data const & dat,
-			change_set::path_rearrangement & re);
+                        change_set::path_rearrangement & re);
 
 void
 write_path_rearrangement(change_set::path_rearrangement const & re,
-			 data & dat);
+                         data & dat);
 
 void
 read_change_set(data const & dat,
-		change_set & cs);
+                change_set & cs);
 
 void
 write_change_set(change_set const & cs,
-		 data & dat);
+                 data & dat);
 
 void
 apply_path_rearrangement(path_set const & old_ps,
-			 change_set::path_rearrangement const & pr,
-			 path_set & new_ps);
+                         change_set::path_rearrangement const & pr,
+                         path_set & new_ps);
 
 void
 apply_path_rearrangement(manifest_map const & old_m,
-			 change_set::path_rearrangement const & pr,
-			 manifest_map & old_m_rearranged);
+                         change_set::path_rearrangement const & pr,
+                         manifest_map & old_m_rearranged);
 
 void
 build_pure_addition_change_set(manifest_map const & man,
-			       change_set & cs);
+                               change_set & cs);
 
 void
 apply_change_set(manifest_map const & old_man,
-		 change_set const & cs,
-		 manifest_map & new_man);
+                 change_set const & cs,
+                 manifest_map & new_man);
 
 // utility for log walker
 file_path
 apply_change_set_inverse(change_set const & cs,
-			 file_path const & file_in_second);
+                         file_path const & file_in_second);
 
 // quick, optimistic and destructive version for rcs importer
 void
 apply_change_set(change_set const & cs,
-		 manifest_map & man);
+                 manifest_map & man);
 
 void 
 invert_change_set(change_set const & a2b,
-		  manifest_map const & a_map,
-		  change_set & b2a);
+                  manifest_map const & a_map,
+                  change_set & b2a);
 
 
 // basic_io access to printers and parsers
@@ -195,18 +201,18 @@
 
 void 
 print_change_set(basic_io::printer & printer,
-		 change_set const & cs);
+                 change_set const & cs);
 
 void 
 parse_change_set(basic_io::parser & parser,
-		 change_set & cs);
+                 change_set & cs);
 
 void 
 print_path_rearrangement(basic_io::printer & basic_printer,
-			 change_set::path_rearrangement const & pr);
+                         change_set::path_rearrangement const & pr);
 
 void 
 parse_path_rearrangement(basic_io::parser & pa,
-			 change_set::path_rearrangement & pr);
+                         change_set::path_rearrangement & pr);
 
 #endif // __CHANGE_SET_HH__
diff -ru monotone-0.15/commands.cc monotone-0.15-patched/commands.cc
--- monotone-0.15/commands.cc	Sun Oct 31 21:53:19 2004
+++ monotone-0.15-patched/commands.cc	Tue Dec  7 20:32:51 2004
@@ -1948,7 +1948,7 @@
 	  if (new_is_archived)
 	    {
 	      file_data dat;
-	      app.db.get_file_version(delta_entry_src(i), dat);
+	      app.db.get_file_version(delta_entry_dst(i), dat);
 	      unpack(dat.inner(), unpacked);
 	    }
 	  else
diff -ru monotone-0.15/database.cc monotone-0.15-patched/database.cc
--- monotone-0.15/database.cc	Sun Oct 17 00:49:45 2004
+++ monotone-0.15-patched/database.cc	Tue Dec  7 20:32:51 2004
@@ -106,22 +106,22 @@
   if (! __sql)
     {
       if (! init)
-	{
-	  if (filename.string() == "")
-	    throw informative_failure(string("no database specified"));
-	  else if (! fs::exists(filename))
-	    throw informative_failure(string("database ") + filename.string() +
-				      string(" does not exist"));
-	}
+        {
+          if (filename.string() == "")
+            throw informative_failure(string("no database specified"));
+          else if (! fs::exists(filename))
+            throw informative_failure(string("database ") + filename.string() +
+                                      string(" does not exist"));
+        }
       N(filename.string() != "",
-	F("need database name"));
+        F("need database name"));
       char * errmsg = NULL;
       __sql = sqlite_open(filename.string().c_str(), 0755, &errmsg);
       if (! __sql)
-	throw oops(string("could not open database: ") + filename.string() + 
-		   (errmsg ? (": " + string(errmsg)) : ""));
+        throw oops(string("could not open database: ") + filename.string() + 
+                   (errmsg ? (": " + string(errmsg)) : ""));
       if (init)
-	execute(schema_constant);
+        execute(schema_constant);
 
       check_schema();
       install_functions(__app);
@@ -170,22 +170,22 @@
   for (int i = 0; i < n; ++i)
     {
       if (i != 0)
-	*(dump->out) << ',';
+        *(dump->out) << ',';
 
       if (vals[i] == NULL)
-	*(dump->out) << "NULL";
+        *(dump->out) << "NULL";
       else
-	{
-	  *(dump->out) << "'";
-	  for (char *cp = vals[i]; *cp; ++cp)
-	    {
-	      if (*cp == '\'')
-		*(dump->out) << "''";
-	      else
-		*(dump->out) << *cp;
-	    }
-	  *(dump->out) << "'";
-	}
+        {
+          *(dump->out) << "'";
+          for (char *cp = vals[i]; *cp; ++cp)
+            {
+              if (*cp == '\'')
+                *(dump->out) << "''";
+              else
+                *(dump->out) << *cp;
+            }
+          *(dump->out) << "'";
+        }
     }
   *(dump->out) << ");\n";  
   return 0;
@@ -207,7 +207,7 @@
       *(dump->out) << vals[2] << ";\n";
       dump->table_name = string(vals[0]);
       sqlite_exec_printf(dump->sql, "SELECT * FROM '%q'", 
-			 dump_row_cb, data, NULL, vals[0]);
+                         dump_row_cb, data, NULL, vals[0]);
     }
   return 0;
 }
@@ -220,10 +220,10 @@
   req.sql = sql();
   out << "BEGIN TRANSACTION;\n";
   int res = sqlite_exec(req.sql,
-			"SELECT name, type, sql FROM sqlite_master "
-			"WHERE type='table' AND sql NOT NULL "
-			"ORDER BY substr(type,2,1), name",
-			dump_table_cb, &req, NULL);
+                        "SELECT name, type, sql FROM sqlite_master "
+                        "WHERE type='table' AND sql NOT NULL "
+                        "ORDER BY substr(type,2,1), name",
+                        dump_table_cb, &req, NULL);
   I(res == SQLITE_OK);
   out << "COMMIT;\n";
 }
@@ -240,7 +240,7 @@
   __sql = sqlite_open(filename.string().c_str(), 0755, &errmsg);
   if (! __sql)
     throw oops(string("could not open database: ") + filename.string() + 
-	       (errmsg ? (": " + string(errmsg)) : ""));
+               (errmsg ? (": " + string(errmsg)) : ""));
   
   while(in)
     {
@@ -261,11 +261,11 @@
   for (size_t i = 0; i < res.size(); ++i)
     {
       for (size_t j = 0; j < res[i].size(); ++j)
-	{
-	  if (j != 0)
-	    out << " | ";
-	  out << res[i][j];
-	}
+        {
+          if (j != 0)
+            out << " | ";
+          out << res[i][j];
+        }
       out << endl;
     }
 }
@@ -307,7 +307,7 @@
   __sql = sqlite_open(filename.string().c_str(), 0755, &errmsg);
   if (! __sql)
     throw oops(string("could not open database: ") + filename.string() + 
-	       (errmsg ? (": " + string(errmsg)) : ""));
+               (errmsg ? (": " + string(errmsg)) : ""));
   migrate_monotone_schema(__sql);
   sqlite_close(__sql);
 }
@@ -326,14 +326,14 @@
     results res;
     vector<cert> certs;
     fetch(res, 5, any_rows, 
-	  "SELECT id, name, value, keypair, signature "
-	  "FROM manifest_certs");
+          "SELECT id, name, value, keypair, signature "
+          "FROM manifest_certs");
     results_to_certs(res, certs);
     execute("DELETE FROM manifest_certs");
     for(vector<cert>::const_iterator i = certs.begin(); i != certs.end(); ++i)
       {
-	put_cert(*i, "manifest_certs");
-	++mcerts;
+        put_cert(*i, "manifest_certs");
+        ++mcerts;
       }
   }
 
@@ -342,14 +342,14 @@
     results res;
     vector<cert> certs;    
     fetch(res, 5, any_rows, 
-	  "SELECT id, name, value, keypair, signature "
-	  "FROM file_certs");
+          "SELECT id, name, value, keypair, signature "
+          "FROM file_certs");
     results_to_certs(res, certs);
     execute("DELETE FROM file_certs");
     for(vector<cert>::const_iterator i = certs.begin(); i != certs.end(); ++i)
       {
-	put_cert(*i, "file_certs");
-	++fcerts;
+        put_cert(*i, "file_certs");
+        ++fcerts;
       }
   }
   
@@ -361,11 +361,11 @@
     execute("DELETE FROM public_keys");
     for (size_t i = 0; i < res.size(); ++i)
       {
-	hexenc<id> tmp;
-	key_hash_code(rsa_keypair_id(res[i][0]), base64<rsa_pub_key>(res[i][1]), tmp);
-	execute("INSERT INTO public_keys VALUES('%q', '%q', '%q')", 
-		tmp().c_str(), res[i][0].c_str(), res[i][1].c_str());
-	++pubkeys;
+        hexenc<id> tmp;
+        key_hash_code(rsa_keypair_id(res[i][0]), base64<rsa_pub_key>(res[i][1]), tmp);
+        execute("INSERT INTO public_keys VALUES('%q', '%q', '%q')", 
+                tmp().c_str(), res[i][0].c_str(), res[i][1].c_str());
+        ++pubkeys;
       }
   }
 
@@ -376,11 +376,11 @@
     execute("DELETE FROM private_keys");
     for (size_t i = 0; i < res.size(); ++i)
       {
-	hexenc<id> tmp;
-	key_hash_code(rsa_keypair_id(res[i][0]), base64< arc4<rsa_priv_key> >(res[i][1]), tmp);
-	execute("INSERT INTO private_keys VALUES('%q', '%q', '%q')", 
-		tmp().c_str(), res[i][0].c_str(), res[i][1].c_str());
-	++privkeys;
+        hexenc<id> tmp;
+        key_hash_code(rsa_keypair_id(res[i][0]), base64< arc4<rsa_priv_key> >(res[i][1]), tmp);
+        execute("INSERT INTO private_keys VALUES('%q', '%q', '%q')", 
+                tmp().c_str(), res[i][0].c_str(), res[i][1].c_str());
+        ++privkeys;
       }
   }
 
@@ -535,9 +535,9 @@
 
 void 
 database::fetch(results & res, 
-		int const want_cols, 
-		int const want_rows, 
-		char const * query, ...)
+                int const want_cols, 
+                int const want_rows, 
+                char const * query, ...)
 {
   char ** result = NULL;
   int nrow;
@@ -583,12 +583,12 @@
   if (want_cols != any_cols &&
       ncol != want_cols)
     throw oops((F("%s wanted %d columns, got %s")
-		% ctx % want_cols % ncol).str());
+                % ctx % want_cols % ncol).str());
 
   if (want_rows != any_rows &&
       nrow != want_rows)
     throw oops((F("%s wanted %d rows, got %s")
-		% ctx % want_rows % nrow).str());
+                % ctx % want_rows % nrow).str());
 
   if (!result)
     throw oops(ctx + "null result set");
@@ -601,13 +601,13 @@
     {
       vector<string> rowvec;
       for (int col = 0; col < ncol; ++col)
-	{
-	  int i = ((1 + row) * ncol) + col;
-	  if (!result[i])
-	    throw oops(ctx + "null result value");
-	  else
-	    rowvec.push_back(result[i]);
-	}
+        {
+          int i = ((1 + row) * ncol) + col;
+          if (!result[i])
+            throw oops(ctx + "null result value");
+          else
+            rowvec.push_back(result[i]);
+        }
       res.push_back(rowvec);
     }
 }
@@ -651,12 +651,12 @@
 
 bool 
 database::exists(hexenc<id> const & ident,
-		      string const & table)
+                      string const & table)
 {
   results res;
   fetch(res, one_col, any_rows, 
-	"SELECT id FROM '%q' WHERE id = '%q'",
-	table.c_str(), ident().c_str());
+        "SELECT id FROM '%q' WHERE id = '%q'",
+        table.c_str(), ident().c_str());
   I((res.size() == 1) || (res.size() == 0));
   return res.size() == 1;
 }
@@ -664,24 +664,24 @@
 
 bool 
 database::delta_exists(hexenc<id> const & ident,
-		       string const & table)
+                       string const & table)
 {
   results res;
   fetch(res, one_col, any_rows, 
-	"SELECT id FROM '%q' WHERE id = '%q'",
-	table.c_str(), ident().c_str());
+        "SELECT id FROM '%q' WHERE id = '%q'",
+        table.c_str(), ident().c_str());
   return res.size() > 0;
 }
 
 bool 
 database::delta_exists(hexenc<id> const & ident,
-		       hexenc<id> const & base,
-		       string const & table)
+                       hexenc<id> const & base,
+                       string const & table)
 {
   results res;
   fetch(res, one_col, any_rows, 
-	"SELECT id FROM '%q' WHERE id = '%q' AND base = '%q'",
-	table.c_str(), ident().c_str(), base().c_str());
+        "SELECT id FROM '%q' WHERE id = '%q' AND base = '%q'",
+        table.c_str(), ident().c_str(), base().c_str());
   I((res.size() == 1) || (res.size() == 0));
   return res.size() == 1;
 }
@@ -691,20 +691,20 @@
 {
   results res;
   fetch(res, one_col, one_row, 
-	"SELECT COUNT(*) FROM '%q'", 
-	table.c_str());
+        "SELECT COUNT(*) FROM '%q'", 
+        table.c_str());
   return lexical_cast<int>(res[0][0]);  
 }
 
 void 
 database::get(hexenc<id> const & ident,
-	      base64< gzip<data> > & dat,
-	      string const & table)
+              base64< gzip<data> > & dat,
+              string const & table)
 {
   results res;
   fetch(res, one_col, one_row,
-	"SELECT data FROM '%q' WHERE id = '%q'", 
-	table.c_str(), ident().c_str());
+        "SELECT data FROM '%q' WHERE id = '%q'", 
+        table.c_str(), ident().c_str());
 
   // consistency check
   base64<gzip<data> > rdata(res[0][0]);
@@ -717,23 +717,23 @@
 
 void 
 database::get_delta(hexenc<id> const & ident,
-		    hexenc<id> const & base,
-		    base64< gzip<delta> > & del,
-		    string const & table)
+                    hexenc<id> const & base,
+                    base64< gzip<delta> > & del,
+                    string const & table)
 {
   I(ident() != "");
   I(base() != "");
   results res;
   fetch(res, one_col, one_row,
-	"SELECT delta FROM '%q' WHERE id = '%q' AND base = '%q'", 
-	table.c_str(), ident().c_str(), base().c_str());
+        "SELECT delta FROM '%q' WHERE id = '%q' AND base = '%q'", 
+        table.c_str(), ident().c_str(), base().c_str());
   del = res[0][0];
 }
 
 void 
 database::put(hexenc<id> const & ident,
-	      base64< gzip<data> > const & dat,
-	      string const & table)
+              base64< gzip<data> > const & dat,
+              string const & table)
 {
   // consistency check
   I(ident() != "");
@@ -742,29 +742,29 @@
   I(tid == ident);
   
   execute("INSERT INTO '%q' VALUES('%q', '%q')", 
-	  table.c_str(), ident().c_str(), dat().c_str());
+          table.c_str(), ident().c_str(), dat().c_str());
 }
 
 
 void 
 database::put_delta(hexenc<id> const & ident,
-		    hexenc<id> const & base,
-		    base64<gzip<delta> > const & del,
-		    string const & table)
+                    hexenc<id> const & base,
+                    base64<gzip<delta> > const & del,
+                    string const & table)
 {
   // nb: delta schema is (id, base, delta)
   I(ident() != "");
   I(base() != "");
   execute("INSERT INTO '%q' VALUES('%q', '%q', '%q')", 
-	  table.c_str(), 
-	  ident().c_str(), base().c_str(), del().c_str());
+          table.c_str(), 
+          ident().c_str(), base().c_str(), del().c_str());
 }
 
 void 
 database::get_version(hexenc<id> const & ident,
-		      base64< gzip<data> > & dat,
-		      string const & data_table,
-		      string const & delta_table)
+                      base64< gzip<data> > & dat,
+                      string const & data_table,
+                      string const & delta_table)
 {
   I(ident() != "");
   if (exists(ident, data_table))
@@ -809,53 +809,53 @@
       hexenc<id> root("");
 
       while (! found_root)
-	{
-	  set< hexenc<id> > next_frontier;
-	  shared_ptr<edgemap> frontier_map(new edgemap());
-
-	  I(!frontier.empty());
-
-	  for (set< hexenc<id> >::const_iterator i = frontier.begin();
-	       i != frontier.end(); ++i)
-	    {
-	      if (exists(*i, data_table))
-		{
-		  root = *i;
-		  found_root = true;
-		  break;
-		}
-	      else
-		{
-		  cycles.insert(*i);
-		  results res;
-		  fetch(res, one_col, any_rows, "SELECT base from '%q' WHERE id = '%q'",
-			delta_table.c_str(), (*i)().c_str());
-		  for (size_t k = 0; k < res.size(); ++k)
-		    {
-		      hexenc<id> const nxt(res[k][0]);
-
-		      if (cycles.find(nxt) != cycles.end())
-			throw oops("cycle in table '" + delta_table + "', at node " 
-				   + (*i)() + " <- " + nxt());
-
-		      next_frontier.insert(nxt);
-
-		      if (frontier_map->find(nxt) == frontier_map->end())
-			{
-			  L(F("inserting edge: %s <- %s\n") % (*i) % nxt);
-			  frontier_map->insert(make_pair(nxt, *i));
-			}
-		      else
-			L(F("skipping merge edge %s <- %s\n") % (*i) % nxt);
-		    }
-		}
-	    }
-	  if (!found_root)
-	    {
-	      frontier = next_frontier;
-	      paths.push_front(frontier_map);
-	    }
-	}
+        {
+          set< hexenc<id> > next_frontier;
+          shared_ptr<edgemap> frontier_map(new edgemap());
+
+          I(!frontier.empty());
+
+          for (set< hexenc<id> >::const_iterator i = frontier.begin();
+               i != frontier.end(); ++i)
+            {
+              if (exists(*i, data_table))
+                {
+                  root = *i;
+                  found_root = true;
+                  break;
+                }
+              else
+                {
+                  cycles.insert(*i);
+                  results res;
+                  fetch(res, one_col, any_rows, "SELECT base from '%q' WHERE id = '%q'",
+                        delta_table.c_str(), (*i)().c_str());
+                  for (size_t k = 0; k < res.size(); ++k)
+                    {
+                      hexenc<id> const nxt(res[k][0]);
+
+                      if (cycles.find(nxt) != cycles.end())
+                        throw oops("cycle in table '" + delta_table + "', at node " 
+                                   + (*i)() + " <- " + nxt());
+
+                      next_frontier.insert(nxt);
+
+                      if (frontier_map->find(nxt) == frontier_map->end())
+                        {
+                          L(F("inserting edge: %s <- %s\n") % (*i) % nxt);
+                          frontier_map->insert(make_pair(nxt, *i));
+                        }
+                      else
+                        L(F("skipping merge edge %s <- %s\n") % (*i) % nxt);
+                    }
+                }
+            }
+          if (!found_root)
+            {
+              frontier = next_frontier;
+              paths.push_front(frontier_map);
+            }
+        }
 
       // path built, now all we need to do is follow it back
 
@@ -871,21 +871,21 @@
       app->begin(begin());
       
       for (list< shared_ptr<edgemap> >::const_iterator p = paths.begin();
-	   p != paths.end(); ++p)
-	{
-	  shared_ptr<edgemap> i = *p;
-	  I(i->find(curr) != i->end());
-	  hexenc<id> const nxt = i->find(curr)->second;
-
-	  L(F("following delta %s -> %s\n") % curr % nxt);
-	  base64< gzip<delta> > del_packed;
-	  get_delta(nxt, curr, del_packed, delta_table);
-	  delta del;
-	  unpack(del_packed, del);
-	  apply_delta (app, del());
-	  app->next();
-	  curr = nxt;
-	}
+           p != paths.end(); ++p)
+        {
+          shared_ptr<edgemap> i = *p;
+          I(i->find(curr) != i->end());
+          hexenc<id> const nxt = i->find(curr)->second;
+
+          L(F("following delta %s -> %s\n") % curr % nxt);
+          base64< gzip<delta> > del_packed;
+          get_delta(nxt, curr, del_packed, delta_table);
+          delta del;
+          unpack(del_packed, del);
+          apply_delta (app, del());
+          app->next();
+          curr = nxt;
+        }
 
       string tmp;
       app->finish(tmp);
@@ -901,19 +901,19 @@
 
 void 
 database::drop(hexenc<id> const & ident, 
-	       string const & table)
+               string const & table)
 {
   execute("DELETE FROM '%q' WHERE id = '%q'",  
-	  table.c_str(),
-	  ident().c_str());
+          table.c_str(),
+          ident().c_str());
 }
 
 void 
 database::put_version(hexenc<id> const & old_id,
-		      hexenc<id> const & new_id,
-		      base64< gzip<delta> > const & del,
-		      string const & data_table,
-		      string const & delta_table)
+                      hexenc<id> const & new_id,
+                      base64< gzip<delta> > const & del,
+                      string const & data_table,
+                      string const & delta_table)
 {
 
   base64< gzip<data> > old_data, new_data;
@@ -937,10 +937,10 @@
 
 void 
 database::put_reverse_version(hexenc<id> const & new_id,
-			      hexenc<id> const & old_id,
-			      base64< gzip<delta> > const & reverse_del,
-			      string const & data_table,
-			      string const & delta_table)
+                              hexenc<id> const & old_id,
+                              base64< gzip<delta> > const & reverse_del,
+                              string const & data_table,
+                              string const & delta_table)
 {
   base64< gzip<data> > old_data, new_data;
   
@@ -986,7 +986,7 @@
 
 void 
 database::get_file_version(file_id const & id,
-			   file_data & dat)
+                           file_data & dat)
 {
   base64< gzip<data> > tmp;
   get_version(id.inner(), tmp, "files", "file_deltas");
@@ -995,7 +995,7 @@
 
 void 
 database::get_manifest_version(manifest_id const & id,
-			       manifest_data & dat)
+                               manifest_data & dat)
 {
   base64< gzip<data> > tmp;
   get_version(id.inner(), tmp, "manifests", "manifest_deltas");
@@ -1004,7 +1004,7 @@
 
 void 
 database::get_manifest(manifest_id const & id,
-		       manifest_map & mm)
+                       manifest_map & mm)
 {
   manifest_data mdat;
   get_manifest_version(id, mdat);
@@ -1014,53 +1014,53 @@
 
 void 
 database::put_file(file_id const & id,
-		   file_data const & dat)
+                   file_data const & dat)
 {
   put(id.inner(), dat.inner(), "files");
 }
 
 void 
 database::put_file_version(file_id const & old_id,
-			   file_id const & new_id,
-			   file_delta const & del)
+                           file_id const & new_id,
+                           file_delta const & del)
 {
   put_version(old_id.inner(), new_id.inner(), del.inner(), 
-	      "files", "file_deltas");
+              "files", "file_deltas");
 }
 
 void 
 database::put_file_reverse_version(file_id const & new_id,
-				   file_id const & old_id,				   
-				   file_delta const & del)
+                                   file_id const & old_id,                                 
+                                   file_delta const & del)
 {
   put_reverse_version(new_id.inner(), old_id.inner(), del.inner(), 
-		      "files", "file_deltas");
+                      "files", "file_deltas");
 }
 
 
 void 
 database::put_manifest(manifest_id const & id,
-		       manifest_data const & dat)
+                       manifest_data const & dat)
 {
   put(id.inner(), dat.inner(), "manifests");
 }
 
 void 
 database::put_manifest_version(manifest_id const & old_id,
-			       manifest_id const & new_id,
-			       manifest_delta const & del)
+                               manifest_id const & new_id,
+                               manifest_delta const & del)
 {
   put_version(old_id.inner(), new_id.inner(), del.inner(), 
-	      "manifests", "manifest_deltas");
+              "manifests", "manifest_deltas");
 }
 
 void 
 database::put_manifest_reverse_version(manifest_id const & new_id,
-				       manifest_id const & old_id,				   
-				       manifest_delta const & del)
+                                       manifest_id const & old_id,                                 
+                                       manifest_delta const & del)
 {
   put_reverse_version(new_id.inner(), old_id.inner(), del.inner(), 
-		      "manifests", "manifest_deltas");
+                      "manifests", "manifest_deltas");
 }
 
 
@@ -1070,41 +1070,41 @@
   results res;
   graph.clear();
   fetch(res, 2, any_rows, 
-	"SELECT parent,child FROM revision_ancestry");
+        "SELECT parent,child FROM revision_ancestry");
   for (size_t i = 0; i < res.size(); ++i)
     graph.insert(std::make_pair(revision_id(res[i][0]),
-				revision_id(res[i][1])));
+                                revision_id(res[i][1])));
 }
 
 void 
 database::get_revision_parents(revision_id const & id,
-			      set<revision_id> & parents)
+                              set<revision_id> & parents)
 {
   results res;
   parents.clear();
   fetch(res, one_col, any_rows, 
-	"SELECT parent FROM revision_ancestry WHERE child = '%q'",
-	id.inner()().c_str());
+        "SELECT parent FROM revision_ancestry WHERE child = '%q'",
+        id.inner()().c_str());
   for (size_t i = 0; i < res.size(); ++i)
     parents.insert(revision_id(res[i][0]));
 }
 
 void 
 database::get_revision_children(revision_id const & id,
-				set<revision_id> & children)
+                                set<revision_id> & children)
 {
   results res;
   children.clear();
   fetch(res, one_col, any_rows, 
-	"SELECT child FROM revision_ancestry WHERE parent = '%q'",
-	id.inner()().c_str());
+        "SELECT child FROM revision_ancestry WHERE parent = '%q'",
+        id.inner()().c_str());
   for (size_t i = 0; i < res.size(); ++i)
     children.insert(revision_id(res[i][0]));
 }
 
 void 
 database::get_revision_manifest(revision_id const & rid,
-			       manifest_id & mid)
+                               manifest_id & mid)
 {
   revision_set rev;
   get_revision(rid, rev);
@@ -1113,7 +1113,7 @@
 
 void 
 database::get_revision(revision_id const & id,
-		       revision_set & rev)
+                       revision_set & rev)
 {
   revision_data d;
   get_revision(id, d);
@@ -1122,12 +1122,12 @@
 
 void 
 database::get_revision(revision_id const & id,
-		       revision_data & dat)
+                       revision_data & dat)
 {
   results res;
   fetch(res, one_col, one_row, 
-	"SELECT data FROM revisions WHERE id = '%q'",
-	id.inner()().c_str());
+        "SELECT data FROM revisions WHERE id = '%q'",
+        id.inner()().c_str());
 
   dat = revision_data(res[0][0]);
 
@@ -1141,7 +1141,7 @@
 
 void 
 database::put_revision(revision_id const & new_id,
-		       revision_set const & rev)
+                       revision_set const & rev)
 {
 
   I(!revision_exists(new_id));
@@ -1155,15 +1155,15 @@
   transaction_guard guard(*this);
 
   execute("INSERT INTO revisions VALUES('%q', '%q')", 
-	  new_id.inner()().c_str(), 
-	  d.inner()().c_str());
+          new_id.inner()().c_str(), 
+          d.inner()().c_str());
 
   for (edge_map::const_iterator e = rev.edges.begin();
        e != rev.edges.end(); ++e)
     {
       execute("INSERT INTO revision_ancestry VALUES('%q', '%q')", 
-	      edge_old_revision(e).inner()().c_str(),
-	      new_id.inner()().c_str());
+              edge_old_revision(e).inner()().c_str(),
+              new_id.inner()().c_str());
     }
 
   guard.commit();
@@ -1171,7 +1171,7 @@
 
 void 
 database::put_revision(revision_id const & new_id,
-		       revision_data const & dat)
+                       revision_data const & dat)
 {
   revision_set rev;
   read_revision_set(dat, rev);
@@ -1183,8 +1183,8 @@
 
 void 
 database::get_key_ids(string const & pattern,
-		      vector<rsa_keypair_id> & pubkeys,
-		      vector<rsa_keypair_id> & privkeys)
+                      vector<rsa_keypair_id> & pubkeys,
+                      vector<rsa_keypair_id> & privkeys)
 {
   pubkeys.clear();
   privkeys.clear();
@@ -1192,22 +1192,22 @@
 
   if (pattern != "")
     fetch(res, one_col, any_rows, 
-	  "SELECT id from public_keys WHERE id GLOB '%q'",
-	  pattern.c_str());
+          "SELECT id from public_keys WHERE id GLOB '%q'",
+          pattern.c_str());
   else
     fetch(res, one_col, any_rows, 
-	  "SELECT id from public_keys");
+          "SELECT id from public_keys");
 
   for (size_t i = 0; i < res.size(); ++i)
     pubkeys.push_back(res[i][0]);
 
   if (pattern != "")
     fetch(res, one_col, any_rows, 
-	  "SELECT id from private_keys WHERE id GLOB '%q'",
-	  pattern.c_str());
+          "SELECT id from private_keys WHERE id GLOB '%q'",
+          pattern.c_str());
   else
     fetch(res, one_col, any_rows, 
-	  "SELECT id from private_keys");
+          "SELECT id from private_keys");
 
   for (size_t i = 0; i < res.size(); ++i)
     privkeys.push_back(res[i][0]);
@@ -1228,8 +1228,8 @@
 {
   results res;
   fetch(res, one_col, any_rows, 
-	"SELECT id FROM public_keys WHERE hash = '%q'",
-	hash().c_str());
+        "SELECT id FROM public_keys WHERE hash = '%q'",
+        hash().c_str());
   I((res.size() == 1) || (res.size() == 0));
   if (res.size() == 1) 
     return true;
@@ -1241,8 +1241,8 @@
 {
   results res;
   fetch(res, one_col, any_rows, 
-	"SELECT id FROM public_keys WHERE id = '%q'",
-	id().c_str());
+        "SELECT id FROM public_keys WHERE id = '%q'",
+        id().c_str());
   I((res.size() == 1) || (res.size() == 0));
   if (res.size() == 1) 
     return true;
@@ -1254,8 +1254,8 @@
 {
   results res;
   fetch(res, one_col, any_rows,
-	"SELECT id FROM private_keys WHERE id = '%q'",
-	id().c_str());
+        "SELECT id FROM private_keys WHERE id = '%q'",
+        id().c_str());
   I((res.size() == 1) || (res.size() == 0));
   if (res.size() == 1)
     return true;
@@ -1270,65 +1270,65 @@
 
 void 
 database::get_pubkey(hexenc<id> const & hash, 
-		     rsa_keypair_id & id,
-		     base64<rsa_pub_key> & pub_encoded)
+                     rsa_keypair_id & id,
+                     base64<rsa_pub_key> & pub_encoded)
 {
   results res;
   fetch(res, 2, one_row, 
-	"SELECT id, keydata FROM public_keys where hash = '%q'", 
-	hash().c_str());
+        "SELECT id, keydata FROM public_keys where hash = '%q'", 
+        hash().c_str());
   id = res[0][0];
   pub_encoded = res[0][1];
 }
 
 void 
 database::get_key(rsa_keypair_id const & pub_id, 
-		  base64<rsa_pub_key> & pub_encoded)
+                  base64<rsa_pub_key> & pub_encoded)
 {
   results res;
   fetch(res, one_col, one_row, 
-	"SELECT keydata FROM public_keys where id = '%q'", 
-	pub_id().c_str());
+        "SELECT keydata FROM public_keys where id = '%q'", 
+        pub_id().c_str());
   pub_encoded = res[0][0];
 }
 
 void 
 database::get_key(rsa_keypair_id const & priv_id, 
-		  base64< arc4<rsa_priv_key> > & priv_encoded)
+                  base64< arc4<rsa_priv_key> > & priv_encoded)
 {
   results res;
   fetch(res, one_col, one_col, 
-	"SELECT keydata FROM private_keys where id = '%q'", 
-	priv_id().c_str());
+        "SELECT keydata FROM private_keys where id = '%q'", 
+        priv_id().c_str());
   priv_encoded = res[0][0];
 }
 
 
 void 
 database::put_key(rsa_keypair_id const & pub_id, 
-		  base64<rsa_pub_key> const & pub_encoded)
+                  base64<rsa_pub_key> const & pub_encoded)
 {
   hexenc<id> thash;
   key_hash_code(pub_id, pub_encoded, thash);
   execute("INSERT INTO public_keys VALUES('%q', '%q', '%q')", 
-	  thash().c_str(), pub_id().c_str(), pub_encoded().c_str());
+          thash().c_str(), pub_id().c_str(), pub_encoded().c_str());
 }
 
 void 
 database::put_key(rsa_keypair_id const & priv_id, 
-		  base64< arc4<rsa_priv_key> > const & priv_encoded)
+                  base64< arc4<rsa_priv_key> > const & priv_encoded)
 {
   
   hexenc<id> thash;
   key_hash_code(priv_id, priv_encoded, thash);
   execute("INSERT INTO private_keys VALUES('%q', '%q', '%q')", 
-	  thash().c_str(), priv_id().c_str(), priv_encoded().c_str());
+          thash().c_str(), priv_id().c_str(), priv_encoded().c_str());
 }
 
 void 
 database::put_key_pair(rsa_keypair_id const & id, 
-		       base64<rsa_pub_key> const & pub_encoded,
-		       base64< arc4<rsa_priv_key> > const & priv_encoded)
+                       base64<rsa_pub_key> const & pub_encoded,
+                       base64< arc4<rsa_priv_key> > const & priv_encoded)
 {
   transaction_guard guard(*this);
   put_key(id, pub_encoded);
@@ -1341,52 +1341,52 @@
 
 bool 
 database::cert_exists(cert const & t,
-		      string const & table)
+                      string const & table)
 {
   results res;
   fetch(res, 1, any_rows,
-	"SELECT id FROM '%q' WHERE id = '%q' "
-	"AND name = '%q' AND value = '%q' " 
-	"AND keypair = '%q' AND signature = '%q' ",
-	table.c_str(),
-	t.ident().c_str(),
-	t.name().c_str(),
-	t.value().c_str(),
-	t.key().c_str(),
-	t.sig().c_str());
+        "SELECT id FROM '%q' WHERE id = '%q' "
+        "AND name = '%q' AND value = '%q' " 
+        "AND keypair = '%q' AND signature = '%q' ",
+        table.c_str(),
+        t.ident().c_str(),
+        t.name().c_str(),
+        t.value().c_str(),
+        t.key().c_str(),
+        t.sig().c_str());
   I(res.size() == 0 || res.size() == 1);
   return res.size() == 1;
 }
 
 void 
 database::put_cert(cert const & t,
-		   string const & table)
+                   string const & table)
 {
   hexenc<id> thash;
   cert_hash_code(t, thash);
   execute("INSERT INTO '%q' VALUES('%q', '%q', '%q', '%q', '%q', '%q')", 
-	  table.c_str(),
-	  thash().c_str(),
-	  t.ident().c_str(),
-	  t.name().c_str(), 
-	  t.value().c_str(),
-	  t.key().c_str(),
-	  t.sig().c_str());
+          table.c_str(),
+          thash().c_str(),
+          t.ident().c_str(),
+          t.name().c_str(), 
+          t.value().c_str(),
+          t.key().c_str(),
+          t.sig().c_str());
 }
 
 void 
 database::results_to_certs(results const & res,
-			   vector<cert> & certs)
+                           vector<cert> & certs)
 {
   certs.clear();
   for (size_t i = 0; i < res.size(); ++i)
     {
       cert t;
       t = cert(hexenc<id>(res[i][0]), 
-	      cert_name(res[i][1]),
-	      base64<cert_value>(res[i][2]),
-	      rsa_keypair_id(res[i][3]),
-	      base64<rsa_sha1_signature>(res[i][4]));
+              cert_name(res[i][1]),
+              base64<cert_value>(res[i][2]),
+              rsa_keypair_id(res[i][3]),
+              base64<rsa_sha1_signature>(res[i][4]));
       certs.push_back(t);
     }
 }
@@ -1414,93 +1414,93 @@
       % valid_signers.size() % signature_type);
     try
       {
-	cert_value v;
-	decode_base64(val, v);
-	// FIXME: lame string-makes-the-mode argument
-	if (signature_type == "revision")
-	  trusted = app.lua.hook_get_revision_cert_trust(valid_signers,
-							ident, name, v);
-	else if (signature_type == "manifest")
-	  trusted = app.lua.hook_get_manifest_cert_trust(valid_signers,
-							 ident, name, v);
-	else if (signature_type == "file")
-	  trusted = app.lua.hook_get_file_cert_trust(valid_signers,
-						     ident, name, v);
-	else
-	  I(false); // should be illegal
+        cert_value v;
+        decode_base64(val, v);
+        // FIXME: lame string-makes-the-mode argument
+        if (signature_type == "revision")
+          trusted = app.lua.hook_get_revision_cert_trust(valid_signers,
+                                                        ident, name, v);
+        else if (signature_type == "manifest")
+          trusted = app.lua.hook_get_manifest_cert_trust(valid_signers,
+                                                         ident, name, v);
+        else if (signature_type == "file")
+          trusted = app.lua.hook_get_file_cert_trust(valid_signers,
+                                                     ident, name, v);
+        else
+          I(false); // should be illegal
       }
     catch (...)
       {
-	W(F("exception in sqlite valid_certs::check_set_trust\n"));
+        W(F("exception in sqlite valid_certs::check_set_trust\n"));
       }
     
     if (trusted)
       L(F("trust function liked %d %s signers\n") 
-	% valid_signers.size() % signature_type);
+        % valid_signers.size() % signature_type);
     else
       L(F("trust function disliked %d %s signers\n") 
-	% valid_signers.size() % signature_type);
+        % valid_signers.size() % signature_type);
     
     return trusted;
   }
 
   void check_single_signer(app_state & app,
-			   int argc, 
-			   char const ** argv)
+                           int argc, 
+                           char const ** argv)
   {
     try
       {
-	// args are: hash, id, name, value, keypair, pubkey, signature
-	// L(F("entries are [%s] [%s] [%s] [%s] [%s] [%s] [%s]\n") 
-	// 	  % argv[0] % argv[1] % argv[2] % argv[3] % argv[4] % argv[5] % argv[6]);
-
-	cert tmp = cert(hexenc<id>(argv[1]), 
-			cert_name(argv[2]),
-			base64<cert_value>(argv[3]),
-			rsa_keypair_id(argv[4]),
-			base64<rsa_sha1_signature>(argv[6]));
-
-	base64<rsa_pub_key> pk(argv[5]);
-
-	if (ident().empty())
-	  ident = tmp.ident;
-	else
-	  I(ident == tmp.ident);
-
-	if (name().empty())
-	  name = tmp.name;
-	else
-	  I(name == tmp.name);
-
-	if (val().empty())
-	  val = tmp.value;
-	else
-	  I(val == tmp.value);
-
-	// 	L(F("examining '%s' %s cert from %s\n") 
-	// 	  % name % signature_type % ident);
-
-	string txt;
-	cert_signable_text(tmp, txt);
-	if (check_signature(app.lua, tmp.key, pk, txt, tmp.sig))
-	  {
-	    L(F("ok '%s' %s cert from %s\n") 
-	      % name % signature_type % tmp.key);
-	    valid_signers.insert(tmp.key);
-	  }
-	else
-	  {
-	    W(F("bad '%s' %s cert from %s\n") 
-	      % name % signature_type % tmp.key);
-	  }
+        // args are: hash, id, name, value, keypair, pubkey, signature
+        // L(F("entries are [%s] [%s] [%s] [%s] [%s] [%s] [%s]\n") 
+        //        % argv[0] % argv[1] % argv[2] % argv[3] % argv[4] % argv[5] % argv[6]);
+
+        cert tmp = cert(hexenc<id>(argv[1]), 
+                        cert_name(argv[2]),
+                        base64<cert_value>(argv[3]),
+                        rsa_keypair_id(argv[4]),
+                        base64<rsa_sha1_signature>(argv[6]));
+
+        base64<rsa_pub_key> pk(argv[5]);
+
+        if (ident().empty())
+          ident = tmp.ident;
+        else
+          I(ident == tmp.ident);
+
+        if (name().empty())
+          name = tmp.name;
+        else
+          I(name == tmp.name);
+
+        if (val().empty())
+          val = tmp.value;
+        else
+          I(val == tmp.value);
+
+        //      L(F("examining '%s' %s cert from %s\n") 
+        //        % name % signature_type % ident);
+
+        string txt;
+        cert_signable_text(tmp, txt);
+        if (check_signature(app.lua, tmp.key, pk, txt, tmp.sig))
+          {
+            L(F("ok '%s' %s cert from %s\n") 
+              % name % signature_type % tmp.key);
+            valid_signers.insert(tmp.key);
+          }
+        else
+          {
+            W(F("bad '%s' %s cert from %s\n") 
+              % name % signature_type % tmp.key);
+          }
       }
     catch (std::exception & e)
       {
-	W(F("std::exception in sqlite valid_certs::check_single_signer: %s\n") % e.what());
+        W(F("std::exception in sqlite valid_certs::check_single_signer: %s\n") % e.what());
       }
     catch (...)
       {
-	W(F("unknown exception in sqlite valid_certs::check_single_signer\n"));
+        W(F("unknown exception in sqlite valid_certs::check_single_signer\n"));
       }
   }
 };
@@ -1510,8 +1510,8 @@
 
 static void
 trusted_step_callback(sqlite_func * fn_ctx, 
-		      int argc, 
-		      char const ** argv)
+                      int argc, 
+                      char const ** argv)
 {
   app_state * app = NULL; 
   valid_certs ** vpp;
@@ -1559,13 +1559,13 @@
 {
   // register any functions we're going to use
   I(sqlite_create_function(sql(), "unbase64", -1, 
-			   &sqlite_unbase64_fn, 
-			   NULL) == 0);
+                           &sqlite_unbase64_fn, 
+                           NULL) == 0);
 
   I(sqlite_create_aggregate(sql(), "trusted", 8, 
-			    &trusted_step_callback,
-			    &trusted_finalize_callback,
-			    app) == 0);
+                            &trusted_step_callback,
+                            &trusted_finalize_callback,
+                            app) == 0);
 }
 
 void
@@ -1574,7 +1574,7 @@
   // delete any existing views
   results res;
   fetch(res, one_col, any_rows,
-	"SELECT name FROM sqlite_master WHERE type='view'");
+        "SELECT name FROM sqlite_master WHERE type='view'");
   for (size_t i = 0; i < res.size(); ++i)
     {
       execute("DROP VIEW '%q'", res[i][0].c_str());
@@ -1585,14 +1585,14 @@
 
 void 
 database::get_heads(base64<cert_value> const & branch,
-		    std::set<revision_id> & heads)
+                    std::set<revision_id> & heads)
 {
   results res;
   fetch(res, one_col, any_rows,
-	"SELECT id "
-	"FROM branch_heads "
-	"WHERE value = '%q'",
-	branch().c_str());
+        "SELECT parent "
+        "FROM branch_heads "
+        "WHERE value = '%q'",
+        branch().c_str());
   heads.clear();
   for (size_t i = 0; i < res.size(); ++i)
     {
@@ -1602,85 +1602,85 @@
 
 void 
 database::get_certs(hexenc<id> const & ident, 
-		    vector<cert> & certs,			
-		    string const & table)
+                    vector<cert> & certs,                       
+                    string const & table)
 {
   results res;
   fetch(res, 5, any_rows, 
-	"SELECT id, name, value, keypair, signature FROM '%q' "
-	"WHERE id = '%q'", 
-	table.c_str(), 	
-	ident().c_str());
+        "SELECT id, name, value, keypair, signature FROM '%q' "
+        "WHERE id = '%q'", 
+        table.c_str(),  
+        ident().c_str());
   results_to_certs(res, certs);
 }
 
 
 void 
-database::get_certs(cert_name const & name, 	      
-		    vector<cert> & certs,
-		    string const & table)
+database::get_certs(cert_name const & name,           
+                    vector<cert> & certs,
+                    string const & table)
 {
   results res;
   fetch(res, 5, any_rows, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM '%q' WHERE name = '%q'", 
-	table.c_str(), 	
-	name().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM '%q' WHERE name = '%q'", 
+        table.c_str(),  
+        name().c_str());
   results_to_certs(res, certs);
 }
 
 
 void 
 database::get_certs(hexenc<id> const & ident, 
-		    cert_name const & name, 	      
-		    vector<cert> & certs,
-		    string const & table)
+                    cert_name const & name,           
+                    vector<cert> & certs,
+                    string const & table)
 {
   results res;
   fetch(res, 5, any_rows, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM '%q' "
-	"WHERE id = '%q' AND name = '%q'", 
-	table.c_str(), 	
-	ident().c_str(),
-	name().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM '%q' "
+        "WHERE id = '%q' AND name = '%q'", 
+        table.c_str(),  
+        ident().c_str(),
+        name().c_str());
   results_to_certs(res, certs);
 }
 
 void 
 database::get_certs(cert_name const & name,
-		    base64<cert_value> const & val, 
-		    vector<cert> & certs,
-		    string const & table)
+                    base64<cert_value> const & val, 
+                    vector<cert> & certs,
+                    string const & table)
 {
   results res;
   fetch(res, 5, any_rows, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM '%q' "
-	"WHERE name = '%q' AND value = '%q'", 
-	table.c_str(), 	
-	name().c_str(),
-	val().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM '%q' "
+        "WHERE name = '%q' AND value = '%q'", 
+        table.c_str(),  
+        name().c_str(),
+        val().c_str());
   results_to_certs(res, certs);
 }
 
 
 void 
 database::get_certs(hexenc<id> const & ident, 
-		    cert_name const & name, 	      
-		    base64<cert_value> const & value,
-		    vector<cert> & certs,
-		    string const & table)
+                    cert_name const & name,           
+                    base64<cert_value> const & value,
+                    vector<cert> & certs,
+                    string const & table)
 {
   results res;
   fetch(res, 5, any_rows, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM '%q' "
-	"WHERE id = '%q' AND name = '%q' AND value = '%q'", 
-	table.c_str(), 	
-	ident().c_str(),
-	name().c_str(),
-	value().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM '%q' "
+        "WHERE id = '%q' AND name = '%q' AND value = '%q'", 
+        table.c_str(),  
+        ident().c_str(),
+        name().c_str(),
+        value().c_str());
   results_to_certs(res, certs);
 }
 
@@ -1724,7 +1724,7 @@
 
 void 
 database::get_file_certs(cert_name const & name, 
-			 vector< file<cert> > & ts)
+                         vector< file<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(name, certs, "file_certs");
@@ -1734,8 +1734,8 @@
 
 void 
 database::get_file_certs(file_id const & id, 
-			 cert_name const & name, 
-			 vector< file<cert> > & ts)
+                         cert_name const & name, 
+                         vector< file<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(id.inner(), name, certs, "file_certs");
@@ -1745,8 +1745,8 @@
 
 void 
 database::get_file_certs(cert_name const & name,
-			 base64<cert_value> const & val, 
-			 vector< file<cert> > & ts)
+                         base64<cert_value> const & val, 
+                         vector< file<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(name, val, certs, "file_certs");
@@ -1756,9 +1756,9 @@
 
 void 
 database::get_file_certs(file_id const & id, 
-			 cert_name const & name,
-			 base64<cert_value> const & val, 
-			 vector< file<cert> > & ts)
+                         cert_name const & name,
+                         base64<cert_value> const & val, 
+                         vector< file<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(id.inner(), name, val, certs, "file_certs");
@@ -1768,7 +1768,7 @@
 
 void 
 database::get_file_certs(file_id const & id, 
-			 vector< file<cert> > & ts)
+                         vector< file<cert> > & ts)
 { 
   vector<cert> certs;
   get_certs(id.inner(), certs, "file_certs"); 
@@ -1783,25 +1783,25 @@
   results res;
   vector<cert> certs;
   fetch(res, one_col, any_rows, 
-	"SELECT id "
-	"FROM file_certs "
-	"WHERE hash = '%q'", 
-	hash().c_str());
+        "SELECT id "
+        "FROM file_certs "
+        "WHERE hash = '%q'", 
+        hash().c_str());
   I(res.size() == 0 || res.size() == 1);
   return (res.size() == 1);
 }
 
 void 
 database::get_file_cert(hexenc<id> const & hash,
-			file<cert> & c)
+                        file<cert> & c)
 {
   results res;
   vector<cert> certs;
   fetch(res, 5, one_row, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM file_certs "
-	"WHERE hash = '%q'", 
-	hash().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM file_certs "
+        "WHERE hash = '%q'", 
+        hash().c_str());
   results_to_certs(res, certs);
   I(certs.size() == 1);
   c = file<cert>(certs[0]);
@@ -1811,7 +1811,7 @@
 
 void 
 database::get_revision_certs(cert_name const & name, 
-			    vector< revision<cert> > & ts)
+                            vector< revision<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(name, certs, "revision_certs");
@@ -1821,8 +1821,8 @@
 
 void 
 database::get_revision_certs(revision_id const & id, 
-			    cert_name const & name, 
-			    vector< revision<cert> > & ts)
+                            cert_name const & name, 
+                            vector< revision<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(id.inner(), name, certs, "revision_certs");
@@ -1832,9 +1832,9 @@
 
 void 
 database::get_revision_certs(revision_id const & id, 
-			    cert_name const & name,
-			    base64<cert_value> const & val, 
-			    vector< revision<cert> > & ts)
+                            cert_name const & name,
+                            base64<cert_value> const & val, 
+                            vector< revision<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(id.inner(), name, val, certs, "revision_certs");
@@ -1844,8 +1844,8 @@
 
 void 
 database::get_revision_certs(cert_name const & name,
-			    base64<cert_value> const & val, 
-			    vector< revision<cert> > & ts)
+                            base64<cert_value> const & val, 
+                            vector< revision<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(name, val, certs, "revision_certs");
@@ -1855,7 +1855,7 @@
 
 void 
 database::get_revision_certs(revision_id const & id, 
-			    vector< revision<cert> > & ts)
+                            vector< revision<cert> > & ts)
 { 
   vector<cert> certs;
   get_certs(id.inner(), certs, "revision_certs"); 
@@ -1865,15 +1865,15 @@
 
 void 
 database::get_revision_cert(hexenc<id> const & hash,
-			   revision<cert> & c)
+                           revision<cert> & c)
 {
   results res;
   vector<cert> certs;
   fetch(res, 5, one_row, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM revision_certs "
-	"WHERE hash = '%q'", 
-	hash().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM revision_certs "
+        "WHERE hash = '%q'", 
+        hash().c_str());
   results_to_certs(res, certs);
   I(certs.size() == 1);
   c = revision<cert>(certs[0]);
@@ -1885,10 +1885,10 @@
   results res;
   vector<cert> certs;
   fetch(res, one_col, any_rows, 
-	"SELECT id "
-	"FROM revision_certs "
-	"WHERE hash = '%q'", 
-	hash().c_str());
+        "SELECT id "
+        "FROM revision_certs "
+        "WHERE hash = '%q'", 
+        hash().c_str());
   I(res.size() == 0 || res.size() == 1);
   return (res.size() == 1);
 }
@@ -1899,25 +1899,25 @@
   results res;
   vector<cert> certs;
   fetch(res, one_col, any_rows, 
-	"SELECT id "
-	"FROM manifest_certs "
-	"WHERE hash = '%q'", 
-	hash().c_str());
+        "SELECT id "
+        "FROM manifest_certs "
+        "WHERE hash = '%q'", 
+        hash().c_str());
   I(res.size() == 0 || res.size() == 1);
   return (res.size() == 1);
 }
 
 void 
 database::get_manifest_cert(hexenc<id> const & hash,
-			    manifest<cert> & c)
+                            manifest<cert> & c)
 {
   results res;
   vector<cert> certs;
   fetch(res, 5, one_row, 
-	"SELECT id, name, value, keypair, signature "
-	"FROM manifest_certs "
-	"WHERE hash = '%q'", 
-	hash().c_str());
+        "SELECT id, name, value, keypair, signature "
+        "FROM manifest_certs "
+        "WHERE hash = '%q'", 
+        hash().c_str());
   results_to_certs(res, certs);
   I(certs.size() == 1);
   c = manifest<cert>(certs[0]);
@@ -1925,7 +1925,7 @@
 
 void 
 database::get_manifest_certs(manifest_id const & id, 
-			     vector< manifest<cert> > & ts)
+                             vector< manifest<cert> > & ts)
 { 
   vector<cert> certs;
   get_certs(id.inner(), certs, "manifest_certs"); 
@@ -1936,7 +1936,7 @@
 
 void 
 database::get_manifest_certs(cert_name const & name, 
-			    vector< manifest<cert> > & ts)
+                            vector< manifest<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(name, certs, "manifest_certs");
@@ -1946,8 +1946,8 @@
 
 void 
 database::get_manifest_certs(manifest_id const & id, 
-			     cert_name const & name, 
-			     vector< manifest<cert> > & ts)
+                             cert_name const & name, 
+                             vector< manifest<cert> > & ts)
 {
   vector<cert> certs;
   get_certs(id.inner(), name, certs, "manifest_certs");
@@ -1959,14 +1959,14 @@
 // completions
 void 
 database::complete(string const & partial,
-		   set<revision_id> & completions)
+                   set<revision_id> & completions)
 {
   results res;
   completions.clear();
 
   fetch(res, 1, any_rows,
-	"SELECT id FROM revisions WHERE id GLOB '%q*'",
-	partial.c_str());
+        "SELECT id FROM revisions WHERE id GLOB '%q*'",
+        partial.c_str());
 
   for (size_t i = 0; i < res.size(); ++i)
     completions.insert(revision_id(res[i][0]));  
@@ -1975,14 +1975,14 @@
 
 void 
 database::complete(string const & partial,
-		   set<manifest_id> & completions)
+                   set<manifest_id> & completions)
 {
   results res;
   completions.clear();
 
   fetch(res, 1, any_rows,
-	"SELECT id FROM manifests WHERE id GLOB '%q*'",
-	partial.c_str());
+        "SELECT id FROM manifests WHERE id GLOB '%q*'",
+        partial.c_str());
 
   for (size_t i = 0; i < res.size(); ++i)
     completions.insert(manifest_id(res[i][0]));  
@@ -1990,8 +1990,8 @@
   res.clear();
 
   fetch(res, 1, any_rows,
-	"SELECT id FROM manifest_deltas WHERE id GLOB '%q*'",
-	partial.c_str());
+        "SELECT id FROM manifest_deltas WHERE id GLOB '%q*'",
+        partial.c_str());
 
   for (size_t i = 0; i < res.size(); ++i)
     completions.insert(manifest_id(res[i][0]));  
@@ -1999,14 +1999,14 @@
 
 void 
 database::complete(string const & partial,
-		   set<file_id> & completions)
+                   set<file_id> & completions)
 {
   results res;
   completions.clear();
 
   fetch(res, 1, any_rows,
-	"SELECT id FROM files WHERE id GLOB '%q*'",
-	partial.c_str());
+        "SELECT id FROM files WHERE id GLOB '%q*'",
+        partial.c_str());
 
   for (size_t i = 0; i < res.size(); ++i)
     completions.insert(file_id(res[i][0]));  
@@ -2014,8 +2014,8 @@
   res.clear();
 
   fetch(res, 1, any_rows,
-	"SELECT id FROM file_deltas WHERE id GLOB '%q*'",
-	partial.c_str());
+        "SELECT id FROM file_deltas WHERE id GLOB '%q*'",
+        partial.c_str());
 
   for (size_t i = 0; i < res.size(); ++i)
     completions.insert(file_id(res[i][0]));  
@@ -2024,7 +2024,7 @@
 using commands::selector_type;
 
 static void selector_to_certname(selector_type ty,
-				 string & s)
+                                 string & s)
 {
   switch (ty)
     {
@@ -2048,9 +2048,9 @@
 }
 
 void database::complete(selector_type ty,
-			string const & partial,
-			vector<pair<selector_type, string> > const & limit,
-			set<string> & completions)
+                        string const & partial,
+                        vector<pair<selector_type, string> > const & limit,
+                        set<string> & completions)
 {
   completions.clear();
 
@@ -2065,34 +2065,34 @@
        i != limit.end(); ++i)
     {
       if (first_limit)
-	first_limit = false;
+        first_limit = false;
       else
-	lim += " INTERSECT ";
+        lim += " INTERSECT ";
       
       if (i->first == commands::sel_ident)
-	{
-	  lim += "SELECT id FROM revision_certs ";
-	  lim += (F("WHERE id GLOB '%s*'") 
-		  % i->second).str();
-	}
+        {
+          lim += "SELECT id FROM revision_certs ";
+          lim += (F("WHERE id GLOB '%s*'") 
+                  % i->second).str();
+        }
       else if (i->first == commands::sel_unknown)
-	{
-	  lim += "SELECT id FROM revision_certs ";
-	  lim += (F(" WHERE (name='%s' OR name='%s' OR name='%s')")
-		  % author_cert_name 
-		  % tag_cert_name 
-		  % branch_cert_name).str();
-	  lim += (F(" AND unbase64(value) glob '*%s*'")
-		  % i->second).str();	  
-	}
+        {
+          lim += "SELECT id FROM revision_certs ";
+          lim += (F(" WHERE (name='%s' OR name='%s' OR name='%s')")
+                  % author_cert_name 
+                  % tag_cert_name 
+                  % branch_cert_name).str();
+          lim += (F(" AND unbase64(value) glob '*%s*'")
+                  % i->second).str();     
+        }
       else
-	{
-	  string certname;
-	  selector_to_certname(i->first, certname);
-	  lim += "SELECT id FROM revision_certs ";
-	  lim += (F("WHERE name='%s' AND unbase64(value) glob '*%s*'")
-		  % certname % i->second).str();
-	}
+        {
+          string certname;
+          selector_to_certname(i->first, certname);
+          lim += "SELECT id FROM revision_certs ";
+          lim += (F("WHERE name='%s' AND unbase64(value) glob '*%s*'")
+                  % certname % i->second).str();
+        }
     }
   lim += ")";
   
@@ -2109,20 +2109,20 @@
     {
       query = "SELECT value FROM revision_certs WHERE";
       if (ty == commands::sel_unknown)
-	{	  	
-	  query += 
-	    (F(" (name='%s' OR name='%s' OR name='%s')")
-	     % author_cert_name 
-	     % tag_cert_name 
-	     % branch_cert_name).str();
-	}
+        {               
+          query += 
+            (F(" (name='%s' OR name='%s' OR name='%s')")
+             % author_cert_name 
+             % tag_cert_name 
+             % branch_cert_name).str();
+        }
       else
-	{
-	  string certname;
-	  selector_to_certname(ty, certname);
-	  query += 
-	    (F(" (name='%s')") % certname).str();
-	}
+        {
+          string certname;
+          selector_to_certname(ty, certname);
+          query += 
+            (F(" (name='%s')") % certname).str();
+        }
         
       query += (F(" AND (unbase64(value) GLOB '*%s*')") % partial).str();
       query += (F(" AND (id IN %s)") % lim).str();
@@ -2133,14 +2133,14 @@
   for (size_t i = 0; i < res.size(); ++i)
     {
       if (ty == commands::sel_ident)
-	completions.insert(res[i][0]);
+        completions.insert(res[i][0]);
       else
-	{
-	  base64<data> row_encoded(res[i][0]);
-	  data row_decoded;
-	  decode_base64(row_encoded, row_decoded);
-	  completions.insert(row_decoded());
-	}
+        {
+          base64<data> row_encoded(res[i][0]);
+          data row_decoded;
+          decode_base64(row_encoded, row_decoded);
+          completions.insert(row_decoded());
+        }
     }
 }
 
@@ -2149,19 +2149,19 @@
 
 bool 
 database::merkle_node_exists(string const & type,
-			     utf8 const & collection, 
-			     size_t level,
-			     hexenc<prefix> const & prefix)
+                             utf8 const & collection, 
+                             size_t level,
+                             hexenc<prefix> const & prefix)
 {
   results res;
   fetch(res, one_col, one_row, 
-	"SELECT COUNT(*) "
-	"FROM merkle_nodes "
-	"WHERE type = '%q' "
-	"AND collection = '%q' "
-	"AND level = %d "
-	"AND prefix = '%q' ",
-	type.c_str(), collection().c_str(), level, prefix().c_str());
+        "SELECT COUNT(*) "
+        "FROM merkle_nodes "
+        "WHERE type = '%q' "
+        "AND collection = '%q' "
+        "AND level = %d "
+        "AND prefix = '%q' ",
+        type.c_str(), collection().c_str(), level, prefix().c_str());
   size_t n_nodes = lexical_cast<size_t>(res[0][0]);
   I(n_nodes == 0 || n_nodes == 1);
   return n_nodes == 1;
@@ -2169,44 +2169,44 @@
 
 void 
 database::get_merkle_node(string const & type,
-			  utf8 const & collection, 
-			  size_t level,
-			  hexenc<prefix> const & prefix,
-			  base64<merkle> & node)
+                          utf8 const & collection, 
+                          size_t level,
+                          hexenc<prefix> const & prefix,
+                          base64<merkle> & node)
 {
   results res;
   fetch(res, one_col, one_row, 
-	"SELECT body "
-	"FROM merkle_nodes "
-	"WHERE type = '%q' "
-	"AND collection = '%q' "
-	"AND level = %d "
-	"AND prefix = '%q'",
-	type.c_str(), collection().c_str(), level, prefix().c_str());
+        "SELECT body "
+        "FROM merkle_nodes "
+        "WHERE type = '%q' "
+        "AND collection = '%q' "
+        "AND level = %d "
+        "AND prefix = '%q'",
+        type.c_str(), collection().c_str(), level, prefix().c_str());
   node = res[0][0];
 }
 
 void 
 database::put_merkle_node(string const & type,
-			  utf8 const & collection, 
-			  size_t level,
-			  hexenc<prefix> const & prefix,				       
-			  base64<merkle> const & node)
+                          utf8 const & collection, 
+                          size_t level,
+                          hexenc<prefix> const & prefix,                                       
+                          base64<merkle> const & node)
 {
   execute("INSERT OR REPLACE "
-	  "INTO merkle_nodes "
-	  "VALUES ('%q', '%q', %d, '%q', '%q')",
-	  type.c_str(), collection().c_str(), level, prefix().c_str(), node().c_str());
+          "INTO merkle_nodes "
+          "VALUES ('%q', '%q', %d, '%q', '%q')",
+          type.c_str(), collection().c_str(), level, prefix().c_str(), node().c_str());
 }
 
 void 
 database::erase_merkle_nodes(string const & type,
-			     utf8 const & collection)
+                             utf8 const & collection)
 {
   execute("DELETE FROM merkle_nodes "
-	  "WHERE type = '%q' "
-	  "AND collection = '%q'",
-	  type.c_str(), collection().c_str());
+          "WHERE type = '%q' "
+          "AND collection = '%q'",
+          type.c_str(), collection().c_str());
 }
 
 // transaction guards
diff -ru monotone-0.15/monotone.texi monotone-0.15-patched/monotone.texi
--- monotone-0.15/monotone.texi	Mon Nov  8 17:00:47 2004
+++ monotone-0.15-patched/monotone.texi	Tue Dec  7 20:32:51 2004
@@ -13,6 +13,7 @@
 This edition documents version @value{VERSION}.
 
 Copyright 2003, 2004 Graydon Hoare
+Copyright 2004 Nathaniel Smith
 All rights reserved
 Licensed to the public under the terms of the GNU FDL (>= 1.1).
 See the file COPYING for details
@@ -31,6 +32,7 @@
 @page
 @vskip 0pt plus 1filll
 Copyright @copyright{} 2003, 2004 Graydon Hoare
+Copyright @copyright{} 2004 Nathaniel Smith
 All rights reserved
 Licensed to the public under the terms of the GNU FDL (>= 1.1).
 See the file COPYING for details
@@ -970,6 +972,33 @@
 branch, and you ask to merge the branch, monotone will merge them
 two-at-a-time until there is only one.
 
+@subsection Branch Names
+
+The branch names used in the above section are fine for an example, but
+they would be bad to use in a real project.  The reason is, monotone
+branch names must be @emph{globally} unique, over all branches in the
+world.  Otherwise, bad things can happen.  Fortunately, we have a handy
+source of globally unique names --- the DNS system.
+
+When naming a branch, always prepend the reversed name of a host that
+you control or are otherwise authorized to use.  For example, monotone
+development happens on the branch @code{net.venge.monotone}, because
+@code{venge.net} belongs to monotone's primary author.  The idea is that
+this way, you can coordinate with other people using a host to make sure
+there are no conflicts --- in the example, monotone's primary author can
+be certain that no-one else using @code{venge.net} will start up a
+different program named @code{monotone}.  If you work for Yoyodyne,
+Inc. (owners of yoyodyne.com), then all your branch names should look
+like @code{com.yoyodyne.@emph{something}}.
+
+What the @code{@emph{something}} part looks like is up to you, but
+usually the first part is the project name (the @code{monotone} in
+@code{net.venge.monotone}), and then possibly more stuff after that to
+describe a particular branch.  For example, monotone's win32 support
+was initially developed on the branch @code{net.venge.monotone.win32}.
+
+(For more information, see @ref{Naming Conventions}.)
+
 @node    Tutorial
 @chapter Tutorial
 
@@ -979,7 +1008,7 @@
 revision selectors.
 
 @subsection Standard Options
-Before operating monotone, two inportant command-line options should
+Before operating monotone, two important command-line options should
 be explained.
 
 @itemize
@@ -1464,7 +1493,7 @@
 
 @smallexample
 @group
-$ monotone cat manifest
+$ monotone cat manifest 2098eddbe833046174de28172a813150a6cbda7b
 3b12b2d0b31439bd50976633db1895cff8b19da0  include/jb.h
 2650ffc660dd00a08b659b883b65a060cac7e560  src/apple.c
 e8f147e5b4d5667f3228b7bba1c5c1e639f5db9f  src/banana.c
@@ -2280,7 +2309,7 @@
 vulnerabilities in a revision, you might wish to create a certificate
 called @code{x-vulnerability}.  Monotone reserves all names which do
 not begin with @code{x-} for possible internal use. If an @code{x-}
-certificate becomes widely used, montotone will likey adopt it as a
+certificate becomes widely used, monotone will likely adopt it as a
 reserved cert name and standardize its semantics.
 
 Most reserved certificate names have no meaning yet; some do. Usually
@@ -2349,11 +2378,11 @@
 
 Some names in monotone are private to your work, such as
 filenames. Other names are potentially visible outside your project,
-such as @sc{rsa} key identifiers or branch names. It is possible that
-if you choose such names carelessly, you will choose a name which
-someone else in the world is using, and subsequently you may cause
-confusion when your work and their is received simultaneously by some
-third party.
+such as @sc{rsa} key identifiers or branch names. It is possible that if
+you choose such names carelessly, you will choose a name which someone
+else in the world is using, and subsequently you may cause confusion
+when your work and theirs is received simultaneously by some third
+party.
 
 We therefore recommend two naming conventions:
 
diff -ru monotone-0.15/netsync.cc monotone-0.15-patched/netsync.cc
--- monotone-0.15/netsync.cc	Mon Nov  8 16:38:02 2004
+++ monotone-0.15-patched/netsync.cc	Tue Dec  7 20:32:51 2004
@@ -243,13 +243,13 @@
   packet_db_writer dbw;
 
   session(protocol_role role,
-	  protocol_voice voice,
-	  vector<utf8> const & collections,
-	  set<string> const & all_collections,
-	  app_state & app,
-	  string const & peer,
-	  Netxx::socket_type sock, 
-	  Netxx::Timeout const & to);
+          protocol_voice voice,
+          vector<utf8> const & collections,
+          set<string> const & all_collections,
+          app_state & app,
+          string const & peer,
+          Netxx::socket_type sock, 
+          Netxx::Timeout const & to);
 
   virtual ~session() {}
 
@@ -268,14 +268,14 @@
   void maybe_say_goodbye();
 
   void analyze_attachment(revision_id const & i, 
-			  set<revision_id> & visited,
-			  map<revision_id, bool> & attached);
+                          set<revision_id> & visited,
+                          map<revision_id, bool> & attached);
   void request_rev_revisions(revision_id const & init, 
-			     map<revision_id, bool> attached,
-			     set<revision_id> visited);
+                             map<revision_id, bool> attached,
+                             set<revision_id> visited);
   void request_fwd_revisions(revision_id const & i, 
-			     map<revision_id, bool> attached,
-			     set<revision_id> & visited);
+                             map<revision_id, bool> attached,
+                             set<revision_id> & visited);
   void analyze_ancestry_graph();
   void analyze_manifest(manifest_map const & man);
 
@@ -283,71 +283,71 @@
   bool read_some();
   bool write_some();
   void update_merkle_trees(netcmd_item_type type,
-			   hexenc<id> const & hident,
-			   bool live_p);
+                           hexenc<id> const & hident,
+                           bool live_p);
 
   void write_netcmd_and_try_flush(netcmd const & cmd);
   void queue_bye_cmd();
   void queue_error_cmd(string const & errmsg);
   void queue_done_cmd(size_t level, netcmd_item_type type);
   void queue_hello_cmd(id const & server, 
-		       id const & nonce);
+                       id const & nonce);
   void queue_anonymous_cmd(protocol_role role, 
-			   string const & collection, 
-			   id const & nonce2);
+                           string const & collection, 
+                           id const & nonce2);
   void queue_auth_cmd(protocol_role role, 
-		      string const & collection, 
-		      id const & client, 
-		      id const & nonce1, 
-		      id const & nonce2, 
-		      string const & signature);
+                      string const & collection, 
+                      id const & client, 
+                      id const & nonce1, 
+                      id const & nonce2, 
+                      string const & signature);
   void queue_confirm_cmd(string const & signature);
   void queue_refine_cmd(merkle_node const & node);
   void queue_send_data_cmd(netcmd_item_type type, 
-			   id const & item);
+                           id const & item);
   void queue_send_delta_cmd(netcmd_item_type type, 
-			    id const & base, 
-			    id const & ident);
+                            id const & base, 
+                            id const & ident);
   void queue_data_cmd(netcmd_item_type type, 
-		      id const & item,
-		      string const & dat);
+                      id const & item,
+                      string const & dat);
   void queue_delta_cmd(netcmd_item_type type, 
-		       id const & base, 
-		       id const & ident, 
-		       delta const & del);
+                       id const & base, 
+                       id const & ident, 
+                       delta const & del);
   void queue_nonexistant_cmd(netcmd_item_type type, 
-			     id const & item);
+                             id const & item);
 
   bool process_bye_cmd();
   bool process_error_cmd(string const & errmsg);
   bool process_done_cmd(size_t level, netcmd_item_type type);
   bool process_hello_cmd(id const & server, 
-			 id const & nonce);
+                         id const & nonce);
   bool process_anonymous_cmd(protocol_role role, 
-			     string const & collection, 
-			     id const & nonce2);
+                             string const & collection, 
+                             id const & nonce2);
   bool process_auth_cmd(protocol_role role, 
-			string const & collection, 
-			id const & client, 
-			id const & nonce1, 
-			id const & nonce2, 
-			string const & signature);
+                        string const & collection, 
+                        id const & client, 
+                        id const & nonce1, 
+                        id const & nonce2, 
+                        string const & signature);
   bool process_confirm_cmd(string const & signature);
   bool process_refine_cmd(merkle_node const & node);
   bool process_send_data_cmd(netcmd_item_type type,
-			     id const & item);
+                             id const & item);
   bool process_send_delta_cmd(netcmd_item_type type,
-			      id const & base, 
-			      id const & ident);
+                              id const & base, 
+                              id const & ident);
   bool process_data_cmd(netcmd_item_type type,
-			id const & item, 
-			string const & dat);
+                        id const & item, 
+                        string const & dat);
   bool process_delta_cmd(netcmd_item_type type,
-			 id const & base, 
-			 id const & ident, 
-			 delta const & del);
+                         id const & base, 
+                         id const & ident, 
+                         delta const & del);
   bool process_nonexistant_cmd(netcmd_item_type type,
-			       id const & item);
+                               id const & item);
 
   
   bool dispatch_payload(netcmd const & cmd);
@@ -381,13 +381,13 @@
 
   
 session::session(protocol_role role,
-		 protocol_voice voice,
-		 vector<utf8> const & collections,
-		 set<string> const & all_coll,
-		 app_state & app,
-		 string const & peer,
-		 Netxx::socket_type sock, 
-		 Netxx::Timeout const & to) : 
+                 protocol_voice voice,
+                 vector<utf8> const & collections,
+                 set<string> const & all_coll,
+                 app_state & app,
+                 string const & peer,
+                 Netxx::socket_type sock, 
+                 Netxx::Timeout const & to) : 
   role(role),
   voice(voice),
   collections(collections),
@@ -470,7 +470,7 @@
       j != done_refinements.end(); ++j)
     {
       if (j->second.tree_is_done == false)
-	all = false;
+        all = false;
     }
   return all;
 }
@@ -486,10 +486,10 @@
 session::got_all_data()
 {
   for (map<netcmd_item_type, boost::shared_ptr< set<id> > >::const_iterator i =
-	 requested_items.begin(); i != requested_items.end(); ++i)
+         requested_items.begin(); i != requested_items.end(); ++i)
     {
       if (! i->second->empty())
-	return false;
+        return false;
     }
   return true;
 }
@@ -549,17 +549,17 @@
        i != man.end(); ++i)
     {
       if (! this->app.db.file_version_exists(manifest_entry_id(i)))
-	{
-	  id tmp;
-	  decode_hexenc(manifest_entry_id(i).inner(), tmp);
-	  queue_send_data_cmd(file_item, tmp);
-	}
+        {
+          id tmp;
+          decode_hexenc(manifest_entry_id(i).inner(), tmp);
+          queue_send_data_cmd(file_item, tmp);
+        }
     }
 }
 
 static bool 
 is_attached(revision_id const & i, 
-	    map<revision_id, bool> const & attach_map)
+            map<revision_id, bool> const & attach_map)
 {
   map<revision_id, bool>::const_iterator j = attach_map.find(i);
   I(j != attach_map.end());
@@ -574,8 +574,8 @@
 
 void
 session::analyze_attachment(revision_id const & i, 
-			    set<revision_id> & visited,
-			    map<revision_id, bool> & attached)
+                            set<revision_id> & visited,
+                            map<revision_id, bool> & attached)
 {
   typedef map<revision_id, boost::shared_ptr< pair<revision_data, revision_set> > > ancestryT;
 
@@ -596,20 +596,19 @@
       L(F("checking attachment of %s in ancestry\n") % i);
       ancestryT::const_iterator j = ancestry.find(i);
       if (j != ancestry.end())
-	{
-	  for (edge_map::const_iterator k = j->second->second.edges.begin();
-	       k != j->second->second.edges.end(); ++k)
-	    {
-	      L(F("checking attachment of %s in parent %s\n") % i % edge_old_revision(k));
-	      analyze_attachment(edge_old_revision(k), visited, attached);
-	      if (is_attached(edge_old_revision(k), attached))
-		{
-		  L(F("revision %s is attached via parent %s\n") % i % edge_old_revision(k));
-		  curr_attached = true;
-		  break;
-		}
-	    }
-	}
+        {
+          for (edge_map::const_iterator k = j->second->second.edges.begin();
+               k != j->second->second.edges.end(); ++k)
+            {
+              L(F("checking attachment of %s in parent %s\n") % i % edge_old_revision(k));
+              analyze_attachment(edge_old_revision(k), visited, attached);
+              if (is_attached(edge_old_revision(k), attached))
+                {
+                  L(F("revision %s is attached via parent %s\n") % i % edge_old_revision(k));
+                  curr_attached = true;
+                }
+            }
+        }
     }
   L(F("decided that revision %s %s attached\n") % i % (curr_attached ? "is" : "is not"));
   attached[i] = curr_attached;
@@ -635,8 +634,8 @@
 
 void 
 session::request_rev_revisions(revision_id const & init, 
-			       map<revision_id, bool> attached,
-			       set<revision_id> visited)
+                               map<revision_id, bool> attached,
+                               set<revision_id> visited)
 {
   typedef map<revision_id, boost::shared_ptr< pair<revision_data, revision_set> > > ancestryT;
 
@@ -649,120 +648,120 @@
     {
       set<revision_id> next_frontier;
       for (set<revision_id>::const_iterator i = frontier.begin();
-	   i != frontier.end(); ++i)
-	{
-	  if (is_attached(*i, attached))
-	    continue;
-
-	  if (visited.find(*i) != visited.end())
-	    continue;
-
-	  visited.insert(*i);
-
-	  ancestryT::const_iterator j = ancestry.find(*i);
-	  if (j != ancestry.end())
-	    {
-
-	      for (edge_map::const_iterator k = j->second->second.edges.begin();
-		   k != j->second->second.edges.end(); ++k)
-		{
-
-		  next_frontier.insert(edge_old_revision(k));
-
-		  // check out the manifest delta edge
-		  manifest_id parent_manifest = edge_old_manifest(k);
-		  manifest_id child_manifest = j->second->second.new_manifest;	
-
-		  // first, if we have a child we've never seen before we will need
-		  // to request it in its entrety.		  
-		  if (seen_manifests.find(child_manifest) == seen_manifests.end())
-		    {
-		      if (this->app.db.manifest_version_exists(child_manifest))
-			L(F("not requesting (in reverse) initial manifest %s as we already have it\n") % child_manifest);
-		      else
-			{
-			  L(F("requesting (in reverse) initial manifest data %s\n") % child_manifest);
-			  queue_send_data_cmd(manifest_item, plain_id(child_manifest));
-			}
-		      seen_manifests.insert(child_manifest);
-		    }
-
-		  // second, if the parent is nonempty, we want to ask for an edge to it		  
-		  if (!parent_manifest.inner()().empty())
-		    {
-		      if (this->app.db.manifest_version_exists(parent_manifest))
-			L(F("not requesting (in reverse) manifest delta to %s as we already have it\n") % parent_manifest);
-		      else
-			{
-			  L(F("requesting (in reverse) manifest delta %s -> %s\n") 
-			    % child_manifest % parent_manifest);
-			  reverse_delta_requests.insert(make_pair(plain_id(child_manifest),
-								  plain_id(parent_manifest)));
-			  queue_send_delta_cmd(manifest_item, 
-					       plain_id(child_manifest), 
-					       plain_id(parent_manifest));
-			}
-		      seen_manifests.insert(parent_manifest);
-		    }
-
-
-		  
-		  // check out each file delta edge
-		  change_set const & cset = edge_changes(k);
-		  for (change_set::delta_map::const_iterator d = cset.deltas.begin(); 
-		       d != cset.deltas.end(); ++d)
-		    {
-		      file_id parent_file (delta_entry_src(d));
-		      file_id child_file (delta_entry_dst(d));
-
-
-		      // first, if we have a child we've never seen before we will need
-		      // to request it in its entrety.		  
-		      if (seen_files.find(child_file) == seen_files.end())
-			{
-			  if (this->app.db.file_version_exists(child_file))
-			    L(F("not requesting (in reverse) initial file %s as we already have it\n") % child_file);
-			  else
-			    {
-			      L(F("requesting (in reverse) initial file data %s\n") % child_file);
-			      queue_send_data_cmd(file_item, plain_id(child_file));
-			    }
-			  seen_files.insert(child_file);
-			}
-		      
-		      // second, if the parent is nonempty, we want to ask for an edge to it		  
-		      if (!parent_file.inner()().empty())
-			{
-			  if (this->app.db.file_version_exists(parent_file))
-			    L(F("not requesting (in reverse) file delta to %s as we already have it\n") % parent_file);
-			  else
-			    {
-			      L(F("requesting (in reverse) file delta %s -> %s on %s\n") 
-				% child_file % parent_file % delta_entry_path(d));
-			      reverse_delta_requests.insert(make_pair(plain_id(child_file),
-								      plain_id(parent_file)));
-			      queue_send_delta_cmd(file_item, 
-						   plain_id(child_file), 
-						   plain_id(parent_file));
-			    }
-			  seen_files.insert(parent_file);
-			}		      
-		    }
-		}
-	      
-	      // now actually consume the data packet, which will wait on the
-	      // arrival of its prerequisites in the packet_db_writer
-	      this->dbw.consume_revision_data(j->first, j->second->first);
-	    }
-	}
+           i != frontier.end(); ++i)
+        {
+          if (is_attached(*i, attached))
+            continue;
+
+          if (visited.find(*i) != visited.end())
+            continue;
+
+          visited.insert(*i);
+
+          ancestryT::const_iterator j = ancestry.find(*i);
+          if (j != ancestry.end())
+            {
+
+              for (edge_map::const_iterator k = j->second->second.edges.begin();
+                   k != j->second->second.edges.end(); ++k)
+                {
+
+                  next_frontier.insert(edge_old_revision(k));
+
+                  // check out the manifest delta edge
+                  manifest_id parent_manifest = edge_old_manifest(k);
+                  manifest_id child_manifest = j->second->second.new_manifest;  
+
+                  // first, if we have a child we've never seen before we will need
+                  // to request it in its entrety.                
+                  if (seen_manifests.find(child_manifest) == seen_manifests.end())
+                    {
+                      if (this->app.db.manifest_version_exists(child_manifest))
+                        L(F("not requesting (in reverse) initial manifest %s as we already have it\n") % child_manifest);
+                      else
+                        {
+                          L(F("requesting (in reverse) initial manifest data %s\n") % child_manifest);
+                          queue_send_data_cmd(manifest_item, plain_id(child_manifest));
+                        }
+                      seen_manifests.insert(child_manifest);
+                    }
+
+                  // second, if the parent is nonempty, we want to ask for an edge to it                  
+                  if (!parent_manifest.inner()().empty())
+                    {
+                      if (this->app.db.manifest_version_exists(parent_manifest))
+                        L(F("not requesting (in reverse) manifest delta to %s as we already have it\n") % parent_manifest);
+                      else
+                        {
+                          L(F("requesting (in reverse) manifest delta %s -> %s\n") 
+                            % child_manifest % parent_manifest);
+                          reverse_delta_requests.insert(make_pair(plain_id(child_manifest),
+                                                                  plain_id(parent_manifest)));
+                          queue_send_delta_cmd(manifest_item, 
+                                               plain_id(child_manifest), 
+                                               plain_id(parent_manifest));
+                        }
+                      seen_manifests.insert(parent_manifest);
+                    }
+
+
+                  
+                  // check out each file delta edge
+                  change_set const & cset = edge_changes(k);
+                  for (change_set::delta_map::const_iterator d = cset.deltas.begin(); 
+                       d != cset.deltas.end(); ++d)
+                    {
+                      file_id parent_file (delta_entry_src(d));
+                      file_id child_file (delta_entry_dst(d));
+
+
+                      // first, if we have a child we've never seen before we will need
+                      // to request it in its entrety.            
+                      if (seen_files.find(child_file) == seen_files.end())
+                        {
+                          if (this->app.db.file_version_exists(child_file))
+                            L(F("not requesting (in reverse) initial file %s as we already have it\n") % child_file);
+                          else
+                            {
+                              L(F("requesting (in reverse) initial file data %s\n") % child_file);
+                              queue_send_data_cmd(file_item, plain_id(child_file));
+                            }
+                          seen_files.insert(child_file);
+                        }
+                      
+                      // second, if the parent is nonempty, we want to ask for an edge to it              
+                      if (!parent_file.inner()().empty())
+                        {
+                          if (this->app.db.file_version_exists(parent_file))
+                            L(F("not requesting (in reverse) file delta to %s as we already have it\n") % parent_file);
+                          else
+                            {
+                              L(F("requesting (in reverse) file delta %s -> %s on %s\n") 
+                                % child_file % parent_file % delta_entry_path(d));
+                              reverse_delta_requests.insert(make_pair(plain_id(child_file),
+                                                                      plain_id(parent_file)));
+                              queue_send_delta_cmd(file_item, 
+                                                   plain_id(child_file), 
+                                                   plain_id(parent_file));
+                            }
+                          seen_files.insert(parent_file);
+                        }                     
+                    }
+                }
+              
+              // now actually consume the data packet, which will wait on the
+              // arrival of its prerequisites in the packet_db_writer
+              this->dbw.consume_revision_data(j->first, j->second->first);
+            }
+        }
       frontier = next_frontier;
     }
 }
 
 void 
 session::request_fwd_revisions(revision_id const & i, 
-			       map<revision_id, bool> attached,
-			       set<revision_id> & visited)
+                               map<revision_id, bool> attached,
+                               set<revision_id> & visited)
 {
   if (visited.find(i) != visited.end())
     return;
@@ -776,72 +775,72 @@
   ancestryT::const_iterator j = ancestry.find(i);
   if (j != ancestry.end())
     {
-      edge_map::const_iterator first_attached_edge = j->second->second.edges.end();
+      edge_map::const_iterator an_attached_edge = j->second->second.edges.end();
 
       // first make sure we've requested enough to get to here by
       // calling ourselves recursively. this is the forward path after all.
 
       for (edge_map::const_iterator k = j->second->second.edges.begin();
-	   k != j->second->second.edges.end(); ++k)
-	{
-	  if (is_attached(edge_old_revision(k), attached))
-	    {
-	      request_fwd_revisions(edge_old_revision(k), attached, visited);
-	      first_attached_edge = k;
-	    }
-	}
+           k != j->second->second.edges.end(); ++k)
+        {
+          if (is_attached(edge_old_revision(k), attached))
+            {
+              request_fwd_revisions(edge_old_revision(k), attached, visited);
+              an_attached_edge = k;
+            }
+        }
       
-      I(first_attached_edge != j->second->second.edges.end());
+      I(an_attached_edge != j->second->second.edges.end());
       
       // check out the manifest delta edge
-      manifest_id parent_manifest = edge_old_manifest(first_attached_edge);
-      manifest_id child_manifest = j->second->second.new_manifest;	
+      manifest_id parent_manifest = edge_old_manifest(an_attached_edge);
+      manifest_id child_manifest = j->second->second.new_manifest;      
       if (this->app.db.manifest_version_exists(child_manifest))
-	L(F("not requesting forward manifest delta to '%s' as we already have it\n") 
-	  % child_manifest);
+        L(F("not requesting forward manifest delta to '%s' as we already have it\n") 
+          % child_manifest);
       else
-	{
-	  if (parent_manifest.inner()().empty())
-	    {
-	      L(F("requesting full manifest data %s\n") % child_manifest);
-	      queue_send_data_cmd(manifest_item, plain_id(child_manifest));
-	    }
-	  else
-	    {
-	      L(F("requesting forward manifest delta %s -> %s\n")
-		% parent_manifest % child_manifest);
-	      queue_send_delta_cmd(manifest_item, 
-				   plain_id(parent_manifest), 
-				   plain_id(child_manifest));
-	    }
-	}
+        {
+          if (parent_manifest.inner()().empty())
+            {
+              L(F("requesting full manifest data %s\n") % child_manifest);
+              queue_send_data_cmd(manifest_item, plain_id(child_manifest));
+            }
+          else
+            {
+              L(F("requesting forward manifest delta %s -> %s\n")
+                % parent_manifest % child_manifest);
+              queue_send_delta_cmd(manifest_item, 
+                                   plain_id(parent_manifest), 
+                                   plain_id(child_manifest));
+            }
+        }
 
       // check out each file delta edge
-      change_set const & first_attached_cset = first_attached_edge->second.second;
-      for (change_set::delta_map::const_iterator k = first_attached_cset.deltas.begin();
-	   k != first_attached_cset.deltas.end(); ++k)
-	{
-	  if (this->app.db.file_version_exists(delta_entry_dst(k)))
-	    L(F("not requesting forward delta %s -> %s on file %s as we already have it\n")
-	      % delta_entry_src(k) % delta_entry_dst(k) % delta_entry_path(k));
-	  else
-	    {
-	      if (delta_entry_src(k).inner()().empty())
-		{
-		  L(F("requesting full file data %s\n") % delta_entry_dst(k));
-		  queue_send_data_cmd(file_item, plain_id(delta_entry_dst(k)));
-		}
-	      else
-		{
-		  
-		  L(F("requesting forward delta %s -> %s on file %s\n")
-		    % delta_entry_src(k) % delta_entry_dst(k) % delta_entry_path(k));
-		  queue_send_delta_cmd(file_item, 
-				       plain_id(delta_entry_src(k)), 
-				       plain_id(delta_entry_dst(k)));
-		}
-	    }
-	}
+      change_set const & an_attached_cset = an_attached_edge->second.second;
+      for (change_set::delta_map::const_iterator k = an_attached_cset.deltas.begin();
+           k != an_attached_cset.deltas.end(); ++k)
+        {
+          if (this->app.db.file_version_exists(delta_entry_dst(k)))
+            L(F("not requesting forward delta %s -> %s on file %s as we already have it\n")
+              % delta_entry_src(k) % delta_entry_dst(k) % delta_entry_path(k));
+          else
+            {
+              if (delta_entry_src(k).inner()().empty())
+                {
+                  L(F("requesting full file data %s\n") % delta_entry_dst(k));
+                  queue_send_data_cmd(file_item, plain_id(delta_entry_dst(k)));
+                }
+              else
+                {
+                  
+                  L(F("requesting forward delta %s -> %s on file %s\n")
+                    % delta_entry_src(k) % delta_entry_dst(k) % delta_entry_path(k));
+                  queue_send_delta_cmd(file_item, 
+                                       plain_id(delta_entry_src(k)), 
+                                       plain_id(delta_entry_dst(k)));
+                }
+            }
+        }
       // now actually consume the data packet, which will wait on the
       // arrival of its prerequisites in the packet_db_writer
       this->dbw.consume_revision_data(j->first, j->second->first);
@@ -866,17 +865,17 @@
     
     for (ancestryT::const_iterator i = ancestry.begin(); i != ancestry.end(); ++i)
       {
-	nodes.insert(i->first);
-	for (edge_map::const_iterator j = i->second->second.edges.begin();
-	     j != i->second->second.edges.end(); ++j)
-	  {
-	    parents.insert(edge_old_revision(j));
-	  }
+        nodes.insert(i->first);
+        for (edge_map::const_iterator j = i->second->second.edges.begin();
+             j != i->second->second.edges.end(); ++j)
+          {
+            parents.insert(edge_old_revision(j));
+          }
       }
     
     set_difference(nodes.begin(), nodes.end(),
-		   parents.begin(), parents.end(),
-		   inserter(heads, heads.begin()));
+                   parents.begin(), parents.end(),
+                   inserter(heads, heads.begin()));
   }
 
   L(F("isolated %d heads\n") % heads.size());
@@ -903,15 +902,15 @@
       I(k != attached.end());
       
       if (k->second)
-	{
-	  L(F("requesting attached ancestry of revision '%s'\n") % *i);
-	  request_fwd_revisions(*i, attached, fwd_visited);
-	}
+        {
+          L(F("requesting attached ancestry of revision '%s'\n") % *i);
+          request_fwd_revisions(*i, attached, fwd_visited);
+        }
       else
-	{
-	  L(F("requesting detached ancestry of revision '%s'\n") % *i);
-	  request_rev_revisions(*i, attached, rev_visited);
-	}	
+        {
+          L(F("requesting detached ancestry of revision '%s'\n") % *i);
+          request_rev_revisions(*i, attached, rev_visited);
+        }       
     }
   analyzed_ancestry = true;
 }
@@ -922,17 +921,17 @@
   if (outbuf.empty())
     {
       if (inbuf.size() < constants::netcmd_maxsz)
-	return Netxx::Probe::ready_read | Netxx::Probe::ready_oobd;
+        return Netxx::Probe::ready_read | Netxx::Probe::ready_oobd;
       else
-	return Netxx::Probe::ready_oobd;
+        return Netxx::Probe::ready_oobd;
     }
   else
     {
       if (inbuf.size() < constants::netcmd_maxsz)
-	return Netxx::Probe::ready_write | Netxx::Probe::ready_read | Netxx::Probe::ready_oobd;
+        return Netxx::Probe::ready_write | Netxx::Probe::ready_read | Netxx::Probe::ready_oobd;
       else
-	return Netxx::Probe::ready_write | Netxx::Probe::ready_oobd;
-    }	    
+        return Netxx::Probe::ready_write | Netxx::Probe::ready_oobd;
+    }       
 }
 
 bool 
@@ -947,7 +946,7 @@
       inbuf.append(string(tmp, tmp + count));
       mark_recent_io();
       if (in_ticker != NULL)
-	(*in_ticker) += count;
+        (*in_ticker) += count;
       return true;
     }
   else
@@ -959,15 +958,15 @@
 {
   I(!outbuf.empty());    
   Netxx::signed_size_type count = str.write(outbuf.data(), 
-					    std::min(outbuf.size(), constants::bufsz));
+                                            std::min(outbuf.size(), constants::bufsz));
   if(count > 0)
     {
       outbuf.erase(0, count);
       L(F("wrote %d bytes to fd %d (peer %s), %d remain in output buffer\n") 
-	% count % fd % peer_id % outbuf.size());
+        % count % fd % peer_id % outbuf.size());
       mark_recent_io();
       if (out_ticker != NULL)
-	(*out_ticker) += count;
+        (*out_ticker) += count;
       return true;
     }
   else
@@ -998,7 +997,7 @@
 
 void 
 session::queue_done_cmd(size_t level, 
-			netcmd_item_type type) 
+                        netcmd_item_type type) 
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -1011,7 +1010,7 @@
 
 void 
 session::queue_hello_cmd(id const & server, 
-			 id const & nonce) 
+                         id const & nonce) 
 {
   netcmd cmd;
   cmd.cmd_code = hello_cmd;
@@ -1021,8 +1020,8 @@
 
 void 
 session::queue_anonymous_cmd(protocol_role role, 
-			     string const & collection, 
-			     id const & nonce2)
+                             string const & collection, 
+                             id const & nonce2)
 {
   netcmd cmd;
   cmd.cmd_code = anonymous_cmd;
@@ -1032,17 +1031,17 @@
 
 void 
 session::queue_auth_cmd(protocol_role role, 
-			string const & collection, 
-			id const & client, 
-			id const & nonce1, 
-			id const & nonce2, 
-			string const & signature)
+                        string const & collection, 
+                        id const & client, 
+                        id const & nonce1, 
+                        id const & nonce2, 
+                        string const & signature)
 {
   netcmd cmd;
   cmd.cmd_code = auth_cmd;
   write_auth_cmd_payload(role, collection, client, 
-			 nonce1, nonce2, signature, 
-			 cmd.payload);
+                         nonce1, nonce2, signature, 
+                         cmd.payload);
   write_netcmd_and_try_flush(cmd);
 }
 
@@ -1072,7 +1071,7 @@
 
 void 
 session::queue_send_data_cmd(netcmd_item_type type,
-			     id const & item)
+                             id const & item)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -1082,14 +1081,14 @@
   if (role == source_role)
     {
       L(F("not queueing request for %s '%s' as we are in pure source role\n") 
-	% typestr % hid);
+        % typestr % hid);
       return;
     }
 
   if (item_request_outstanding(type, item))
     {
       L(F("not queueing request for %s '%s' as we already requested it\n") 
-	% typestr % hid);
+        % typestr % hid);
       return;
     }
 
@@ -1104,8 +1103,8 @@
     
 void 
 session::queue_send_delta_cmd(netcmd_item_type type,
-			      id const & base, 
-			      id const & ident)
+                              id const & base, 
+                              id const & ident)
 {
   I(type == manifest_item || type == file_item);
 
@@ -1119,14 +1118,14 @@
   if (role == source_role)
     {
       L(F("not queueing request for %s delta '%s' -> '%s' as we are in pure source role\n") 
-	% typestr % base_hid % ident_hid);
+        % typestr % base_hid % ident_hid);
       return;
     }
 
   if (item_request_outstanding(type, ident))
     {
       L(F("not queueing request for %s delta '%s' -> '%s' as we already requested the target\n") 
-	% typestr % base_hid % ident_hid);
+        % typestr % base_hid % ident_hid);
       return;
     }
 
@@ -1141,8 +1140,8 @@
 
 void 
 session::queue_data_cmd(netcmd_item_type type,
-			id const & item, 
-			string const & dat)
+                        id const & item, 
+                        string const & dat)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -1152,7 +1151,7 @@
   if (role == sink_role)
     {
       L(F("not queueing %s data for '%s' as we are in pure sink role\n") 
-	% typestr % hid);
+        % typestr % hid);
       return;
     }
 
@@ -1166,9 +1165,9 @@
 
 void
 session::queue_delta_cmd(netcmd_item_type type,
-			 id const & base, 
-			 id const & ident, 
-			 delta const & del)
+                         id const & base, 
+                         id const & ident, 
+                         delta const & del)
 {
   I(type == manifest_item || type == file_item);
   I(! del().empty() || ident == base);
@@ -1182,7 +1181,7 @@
   if (role == sink_role)
     {
       L(F("not queueing %s delta '%s' -> '%s' as we are in pure sink role\n") 
-	% typestr % base_hid % ident_hid);
+        % typestr % base_hid % ident_hid);
       return;
     }
 
@@ -1196,7 +1195,7 @@
 
 void 
 session::queue_nonexistant_cmd(netcmd_item_type type,
-			       id const & item)
+                               id const & item)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -1205,7 +1204,7 @@
   if (role == sink_role)
     {
       L(F("not queueing note of nonexistence of %s item '%s' as we are in pure sink role\n") 
-	% typestr % hid);
+        % typestr % hid);
       return;
     }
 
@@ -1250,18 +1249,18 @@
       // we received *no* refinements on this level -- or we ran out of
       // levels -- so refinement for this type is finished.
       L(F("received 'done' for empty %s level %d, marking as complete\n") 
-	% typestr % static_cast<int>(level));
+        % typestr % static_cast<int>(level));
 
       // possibly echo it back one last time, for shutdown purposes
       if (!i->second.tree_is_done)
-	queue_done_cmd(level + 1, type);
+        queue_done_cmd(level + 1, type);
 
       // tombstone it
       i->second.current_level_had_refinements = false;
       i->second.tree_is_done = true;
 
       if (all_requested_revisions_received())
-	analyze_ancestry_graph();      
+        analyze_ancestry_graph();      
     }
 
   else if (i->second.current_level_had_refinements 
@@ -1270,10 +1269,10 @@
       // we *did* receive some refinements on this level, reset to zero and
       // queue an echo of the 'done' marker.
       L(F("received 'done' for %s level %d, which had refinements; "
-	  "sending echo of done for level %d\n") 
-	% typestr 
-	% static_cast<int>(level) 
-	% static_cast<int>(level + 1));
+          "sending echo of done for level %d\n") 
+        % typestr 
+        % static_cast<int>(level) 
+        % static_cast<int>(level + 1));
       i->second.current_level_had_refinements = false;
       queue_done_cmd(level + 1, type);
       return true;
@@ -1283,7 +1282,7 @@
 
 bool 
 session::process_hello_cmd(id const & server, 
-			   id const & nonce) 
+                           id const & nonce) 
 {
   I(this->remote_peer_key_hash().size() == 0);
   I(this->saved_nonce().size() == 0);
@@ -1302,44 +1301,44 @@
       this->remote_peer_key_hash = server;
       
       if (app.signing_key() != "")
-	{
-	  // get our public key for its hash identifier
-	  base64<rsa_pub_key> our_pub;
-	  hexenc<id> our_key_hash;
-	  id our_key_hash_raw;
-	  app.db.get_key(app.signing_key, our_pub);
-	  key_hash_code(app.signing_key, our_pub, our_key_hash);
-	  decode_hexenc(our_key_hash, our_key_hash_raw);
-	  
-	  // get our private key and make a signature
-	  base64<rsa_sha1_signature> sig;
-	  rsa_sha1_signature sig_raw;
-	  base64< arc4<rsa_priv_key> > our_priv;
-	  app.db.get_key(app.signing_key, our_priv);
-	  make_signature(app.lua, app.signing_key, our_priv, nonce(), sig);
-	  decode_base64(sig, sig_raw);
-	  
-	  // make a new nonce of our own and send off the 'auth'
-	  queue_auth_cmd(this->role, this->collection(), our_key_hash_raw, 
-			 nonce, mk_nonce(), sig_raw());
-	}
+        {
+          // get our public key for its hash identifier
+          base64<rsa_pub_key> our_pub;
+          hexenc<id> our_key_hash;
+          id our_key_hash_raw;
+          app.db.get_key(app.signing_key, our_pub);
+          key_hash_code(app.signing_key, our_pub, our_key_hash);
+          decode_hexenc(our_key_hash, our_key_hash_raw);
+          
+          // get our private key and make a signature
+          base64<rsa_sha1_signature> sig;
+          rsa_sha1_signature sig_raw;
+          base64< arc4<rsa_priv_key> > our_priv;
+          app.db.get_key(app.signing_key, our_priv);
+          make_signature(app.lua, app.signing_key, our_priv, nonce(), sig);
+          decode_base64(sig, sig_raw);
+          
+          // make a new nonce of our own and send off the 'auth'
+          queue_auth_cmd(this->role, this->collection(), our_key_hash_raw, 
+                         nonce, mk_nonce(), sig_raw());
+        }
       else
-	{
-	  queue_anonymous_cmd(this->role, this->collection(), mk_nonce());
-	}
+        {
+          queue_anonymous_cmd(this->role, this->collection(), mk_nonce());
+        }
       return true;
     }
   else
     {
-      W(F("unknown server key\n"));
+      W(F("unknown server key.  disconnecting.\n"));
     }
   return false;
 }
 
 bool 
 session::process_anonymous_cmd(protocol_role role, 
-			       string const & collection, 
-			       id const & nonce2)
+                               string const & collection, 
+                               id const & nonce2)
 {
   hexenc<id> hnonce2;
   encode_hexenc(nonce2, hnonce2);
@@ -1347,7 +1346,7 @@
   L(F("received 'anonymous' netcmd from client for collection '%s' "
       "in %s mode with nonce2 '%s'\n")
     %  collection % (role == source_and_sink_role ? "source and sink" :
-		     (role == source_role ? "source " : "sink"))
+                     (role == source_role ? "source " : "sink"))
     % hnonce2);
 
   // check they're asking for a collection we're serving
@@ -1356,16 +1355,16 @@
        i != collections.end(); ++i)
     {
       if (*i == collection)
-	{
-	  collection_ok = true;
-	  break;
-	}
+        {
+          collection_ok = true;
+          break;
+        }
     }
   if (!collection_ok)
     {
       W(F("not currently serving requested collection '%s'\n") % collection);
       this->saved_nonce = id("");
-      return false;	  
+      return false;       
     }
   
   //
@@ -1389,7 +1388,7 @@
     }
 
   if (! ((this->role == source_role || this->role == source_and_sink_role)
-	 && app.lua.hook_get_netsync_anonymous_read_permitted(collection)))
+         && app.lua.hook_get_netsync_anonymous_read_permitted(collection)))
     {
       W(F("anonymous read permission denied for '%s'\n") % collection);
       this->saved_nonce = id("");
@@ -1413,11 +1412,11 @@
 
 bool 
 session::process_auth_cmd(protocol_role role, 
-			  string const & collection, 
-			  id const & client, 
-			  id const & nonce1, 
-			  id const & nonce2, 
-			  string const & signature)
+                          string const & collection, 
+                          id const & client, 
+                          id const & nonce1, 
+                          id const & nonce2, 
+                          string const & signature)
 {
   I(this->remote_peer_key_hash().size() == 0);
   I(this->saved_nonce().size() == constants::merkle_hash_length_in_bytes);
@@ -1431,7 +1430,7 @@
   L(F("received 'auth' netcmd from client '%s' for collection '%s' "
       "in %s mode with nonce1 '%s' and nonce2 '%s'\n")
     % their_key_hash % collection % (role == source_and_sink_role ? "source and sink" :
-				     (role == source_role ? "source " : "sink"))
+                                     (role == source_role ? "source " : "sink"))
     % hnonce1 % hnonce2);
   
   // check that they replied with the nonce we asked for
@@ -1448,16 +1447,16 @@
        i != collections.end(); ++i)
     {
       if (*i == collection)
-	{
-	  collection_ok = true;
-	  break;
-	}
+        {
+          collection_ok = true;
+          break;
+        }
     }
   if (!collection_ok)
     {
       W(F("not currently serving requested collection '%s'\n") % collection);
       this->saved_nonce = id("");
-      return false;	  
+      return false;       
     }
 
   //
@@ -1488,25 +1487,25 @@
   if (role == sink_role || role == source_and_sink_role)
     {
       if (! ((this->role == source_role || this->role == source_and_sink_role)
-	     && app.lua.hook_get_netsync_read_permitted(collection, 
-							their_id())))
-	{
-	  W(F("read permission denied for '%s'\n") % collection);
-	  this->saved_nonce = id("");
-	  return false;
-	}
+             && app.lua.hook_get_netsync_read_permitted(collection, 
+                                                        their_id())))
+        {
+          W(F("read permission denied for '%s'\n") % collection);
+          this->saved_nonce = id("");
+          return false;
+        }
     }
   
   if (role == source_role || role == source_and_sink_role)
     {
       if (! ((this->role == sink_role || this->role == source_and_sink_role)
-	     && app.lua.hook_get_netsync_write_permitted(collection, 
-							 their_id())))
-	{
-	  W(F("write permission denied for '%s'\n") % collection);
-	  this->saved_nonce = id("");
-	  return false;
-	}
+             && app.lua.hook_get_netsync_write_permitted(collection, 
+                                                         their_id())))
+        {
+          W(F("write permission denied for '%s'\n") % collection);
+          this->saved_nonce = id("");
+          return false;
+        }
     }
   
   // save their identity 
@@ -1530,24 +1529,24 @@
       this->authenticated = true;
       // assume the (possibly degraded) opposite role
       switch (role)
-	{
-	case source_role:
-	  I(this->role != source_role);
-	  this->role = sink_role;
-	  break;
-	case source_and_sink_role:
-	  I(this->role == source_and_sink_role);
-	  break;
-	case sink_role:
-	  I(this->role != sink_role);
-	  this->role = source_role;
-	  break;	  
-	}
+        {
+        case source_role:
+          I(this->role != source_role);
+          this->role = sink_role;
+          break;
+        case source_and_sink_role:
+          I(this->role == source_and_sink_role);
+          break;
+        case sink_role:
+          I(this->role != sink_role);
+          this->role = source_role;
+          break;          
+        }
       return true;
     }
   else
     {
-      W(F("bad client signature\n"));	      
+      W(F("bad client signature\n"));         
     }  
   return false;
 }
@@ -1564,7 +1563,7 @@
   // nb. this->role is our role, the server is in the opposite role
   L(F("received 'confirm' netcmd from server '%s' for collection '%s' in %s mode\n")
     % their_key_hash % this->collection % (this->role == source_and_sink_role ? "source and sink" :
-					   (this->role == source_role ? "sink" : "source")));
+                                           (this->role == source_role ? "sink" : "source")));
   
   // check their signature
   if (app.db.public_key_exists(their_key_hash))
@@ -1576,31 +1575,31 @@
       base64<rsa_sha1_signature> sig;
       encode_base64(rsa_sha1_signature(signature), sig);
       if (check_signature(app.lua, their_id, their_key, this->saved_nonce(), sig))
-	{
-	  L(F("server signature OK, accepting authentication\n"));
-	  this->authenticated = true;
-	  merkle_node root;
-	  load_merkle_node(app, key_item, this->collection, 0, get_root_prefix().val, root);
-	  queue_refine_cmd(root);
-	  queue_done_cmd(0, key_item);
-
-	  load_merkle_node(app, rcert_item, this->collection, 0, get_root_prefix().val, root);
-	  queue_refine_cmd(root);
-	  queue_done_cmd(0, rcert_item);
-
-	  load_merkle_node(app, mcert_item, this->collection, 0, get_root_prefix().val, root);
-	  queue_refine_cmd(root);
-	  queue_done_cmd(0, mcert_item);
-
-	  load_merkle_node(app, fcert_item, this->collection, 0, get_root_prefix().val, root);
-	  queue_refine_cmd(root);
-	  queue_done_cmd(0, fcert_item);
-	  return true;
-	}
+        {
+          L(F("server signature OK, accepting authentication\n"));
+          this->authenticated = true;
+          merkle_node root;
+          load_merkle_node(app, key_item, this->collection, 0, get_root_prefix().val, root);
+          queue_refine_cmd(root);
+          queue_done_cmd(0, key_item);
+
+          load_merkle_node(app, rcert_item, this->collection, 0, get_root_prefix().val, root);
+          queue_refine_cmd(root);
+          queue_done_cmd(0, rcert_item);
+
+          load_merkle_node(app, mcert_item, this->collection, 0, get_root_prefix().val, root);
+          queue_refine_cmd(root);
+          queue_done_cmd(0, mcert_item);
+
+          load_merkle_node(app, fcert_item, this->collection, 0, get_root_prefix().val, root);
+          queue_refine_cmd(root);
+          queue_done_cmd(0, fcert_item);
+          return true;
+        }
       else
-	{
-	  W(F("bad server signature\n"));	      
-	}
+        {
+          W(F("bad server signature\n"));             
+        }
     }
   else
     {
@@ -1611,8 +1610,8 @@
 
 static bool 
 data_exists(netcmd_item_type type, 
-	    id const & item, 
-	    app_state & app)
+            id const & item, 
+            app_state & app)
 {
   hexenc<id> hitem;
   encode_hexenc(item, hitem);
@@ -1638,9 +1637,9 @@
 
 static void 
 load_data(netcmd_item_type type, 
-	  id const & item, 
-	  app_state & app, 
-	  string & out)
+          id const & item, 
+          app_state & app, 
+          string & out)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -1650,104 +1649,104 @@
     {
     case key_item:
       if (app.db.public_key_exists(hitem))
-	{
-	  rsa_keypair_id keyid;
-	  base64<rsa_pub_key> pub_encoded;
-	  app.db.get_pubkey(hitem, keyid, pub_encoded);
-	  L(F("public key '%s' is also called '%s'\n") % hitem % keyid);
-	  write_pubkey(keyid, pub_encoded, out);
-	}
+        {
+          rsa_keypair_id keyid;
+          base64<rsa_pub_key> pub_encoded;
+          app.db.get_pubkey(hitem, keyid, pub_encoded);
+          L(F("public key '%s' is also called '%s'\n") % hitem % keyid);
+          write_pubkey(keyid, pub_encoded, out);
+        }
       else
-	{
-	  throw bad_decode(F("public key '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("public key '%s' does not exist in our database") % hitem);
+        }
       break;
 
     case revision_item:
       if (app.db.revision_exists(revision_id(hitem)))
-	{
-	  revision_data mdat;
-	  data dat;
-	  app.db.get_revision(revision_id(hitem), mdat);
-	  unpack(mdat.inner(), dat);
-	  out = dat();
-	}
+        {
+          revision_data mdat;
+          data dat;
+          app.db.get_revision(revision_id(hitem), mdat);
+          unpack(mdat.inner(), dat);
+          out = dat();
+        }
       else
-	{
-	  throw bad_decode(F("revision '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("revision '%s' does not exist in our database") % hitem);
+        }
       break;
 
     case manifest_item:
       if (app.db.manifest_version_exists(manifest_id(hitem)))
-	{
-	  manifest_data mdat;
-	  data dat;
-	  app.db.get_manifest_version(manifest_id(hitem), mdat);
-	  unpack(mdat.inner(), dat);
-	  out = dat();
-	}
+        {
+          manifest_data mdat;
+          data dat;
+          app.db.get_manifest_version(manifest_id(hitem), mdat);
+          unpack(mdat.inner(), dat);
+          out = dat();
+        }
       else
-	{
-	  throw bad_decode(F("manifest '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("manifest '%s' does not exist in our database") % hitem);
+        }
       break;
 
     case file_item:
       if (app.db.file_version_exists(file_id(hitem)))
-	{
-	  file_data fdat;
-	  data dat;
-	  app.db.get_file_version(file_id(hitem), fdat);
-	  unpack(fdat.inner(), dat);
-	  out = dat();
-	}
+        {
+          file_data fdat;
+          data dat;
+          app.db.get_file_version(file_id(hitem), fdat);
+          unpack(fdat.inner(), dat);
+          out = dat();
+        }
       else
-	{
-	  throw bad_decode(F("file '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("file '%s' does not exist in our database") % hitem);
+        }
       break;
 
     case rcert_item:
       if(app.db.revision_cert_exists(hitem))
-	{
-	  revision<cert> c;
-	  app.db.get_revision_cert(hitem, c);
-	  string tmp;
-	  write_cert(c.inner(), out);
-	}
+        {
+          revision<cert> c;
+          app.db.get_revision_cert(hitem, c);
+          string tmp;
+          write_cert(c.inner(), out);
+        }
       else
-	{
-	  throw bad_decode(F("rcert '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("rcert '%s' does not exist in our database") % hitem);
+        }
       break;
 
     case mcert_item:
       if(app.db.manifest_cert_exists(hitem))
-	{
-	  manifest<cert> c;
-	  app.db.get_manifest_cert(hitem, c);
-	  string tmp;
-	  write_cert(c.inner(), out);
-	}
+        {
+          manifest<cert> c;
+          app.db.get_manifest_cert(hitem, c);
+          string tmp;
+          write_cert(c.inner(), out);
+        }
       else
-	{
-	  throw bad_decode(F("mcert '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("mcert '%s' does not exist in our database") % hitem);
+        }
       break;
 
     case fcert_item:
       if(app.db.file_cert_exists(hitem))
-	{
-	  file<cert> c;
-	  app.db.get_file_cert(hitem, c);
-	  string tmp;
-	  write_cert(c.inner(), out);
-	}
+        {
+          file<cert> c;
+          app.db.get_file_cert(hitem, c);
+          string tmp;
+          write_cert(c.inner(), out);
+        }
       else
-	{
-	  throw bad_decode(F("fcert '%s' does not exist in our database") % hitem);
-	}
+        {
+          throw bad_decode(F("fcert '%s' does not exist in our database") % hitem);
+        }
       break;
     }
 }
@@ -1767,372 +1766,372 @@
     % typestr % hpref % lev);
   
   if (!app.db.merkle_node_exists(typestr, this->collection, 
-				 their_node.level, hpref))
+                                 their_node.level, hpref))
     {
       L(F("no corresponding %s merkle node for prefix '%s', level %d\n")
-	% typestr % hpref % lev);
+        % typestr % hpref % lev);
 
       for (size_t slot = 0; slot < constants::merkle_num_slots; ++slot)
-	{
-	  switch (their_node.get_slot_state(slot))
-	    {
-	    case empty_state:
-	      {
-		// we agree, this slot is empty
-		L(F("(#0) they have an empty slot %d (in a %s node '%s', level %d, we do not have)\n")
-		  % slot % typestr % hpref % lev);
-		continue;
-	      }
-	      break;
-	    case live_leaf_state:
-	      {
-		// we want what *they* have
-		id slotval;
-		hexenc<id> hslotval;
-		their_node.get_raw_slot(slot, slotval);
-		their_node.get_hex_slot(slot, hslotval);
-		L(F("(#0) they have a live leaf at slot %d (in a %s node '%s', level %d, we do not have)\n")
-		  % slot % typestr % hpref % lev);
-		L(F("(#0) requesting their %s leaf %s\n") % typestr % hslotval);
-		queue_send_data_cmd(their_node.type, slotval);
-	      }
-	      break;
-	    case dead_leaf_state:
-	      {
-		// we cannot ask for what they have, it is dead
-		L(F("(#0) they have a dead leaf at slot %d (in a %s node '%s', level %d, we do not have)\n")
-		  % slot % typestr % hpref % lev);
-		continue;
-	      }
-	      break;
-	    case subtree_state:
-	      {
-		// they have a subtree; might as well ask for that
-		L(F("(#0) they have a subtree at slot %d (in a %s node '%s', level %d, we do not have)\n")
-		  % slot % typestr % hpref % lev);
-		merkle_node our_fake_subtree;
-		their_node.extended_prefix(slot, our_fake_subtree.pref);
-		our_fake_subtree.level = their_node.level + 1;
-		our_fake_subtree.type = their_node.type;
-		queue_refine_cmd(our_fake_subtree);
-	      }
-	      break;
-	    }
-	}
+        {
+          switch (their_node.get_slot_state(slot))
+            {
+            case empty_state:
+              {
+                // we agree, this slot is empty
+                L(F("(#0) they have an empty slot %d (in a %s node '%s', level %d, we do not have)\n")
+                  % slot % typestr % hpref % lev);
+                continue;
+              }
+              break;
+            case live_leaf_state:
+              {
+                // we want what *they* have
+                id slotval;
+                hexenc<id> hslotval;
+                their_node.get_raw_slot(slot, slotval);
+                their_node.get_hex_slot(slot, hslotval);
+                L(F("(#0) they have a live leaf at slot %d (in a %s node '%s', level %d, we do not have)\n")
+                  % slot % typestr % hpref % lev);
+                L(F("(#0) requesting their %s leaf %s\n") % typestr % hslotval);
+                queue_send_data_cmd(their_node.type, slotval);
+              }
+              break;
+            case dead_leaf_state:
+              {
+                // we cannot ask for what they have, it is dead
+                L(F("(#0) they have a dead leaf at slot %d (in a %s node '%s', level %d, we do not have)\n")
+                  % slot % typestr % hpref % lev);
+                continue;
+              }
+              break;
+            case subtree_state:
+              {
+                // they have a subtree; might as well ask for that
+                L(F("(#0) they have a subtree at slot %d (in a %s node '%s', level %d, we do not have)\n")
+                  % slot % typestr % hpref % lev);
+                merkle_node our_fake_subtree;
+                their_node.extended_prefix(slot, our_fake_subtree.pref);
+                our_fake_subtree.level = their_node.level + 1;
+                our_fake_subtree.type = their_node.type;
+                queue_refine_cmd(our_fake_subtree);
+              }
+              break;
+            }
+        }
     }
   else
     {
       // we have a corresponding merkle node. there are 16 branches
       // to the following switch condition. it is awful. sorry.
       L(F("found corresponding %s merkle node for prefix '%s', level %d\n")
-	% typestr % hpref % lev);
+        % typestr % hpref % lev);
       merkle_node our_node;
       load_merkle_node(app, their_node.type, this->collection, 
-		       their_node.level, hpref, our_node);
+                       their_node.level, hpref, our_node);
       for (size_t slot = 0; slot < constants::merkle_num_slots; ++slot)
-	{	  
-	  switch (their_node.get_slot_state(slot))
-	    {
-	    case empty_state:
-	      switch (our_node.get_slot_state(slot))
-		{
-
-		case empty_state:
-		  // 1: theirs == empty, ours == empty 
-		  L(F("(#1) they have an empty slot %d in %s node '%s', level %d, and so do we\n")
-		    % slot % typestr % hpref % lev);
-		  continue;
-		  break;
-
-		case live_leaf_state:
-		  // 2: theirs == empty, ours == live 
-		  L(F("(#2) they have an empty slot %d in %s node '%s', level %d, we have a live leaf\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    I(their_node.type == our_node.type);
-		    string tmp;
-		    id slotval;
-		    our_node.get_raw_slot(slot, slotval);
-		    load_data(their_node.type, slotval, this->app, tmp);
-		    queue_data_cmd(their_node.type, slotval, tmp);
-		  }
-		  break;
-
-		case dead_leaf_state:
-		  // 3: theirs == empty, ours == dead 
-		  L(F("(#3) they have an empty slot %d in %s node '%s', level %d, we have a dead leaf\n")
-		    % slot % typestr % hpref % lev);
-		  continue;
-		  break;
-
-		case subtree_state:
-		  // 4: theirs == empty, ours == subtree 
-		  L(F("(#4) they have an empty slot %d in %s node '%s', level %d, we have a subtree\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    hexenc<prefix> subprefix;
-		    our_node.extended_hex_prefix(slot, subprefix);
-		    merkle_node our_subtree;
-		    I(our_node.type == their_node.type);
-		    load_merkle_node(app, their_node.type, this->collection, 
-				     our_node.level + 1, subprefix, our_subtree);
-		    I(our_node.type == our_subtree.type);
-		    queue_refine_cmd(our_subtree);
-		  }
-		  break;
-
-		}
-	      break;
-
-
-	    case live_leaf_state:
-	      switch (our_node.get_slot_state(slot))
-		{
-
-		case empty_state:
-		  // 5: theirs == live, ours == empty 
-		  L(F("(#5) they have a live leaf at slot %d in %s node '%s', level %d, we have nothing\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    id slotval;
-		    their_node.get_raw_slot(slot, slotval);
-		    queue_send_data_cmd(their_node.type, slotval);
-		  }
-		  break;
-
-		case live_leaf_state:
-		  // 6: theirs == live, ours == live 
-		  L(F("(#6) they have a live leaf at slot %d in %s node '%s', and so do we\n")
-		    % slot % typestr % hpref);
-		  {
-		    id our_slotval, their_slotval;
-		    their_node.get_raw_slot(slot, their_slotval);
-		    our_node.get_raw_slot(slot, our_slotval);		    
-		    if (their_slotval == our_slotval)
-		      {
-			hexenc<id> hslotval;
-			their_node.get_hex_slot(slot, hslotval);
-			L(F("(#6) we both have live %s leaf '%s'\n") % typestr % hslotval);
-			continue;
-		      }
-		    else
-		      {
-			I(their_node.type == our_node.type);
-			string tmp;
-			load_data(our_node.type, our_slotval, this->app, tmp);
-			queue_send_data_cmd(their_node.type, their_slotval);
-			queue_data_cmd(our_node.type, our_slotval, tmp);
-		      }
-		  }
-		  break;
-
-		case dead_leaf_state:
-		  // 7: theirs == live, ours == dead 
-		  L(F("(#7) they have a live leaf at slot %d in %s node %s, level %d, we have a dead one\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    id our_slotval, their_slotval;
-		    our_node.get_raw_slot(slot, our_slotval);
-		    their_node.get_raw_slot(slot, their_slotval);
-		    if (their_slotval == our_slotval)
-		      {
-			hexenc<id> hslotval;
-			their_node.get_hex_slot(slot, hslotval);
-			L(F("(#7) it's the same %s leaf '%s', but ours is dead\n") 
-			  % typestr % hslotval);
-			continue;
-		      }
-		    else
-		      {
-			queue_send_data_cmd(their_node.type, their_slotval);
-		      }
-		  }
-		  break;
-
-		case subtree_state:
-		  // 8: theirs == live, ours == subtree 
-		  L(F("(#8) they have a live leaf in slot %d of %s node '%s', level %d, we have a subtree\n")
-		    % slot % typestr % hpref % lev);
-		  {
-
-		    id their_slotval;
-		    hexenc<id> their_hval;
-		    their_node.get_raw_slot(slot, their_slotval);
-		    encode_hexenc(their_slotval, their_hval);
-		    if (data_exists(their_node.type, their_slotval, app))
-		      L(F("(#8) we have a copy of their live leaf '%s' in slot %d of %s node '%s', level %d\n")
-			% their_hval % slot % typestr % hpref % lev);
-		    else
-		      {
-			L(F("(#8) requesting a copy of their live leaf '%s' in slot %d of %s node '%s', level %d\n")
-			  % their_hval % slot % typestr % hpref % lev);
-			queue_send_data_cmd(their_node.type, their_slotval);
-		      }
-		    
-		    L(F("(#8) sending our subtree for refinement, in slot %d of %s node '%s', level %d\n")
-		      % slot % typestr % hpref % lev);
-		    hexenc<prefix> subprefix;
-		    our_node.extended_hex_prefix(slot, subprefix);
-		    merkle_node our_subtree;
-		    load_merkle_node(app, our_node.type, this->collection, 
-				     our_node.level + 1, subprefix, our_subtree);
-		    queue_refine_cmd(our_subtree);
-		  }
-		  break;
-		}
-	      break;
-
-
-	    case dead_leaf_state:
-	      switch (our_node.get_slot_state(slot))
-		{
-		case empty_state:
-		  // 9: theirs == dead, ours == empty 
-		  L(F("(#9) they have a dead leaf at slot %d in %s node '%s', level %d, we have nothing\n")
-		    % slot % typestr % hpref % lev);
-		  continue;
-		  break;
-
-		case live_leaf_state:
-		  // 10: theirs == dead, ours == live 
-		  L(F("(#10) they have a dead leaf at slot %d in %s node '%s', level %d, we have a live one\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    id our_slotval, their_slotval;
-		    their_node.get_raw_slot(slot, their_slotval);
-		    our_node.get_raw_slot(slot, our_slotval);
-		    hexenc<id> hslotval;
-		    our_node.get_hex_slot(slot, hslotval);
-		    if (their_slotval == our_slotval)
-		      {
-			L(F("(#10) we both have %s leaf %s, theirs is dead\n") 
-			  % typestr % hslotval);
-			continue;
-		      }
-		    else
-		      {
-			I(their_node.type == our_node.type);
-			string tmp;
-			load_data(our_node.type, our_slotval, this->app, tmp);
-			queue_data_cmd(our_node.type, our_slotval, tmp);
-		      }
-		  }
-		  break;
-
-		case dead_leaf_state:
-		  // 11: theirs == dead, ours == dead 
-		  L(F("(#11) they have a dead leaf at slot %d in %s node '%s', level %d, so do we\n")
-		    % slot % typestr % hpref % lev);
-		  continue;
-		  break;
-
-		case subtree_state:
-		  // theirs == dead, ours == subtree 
-		  L(F("(#12) they have a dead leaf in slot %d of %s node '%s', we have a subtree\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    hexenc<prefix> subprefix;
-		    our_node.extended_hex_prefix(slot, subprefix);
-		    merkle_node our_subtree;
-		    load_merkle_node(app, our_node.type, this->collection, 
-				     our_node.level + 1, subprefix, our_subtree);
-		    queue_refine_cmd(our_subtree);
-		  }
-		  break;
-		}
-	      break;
-
-
-	    case subtree_state:
-	      switch (our_node.get_slot_state(slot))
-		{
-		case empty_state:
-		  // 13: theirs == subtree, ours == empty 
-		  L(F("(#13) they have a subtree at slot %d in %s node '%s', level %d, we have nothing\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    merkle_node our_fake_subtree;
-		    their_node.extended_prefix(slot, our_fake_subtree.pref);
-		    our_fake_subtree.level = their_node.level + 1;
-		    our_fake_subtree.type = their_node.type;
-		    queue_refine_cmd(our_fake_subtree);
-		  }
-		  break;
-
-		case live_leaf_state:
-		  // 14: theirs == subtree, ours == live 
-		  L(F("(#14) they have a subtree at slot %d in %s node '%s', level %d, we have a live leaf\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    size_t subslot;
-		    id our_slotval;
-		    merkle_node our_fake_subtree;
-		    our_node.get_raw_slot(slot, our_slotval);
-		    hexenc<id> hslotval;
-		    encode_hexenc(our_slotval, hslotval);
-		    
-		    pick_slot_and_prefix_for_value(our_slotval, our_node.level + 1, subslot, 
-						   our_fake_subtree.pref);
-		    L(F("(#14) pushed our leaf '%s' into fake subtree slot %d, level %d\n")
-		      % hslotval % subslot % (lev + 1));
-		    our_fake_subtree.type = their_node.type;
-		    our_fake_subtree.level = our_node.level + 1;
-		    our_fake_subtree.set_raw_slot(subslot, our_slotval);
-		    our_fake_subtree.set_slot_state(subslot, our_node.get_slot_state(slot));
-		    queue_refine_cmd(our_fake_subtree);
-		  }
-		  break;
-
-		case dead_leaf_state:
-		  // 15: theirs == subtree, ours == dead 
-		  L(F("(#15) they have a subtree at slot %d in %s node '%s', level %d, we have a dead leaf\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    size_t subslot;
-		    id our_slotval;
-		    merkle_node our_fake_subtree;
-		    our_node.get_raw_slot(slot, our_slotval);
-		    pick_slot_and_prefix_for_value(our_slotval, our_node.level + 1, subslot, 
-						   our_fake_subtree.pref);
-		    our_fake_subtree.type = their_node.type;
-		    our_fake_subtree.level = our_node.level + 1;
-		    our_fake_subtree.set_raw_slot(subslot, our_slotval);
-		    our_fake_subtree.set_slot_state(subslot, our_node.get_slot_state(slot));
-		    queue_refine_cmd(our_fake_subtree);    
-		  }
-		  break;
-
-		case subtree_state:
-		  // 16: theirs == subtree, ours == subtree 
-		  L(F("(#16) they have a subtree at slot %d in %s node '%s', level %d, and so do we\n")
-		    % slot % typestr % hpref % lev);
-		  {
-		    id our_slotval, their_slotval;
-		    hexenc<id> hslotval;
-		    their_node.get_raw_slot(slot, their_slotval);
-		    our_node.get_raw_slot(slot, our_slotval);
-		    our_node.get_hex_slot(slot, hslotval);
-		    if (their_slotval == our_slotval)
-		      {
-			L(F("(#16) we both have %s subtree '%s'\n") % typestr % hslotval);
-			continue;
-		      }
-		    else
-		      {
-			L(F("(#16) %s subtrees at slot %d differ, refining ours\n") % typestr % slot);
-			hexenc<prefix> subprefix;
-			our_node.extended_hex_prefix(slot, subprefix);
-			merkle_node our_subtree;
-			load_merkle_node(app, our_node.type, this->collection, 
-					 our_node.level + 1, subprefix, our_subtree);
-			queue_refine_cmd(our_subtree);
-		      }
-		  }
-		  break;
-		}
-	      break;
-	    }
-	}
+        {         
+          switch (their_node.get_slot_state(slot))
+            {
+            case empty_state:
+              switch (our_node.get_slot_state(slot))
+                {
+
+                case empty_state:
+                  // 1: theirs == empty, ours == empty 
+                  L(F("(#1) they have an empty slot %d in %s node '%s', level %d, and so do we\n")
+                    % slot % typestr % hpref % lev);
+                  continue;
+                  break;
+
+                case live_leaf_state:
+                  // 2: theirs == empty, ours == live 
+                  L(F("(#2) they have an empty slot %d in %s node '%s', level %d, we have a live leaf\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    I(their_node.type == our_node.type);
+                    string tmp;
+                    id slotval;
+                    our_node.get_raw_slot(slot, slotval);
+                    load_data(their_node.type, slotval, this->app, tmp);
+                    queue_data_cmd(their_node.type, slotval, tmp);
+                  }
+                  break;
+
+                case dead_leaf_state:
+                  // 3: theirs == empty, ours == dead 
+                  L(F("(#3) they have an empty slot %d in %s node '%s', level %d, we have a dead leaf\n")
+                    % slot % typestr % hpref % lev);
+                  continue;
+                  break;
+
+                case subtree_state:
+                  // 4: theirs == empty, ours == subtree 
+                  L(F("(#4) they have an empty slot %d in %s node '%s', level %d, we have a subtree\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    hexenc<prefix> subprefix;
+                    our_node.extended_hex_prefix(slot, subprefix);
+                    merkle_node our_subtree;
+                    I(our_node.type == their_node.type);
+                    load_merkle_node(app, their_node.type, this->collection, 
+                                     our_node.level + 1, subprefix, our_subtree);
+                    I(our_node.type == our_subtree.type);
+                    queue_refine_cmd(our_subtree);
+                  }
+                  break;
+
+                }
+              break;
+
+
+            case live_leaf_state:
+              switch (our_node.get_slot_state(slot))
+                {
+
+                case empty_state:
+                  // 5: theirs == live, ours == empty 
+                  L(F("(#5) they have a live leaf at slot %d in %s node '%s', level %d, we have nothing\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    id slotval;
+                    their_node.get_raw_slot(slot, slotval);
+                    queue_send_data_cmd(their_node.type, slotval);
+                  }
+                  break;
+
+                case live_leaf_state:
+                  // 6: theirs == live, ours == live 
+                  L(F("(#6) they have a live leaf at slot %d in %s node '%s', and so do we\n")
+                    % slot % typestr % hpref);
+                  {
+                    id our_slotval, their_slotval;
+                    their_node.get_raw_slot(slot, their_slotval);
+                    our_node.get_raw_slot(slot, our_slotval);               
+                    if (their_slotval == our_slotval)
+                      {
+                        hexenc<id> hslotval;
+                        their_node.get_hex_slot(slot, hslotval);
+                        L(F("(#6) we both have live %s leaf '%s'\n") % typestr % hslotval);
+                        continue;
+                      }
+                    else
+                      {
+                        I(their_node.type == our_node.type);
+                        string tmp;
+                        load_data(our_node.type, our_slotval, this->app, tmp);
+                        queue_send_data_cmd(their_node.type, their_slotval);
+                        queue_data_cmd(our_node.type, our_slotval, tmp);
+                      }
+                  }
+                  break;
+
+                case dead_leaf_state:
+                  // 7: theirs == live, ours == dead 
+                  L(F("(#7) they have a live leaf at slot %d in %s node %s, level %d, we have a dead one\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    id our_slotval, their_slotval;
+                    our_node.get_raw_slot(slot, our_slotval);
+                    their_node.get_raw_slot(slot, their_slotval);
+                    if (their_slotval == our_slotval)
+                      {
+                        hexenc<id> hslotval;
+                        their_node.get_hex_slot(slot, hslotval);
+                        L(F("(#7) it's the same %s leaf '%s', but ours is dead\n") 
+                          % typestr % hslotval);
+                        continue;
+                      }
+                    else
+                      {
+                        queue_send_data_cmd(their_node.type, their_slotval);
+                      }
+                  }
+                  break;
+
+                case subtree_state:
+                  // 8: theirs == live, ours == subtree 
+                  L(F("(#8) they have a live leaf in slot %d of %s node '%s', level %d, we have a subtree\n")
+                    % slot % typestr % hpref % lev);
+                  {
+
+                    id their_slotval;
+                    hexenc<id> their_hval;
+                    their_node.get_raw_slot(slot, their_slotval);
+                    encode_hexenc(their_slotval, their_hval);
+                    if (data_exists(their_node.type, their_slotval, app))
+                      L(F("(#8) we have a copy of their live leaf '%s' in slot %d of %s node '%s', level %d\n")
+                        % their_hval % slot % typestr % hpref % lev);
+                    else
+                      {
+                        L(F("(#8) requesting a copy of their live leaf '%s' in slot %d of %s node '%s', level %d\n")
+                          % their_hval % slot % typestr % hpref % lev);
+                        queue_send_data_cmd(their_node.type, their_slotval);
+                      }
+                    
+                    L(F("(#8) sending our subtree for refinement, in slot %d of %s node '%s', level %d\n")
+                      % slot % typestr % hpref % lev);
+                    hexenc<prefix> subprefix;
+                    our_node.extended_hex_prefix(slot, subprefix);
+                    merkle_node our_subtree;
+                    load_merkle_node(app, our_node.type, this->collection, 
+                                     our_node.level + 1, subprefix, our_subtree);
+                    queue_refine_cmd(our_subtree);
+                  }
+                  break;
+                }
+              break;
+
+
+            case dead_leaf_state:
+              switch (our_node.get_slot_state(slot))
+                {
+                case empty_state:
+                  // 9: theirs == dead, ours == empty 
+                  L(F("(#9) they have a dead leaf at slot %d in %s node '%s', level %d, we have nothing\n")
+                    % slot % typestr % hpref % lev);
+                  continue;
+                  break;
+
+                case live_leaf_state:
+                  // 10: theirs == dead, ours == live 
+                  L(F("(#10) they have a dead leaf at slot %d in %s node '%s', level %d, we have a live one\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    id our_slotval, their_slotval;
+                    their_node.get_raw_slot(slot, their_slotval);
+                    our_node.get_raw_slot(slot, our_slotval);
+                    hexenc<id> hslotval;
+                    our_node.get_hex_slot(slot, hslotval);
+                    if (their_slotval == our_slotval)
+                      {
+                        L(F("(#10) we both have %s leaf %s, theirs is dead\n") 
+                          % typestr % hslotval);
+                        continue;
+                      }
+                    else
+                      {
+                        I(their_node.type == our_node.type);
+                        string tmp;
+                        load_data(our_node.type, our_slotval, this->app, tmp);
+                        queue_data_cmd(our_node.type, our_slotval, tmp);
+                      }
+                  }
+                  break;
+
+                case dead_leaf_state:
+                  // 11: theirs == dead, ours == dead 
+                  L(F("(#11) they have a dead leaf at slot %d in %s node '%s', level %d, so do we\n")
+                    % slot % typestr % hpref % lev);
+                  continue;
+                  break;
+
+                case subtree_state:
+                  // theirs == dead, ours == subtree 
+                  L(F("(#12) they have a dead leaf in slot %d of %s node '%s', we have a subtree\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    hexenc<prefix> subprefix;
+                    our_node.extended_hex_prefix(slot, subprefix);
+                    merkle_node our_subtree;
+                    load_merkle_node(app, our_node.type, this->collection, 
+                                     our_node.level + 1, subprefix, our_subtree);
+                    queue_refine_cmd(our_subtree);
+                  }
+                  break;
+                }
+              break;
+
+
+            case subtree_state:
+              switch (our_node.get_slot_state(slot))
+                {
+                case empty_state:
+                  // 13: theirs == subtree, ours == empty 
+                  L(F("(#13) they have a subtree at slot %d in %s node '%s', level %d, we have nothing\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    merkle_node our_fake_subtree;
+                    their_node.extended_prefix(slot, our_fake_subtree.pref);
+                    our_fake_subtree.level = their_node.level + 1;
+                    our_fake_subtree.type = their_node.type;
+                    queue_refine_cmd(our_fake_subtree);
+                  }
+                  break;
+
+                case live_leaf_state:
+                  // 14: theirs == subtree, ours == live 
+                  L(F("(#14) they have a subtree at slot %d in %s node '%s', level %d, we have a live leaf\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    size_t subslot;
+                    id our_slotval;
+                    merkle_node our_fake_subtree;
+                    our_node.get_raw_slot(slot, our_slotval);
+                    hexenc<id> hslotval;
+                    encode_hexenc(our_slotval, hslotval);
+                    
+                    pick_slot_and_prefix_for_value(our_slotval, our_node.level + 1, subslot, 
+                                                   our_fake_subtree.pref);
+                    L(F("(#14) pushed our leaf '%s' into fake subtree slot %d, level %d\n")
+                      % hslotval % subslot % (lev + 1));
+                    our_fake_subtree.type = their_node.type;
+                    our_fake_subtree.level = our_node.level + 1;
+                    our_fake_subtree.set_raw_slot(subslot, our_slotval);
+                    our_fake_subtree.set_slot_state(subslot, our_node.get_slot_state(slot));
+                    queue_refine_cmd(our_fake_subtree);
+                  }
+                  break;
+
+                case dead_leaf_state:
+                  // 15: theirs == subtree, ours == dead 
+                  L(F("(#15) they have a subtree at slot %d in %s node '%s', level %d, we have a dead leaf\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    size_t subslot;
+                    id our_slotval;
+                    merkle_node our_fake_subtree;
+                    our_node.get_raw_slot(slot, our_slotval);
+                    pick_slot_and_prefix_for_value(our_slotval, our_node.level + 1, subslot, 
+                                                   our_fake_subtree.pref);
+                    our_fake_subtree.type = their_node.type;
+                    our_fake_subtree.level = our_node.level + 1;
+                    our_fake_subtree.set_raw_slot(subslot, our_slotval);
+                    our_fake_subtree.set_slot_state(subslot, our_node.get_slot_state(slot));
+                    queue_refine_cmd(our_fake_subtree);    
+                  }
+                  break;
+
+                case subtree_state:
+                  // 16: theirs == subtree, ours == subtree 
+                  L(F("(#16) they have a subtree at slot %d in %s node '%s', level %d, and so do we\n")
+                    % slot % typestr % hpref % lev);
+                  {
+                    id our_slotval, their_slotval;
+                    hexenc<id> hslotval;
+                    their_node.get_raw_slot(slot, their_slotval);
+                    our_node.get_raw_slot(slot, our_slotval);
+                    our_node.get_hex_slot(slot, hslotval);
+                    if (their_slotval == our_slotval)
+                      {
+                        L(F("(#16) we both have %s subtree '%s'\n") % typestr % hslotval);
+                        continue;
+                      }
+                    else
+                      {
+                        L(F("(#16) %s subtrees at slot %d differ, refining ours\n") % typestr % slot);
+                        hexenc<prefix> subprefix;
+                        our_node.extended_hex_prefix(slot, subprefix);
+                        merkle_node our_subtree;
+                        load_merkle_node(app, our_node.type, this->collection, 
+                                         our_node.level + 1, subprefix, our_subtree);
+                        queue_refine_cmd(our_subtree);
+                      }
+                  }
+                  break;
+                }
+              break;
+            }
+        }
     }
   return true;
 }
@@ -2140,7 +2139,7 @@
 
 bool 
 session::process_send_data_cmd(netcmd_item_type type,
-			       id const & item)
+                               id const & item)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -2163,8 +2162,8 @@
 
 bool 
 session::process_send_delta_cmd(netcmd_item_type type,
-				id const & base,
-				id const & ident)
+                                id const & base,
+                                id const & ident)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -2181,49 +2180,49 @@
     {
     case file_item:
       {
-	file_id fbase(hbase), fident(hident);
-	file_delta fdel;
-	if (this->app.db.file_version_exists(fbase) 
-	    && this->app.db.file_version_exists(fident))
-	  {
-	    file_data base_fdat, ident_fdat;
-	    data base_dat, ident_dat;
-	    this->app.db.get_file_version(fbase, base_fdat);
-	    this->app.db.get_file_version(fident, ident_fdat);	    
-	    string tmp;	    
-	    unpack(base_fdat.inner(), base_dat);
-	    unpack(ident_fdat.inner(), ident_dat);
-	    compute_delta(base_dat(), ident_dat(), tmp);
-	    del = delta(tmp);
-	  }
-	else
-	  {
-	    return process_send_data_cmd(type, ident);
-	  }
+        file_id fbase(hbase), fident(hident);
+        file_delta fdel;
+        if (this->app.db.file_version_exists(fbase) 
+            && this->app.db.file_version_exists(fident))
+          {
+            file_data base_fdat, ident_fdat;
+            data base_dat, ident_dat;
+            this->app.db.get_file_version(fbase, base_fdat);
+            this->app.db.get_file_version(fident, ident_fdat);      
+            string tmp;     
+            unpack(base_fdat.inner(), base_dat);
+            unpack(ident_fdat.inner(), ident_dat);
+            compute_delta(base_dat(), ident_dat(), tmp);
+            del = delta(tmp);
+          }
+        else
+          {
+            return process_send_data_cmd(type, ident);
+          }
       }
       break;
 
     case manifest_item:
       {
-	manifest_id mbase(hbase), mident(hident);
-	manifest_delta mdel;
-	if (this->app.db.manifest_version_exists(mbase) 
-	    && this->app.db.manifest_version_exists(mident))
-	  {
-	    manifest_data base_mdat, ident_mdat;
-	    data base_dat, ident_dat;
-	    this->app.db.get_manifest_version(mbase, base_mdat);
-	    this->app.db.get_manifest_version(mident, ident_mdat);
-	    string tmp;
-	    unpack(base_mdat.inner(), base_dat);
-	    unpack(ident_mdat.inner(), ident_dat);
-	    compute_delta(base_dat(), ident_dat(), tmp);
-	    del = delta(tmp);
-	  }
-	else
-	  {
-	    return process_send_data_cmd(type, ident);
-	  }
+        manifest_id mbase(hbase), mident(hident);
+        manifest_delta mdel;
+        if (this->app.db.manifest_version_exists(mbase) 
+            && this->app.db.manifest_version_exists(mident))
+          {
+            manifest_data base_mdat, ident_mdat;
+            data base_dat, ident_dat;
+            this->app.db.get_manifest_version(mbase, base_mdat);
+            this->app.db.get_manifest_version(mident, ident_mdat);
+            string tmp;
+            unpack(base_mdat.inner(), base_dat);
+            unpack(ident_mdat.inner(), ident_dat);
+            compute_delta(base_dat(), ident_dat(), tmp);
+            del = delta(tmp);
+          }
+        else
+          {
+            return process_send_data_cmd(type, ident);
+          }
       }
       break;
       
@@ -2236,8 +2235,8 @@
 
 void 
 session::update_merkle_trees(netcmd_item_type type,
-			     hexenc<id> const & hident,
-			     bool live_p)
+                             hexenc<id> const & hident,
+                             bool live_p)
 {
   id raw_id;
   decode_hexenc(hident, raw_id);
@@ -2247,18 +2246,18 @@
        i != this->all_collections.end(); ++i)
     {
       if (this->collection().find(*i) == 0)
-	{
-	  L(F("updating %s collection '%s' with item %s\n")
-	    % typestr % *i % hident);
-	  insert_into_merkle_tree(this->app, live_p, type, *i, raw_id(), 0); 
-	}
+        {
+          L(F("updating %s collection '%s' with item %s\n")
+            % typestr % *i % hident);
+          insert_into_merkle_tree(this->app, live_p, type, *i, raw_id(), 0); 
+        }
     }
 }
 
 bool 
 session::process_data_cmd(netcmd_item_type type,
-			  id const & item, 
-			  string const & dat)
+                          id const & item, 
+                          string const & dat)
 {  
   hexenc<id> hitem;
   encode_hexenc(item, hitem);
@@ -2266,134 +2265,134 @@
   // it's ok if we received something we didn't ask for; it might
   // be a spontaneous transmission from refinement
   note_item_arrived(type, item);
-			   
+                           
   switch (type)
     {
     case key_item:
       if (this->app.db.public_key_exists(hitem))
-	L(F("public key '%s' already exists in our database\n")  % hitem);
+        L(F("public key '%s' already exists in our database\n")  % hitem);
       else
-	{
-	  rsa_keypair_id keyid;
-	  base64<rsa_pub_key> pub;
-	  read_pubkey(dat, keyid, pub);
-	  hexenc<id> tmp;
-	  key_hash_code(keyid, pub, tmp);
-	  if (! (tmp == hitem))
-	    throw bad_decode(F("hash check failed for public key '%s' (%s);"
-			       " wanted '%s' got '%s'")  
-			     % hitem % keyid % hitem % tmp);
-	  this->dbw.consume_public_key(keyid, pub);
-	  update_merkle_trees(key_item, tmp, true);
-	}
+        {
+          rsa_keypair_id keyid;
+          base64<rsa_pub_key> pub;
+          read_pubkey(dat, keyid, pub);
+          hexenc<id> tmp;
+          key_hash_code(keyid, pub, tmp);
+          if (! (tmp == hitem))
+            throw bad_decode(F("hash check failed for public key '%s' (%s);"
+                               " wanted '%s' got '%s'")  
+                             % hitem % keyid % hitem % tmp);
+          this->dbw.consume_public_key(keyid, pub);
+          update_merkle_trees(key_item, tmp, true);
+        }
       break;
 
     case mcert_item:
       if (this->app.db.manifest_cert_exists(hitem))
-	L(F("manifest cert '%s' already exists in our database\n")  % hitem);
+        L(F("manifest cert '%s' already exists in our database\n")  % hitem);
       else
-	{
-	  cert c;
-	  read_cert(dat, c);
-	  hexenc<id> tmp;
-	  cert_hash_code(c, tmp);
-	  if (! (tmp == hitem))
-	    throw bad_decode(F("hash check failed for manifest cert '%s'")  % hitem);
-	  this->dbw.consume_manifest_cert(manifest<cert>(c));
-	  update_merkle_trees(mcert_item, tmp, true);
-	}
+        {
+          cert c;
+          read_cert(dat, c);
+          hexenc<id> tmp;
+          cert_hash_code(c, tmp);
+          if (! (tmp == hitem))
+            throw bad_decode(F("hash check failed for manifest cert '%s'")  % hitem);
+          this->dbw.consume_manifest_cert(manifest<cert>(c));
+          update_merkle_trees(mcert_item, tmp, true);
+        }
       break;
 
     case rcert_item:
       if (this->app.db.revision_cert_exists(hitem))
-	L(F("revision cert '%s' already exists in our database\n")  % hitem);
+        L(F("revision cert '%s' already exists in our database\n")  % hitem);
       else
-	{
-	  cert c;
-	  read_cert(dat, c);
-	  hexenc<id> tmp;
-	  cert_hash_code(c, tmp);
-	  if (! (tmp == hitem))
-	    throw bad_decode(F("hash check failed for revision cert '%s'")  % hitem);
-	  this->dbw.consume_revision_cert(revision<cert>(c));
-	  if (!app.db.revision_exists(revision_id(c.ident)))
-	    {
-	      id rid;
-	      decode_hexenc(c.ident, rid);
-	      queue_send_data_cmd(revision_item, rid);
-	    }
-	  update_merkle_trees(rcert_item, tmp, true);
-	}
+        {
+          cert c;
+          read_cert(dat, c);
+          hexenc<id> tmp;
+          cert_hash_code(c, tmp);
+          if (! (tmp == hitem))
+            throw bad_decode(F("hash check failed for revision cert '%s'")  % hitem);
+          this->dbw.consume_revision_cert(revision<cert>(c));
+          if (!app.db.revision_exists(revision_id(c.ident)))
+            {
+              id rid;
+              decode_hexenc(c.ident, rid);
+              queue_send_data_cmd(revision_item, rid);
+            }
+          update_merkle_trees(rcert_item, tmp, true);
+        }
       break;
 
     case fcert_item:
       if (this->app.db.file_cert_exists(hitem))
-	L(F("file cert '%s' already exists in our database\n")  % hitem);
+        L(F("file cert '%s' already exists in our database\n")  % hitem);
       else
-	{
-	  cert c;
-	  read_cert(dat, c);
-	  hexenc<id> tmp;
-	  cert_hash_code(c, tmp);
-	  if (! (tmp == hitem))
-	    throw bad_decode(F("hash check failed for file cert '%s'")  % hitem);
-	  this->dbw.consume_file_cert(file<cert>(c));
-	  update_merkle_trees(fcert_item, tmp, true);
-	}
+        {
+          cert c;
+          read_cert(dat, c);
+          hexenc<id> tmp;
+          cert_hash_code(c, tmp);
+          if (! (tmp == hitem))
+            throw bad_decode(F("hash check failed for file cert '%s'")  % hitem);
+          this->dbw.consume_file_cert(file<cert>(c));
+          update_merkle_trees(fcert_item, tmp, true);
+        }
       break;
 
     case revision_item:
       {
-	revision_id rid(hitem);
-	if (this->app.db.revision_exists(rid))
-	  L(F("revision '%s' already exists in our database\n") % hitem);
-	else
-	  {
-	    L(F("received revision '%s' \n") % hitem);
-	    boost::shared_ptr< pair<revision_data, revision_set > > 
-	      rp(new pair<revision_data, revision_set>());
-	    
-	    base64< gzip<data> > packed;
-	    pack(data(dat), packed);
-	    rp->first = revision_data(packed);
-	    read_revision_set(dat, rp->second);
-	    ancestry.insert(std::make_pair(rid, rp));
-	    if (rcert_refinement_done())
-	      {
-		analyze_ancestry_graph();
-	      }
-	  }
+        revision_id rid(hitem);
+        if (this->app.db.revision_exists(rid))
+          L(F("revision '%s' already exists in our database\n") % hitem);
+        else
+          {
+            L(F("received revision '%s' \n") % hitem);
+            boost::shared_ptr< pair<revision_data, revision_set > > 
+              rp(new pair<revision_data, revision_set>());
+            
+            base64< gzip<data> > packed;
+            pack(data(dat), packed);
+            rp->first = revision_data(packed);
+            read_revision_set(dat, rp->second);
+            ancestry.insert(std::make_pair(rid, rp));
+            if (rcert_refinement_done())
+              {
+                analyze_ancestry_graph();
+              }
+          }
       }
       break;
 
     case manifest_item:
       {
-	manifest_id mid(hitem);
-	if (this->app.db.manifest_version_exists(mid))
-	  L(F("manifest version '%s' already exists in our database\n") % hitem);
-	else
-	  {
-	    base64< gzip<data> > packed_dat;
-	    pack(data(dat), packed_dat);
-	    this->dbw.consume_manifest_data(mid, manifest_data(packed_dat));
-	    manifest_map man;
-	    read_manifest_map(data(dat), man);
-	    analyze_manifest(man);
-	  }
+        manifest_id mid(hitem);
+        if (this->app.db.manifest_version_exists(mid))
+          L(F("manifest version '%s' already exists in our database\n") % hitem);
+        else
+          {
+            base64< gzip<data> > packed_dat;
+            pack(data(dat), packed_dat);
+            this->dbw.consume_manifest_data(mid, manifest_data(packed_dat));
+            manifest_map man;
+            read_manifest_map(data(dat), man);
+            analyze_manifest(man);
+          }
       }
       break;
 
     case file_item:
       {
-	file_id fid(hitem);
-	if (this->app.db.file_version_exists(fid))
-	  L(F("file version '%s' already exists in our database\n") % hitem);
-	else
-	  {
-	    base64< gzip<data> > packed_dat;
-	    pack(data(dat), packed_dat);
-	    this->dbw.consume_file_data(fid, file_data(packed_dat));
-	  }
+        file_id fid(hitem);
+        if (this->app.db.file_version_exists(fid))
+          L(F("file version '%s' already exists in our database\n") % hitem);
+        else
+          {
+            base64< gzip<data> > packed_dat;
+            pack(data(dat), packed_dat);
+            this->dbw.consume_file_data(fid, file_data(packed_dat));
+          }
       }
       break;
 
@@ -2403,9 +2402,9 @@
 
 bool 
 session::process_delta_cmd(netcmd_item_type type,
-			   id const & base, 
-			   id const & ident, 
-			   delta const & del)
+                           id const & base, 
+                           id const & ident, 
+                           delta const & del)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -2423,42 +2422,42 @@
     {
     case manifest_item:
       {
-	manifest_id src_manifest(hbase), dst_manifest(hident);
-	base64< gzip<delta> > packed_del;
-	pack(del, packed_del);
-	if (reverse_delta_requests.find(id_pair)
-	    != reverse_delta_requests.end())
-	  {
-	    reverse_delta_requests.erase(id_pair);
-	    this->dbw.consume_manifest_reverse_delta(src_manifest, 
-						     dst_manifest,
-						     manifest_delta(packed_del));
-	  }
-	else
-	  this->dbw.consume_manifest_delta(src_manifest, 
-					   dst_manifest,
-					   manifest_delta(packed_del));
-	
+        manifest_id src_manifest(hbase), dst_manifest(hident);
+        base64< gzip<delta> > packed_del;
+        pack(del, packed_del);
+        if (reverse_delta_requests.find(id_pair)
+            != reverse_delta_requests.end())
+          {
+            reverse_delta_requests.erase(id_pair);
+            this->dbw.consume_manifest_reverse_delta(src_manifest, 
+                                                     dst_manifest,
+                                                     manifest_delta(packed_del));
+          }
+        else
+          this->dbw.consume_manifest_delta(src_manifest, 
+                                           dst_manifest,
+                                           manifest_delta(packed_del));
+        
       }
       break;
 
     case file_item:
       {
-	file_id src_file(hbase), dst_file(hident);
-	base64< gzip<delta> > packed_del;
-	pack(del, packed_del);
-	if (reverse_delta_requests.find(id_pair)
-	    != reverse_delta_requests.end())
-	  {
-	    reverse_delta_requests.erase(id_pair);
-	    this->dbw.consume_file_reverse_delta(src_file, 
-						 dst_file,
-						 file_delta(packed_del));
-	  }
-	else
-	  this->dbw.consume_file_delta(src_file, 
-				       dst_file,
-				       file_delta(packed_del));
+        file_id src_file(hbase), dst_file(hident);
+        base64< gzip<delta> > packed_del;
+        pack(del, packed_del);
+        if (reverse_delta_requests.find(id_pair)
+            != reverse_delta_requests.end())
+          {
+            reverse_delta_requests.erase(id_pair);
+            this->dbw.consume_file_reverse_delta(src_file, 
+                                                 dst_file,
+                                                 file_delta(packed_del));
+          }
+        else
+          this->dbw.consume_file_delta(src_file, 
+                                       dst_file,
+                                       file_delta(packed_del));
       }
       break;
       
@@ -2471,7 +2470,7 @@
 
 bool 
 session::process_nonexistant_cmd(netcmd_item_type type,
-				 id const & item)
+                                 id const & item)
 {
   string typestr;
   netcmd_item_type_to_string(type, typestr);
@@ -2498,9 +2497,9 @@
 
     case error_cmd:
       {
-	string errmsg;
-	read_error_cmd_payload(cmd.payload, errmsg);
-	return process_error_cmd(errmsg);
+        string errmsg;
+        read_error_cmd_payload(cmd.payload, errmsg);
+        return process_error_cmd(errmsg);
       }
       break;
 
@@ -2508,9 +2507,9 @@
       require(! authenticated, "hello netcmd received when not authenticated");
       require(voice == client_voice, "hello netcmd received in client voice");
       {
-	id server, nonce;
-	read_hello_cmd_payload(cmd.payload, server, nonce);
-	return process_hello_cmd(server, nonce);
+        id server, nonce;
+        read_hello_cmd_payload(cmd.payload, server, nonce);
+        return process_hello_cmd(server, nonce);
       }
       break;
 
@@ -2518,14 +2517,14 @@
       require(! authenticated, "anonymous netcmd received when not authenticated");
       require(voice == server_voice, "anonymous netcmd received in server voice");
       require(role == source_role ||
-	      role == source_and_sink_role, 
-	      "anonymous netcmd received in source or source/sink role");
+              role == source_and_sink_role, 
+              "anonymous netcmd received in source or source/sink role");
       {
-	protocol_role role;
-	string collection;
-	id nonce2;
-	read_anonymous_cmd_payload(cmd.payload, role, collection, nonce2);
-	return process_anonymous_cmd(role, collection, nonce2);
+        protocol_role role;
+        string collection;
+        id nonce2;
+        read_anonymous_cmd_payload(cmd.payload, role, collection, nonce2);
+        return process_anonymous_cmd(role, collection, nonce2);
       }
       break;
 
@@ -2533,11 +2532,11 @@
       require(! authenticated, "auth netcmd received when not authenticated");
       require(voice == server_voice, "auth netcmd received in server voice");
       {
-	protocol_role role;
-	string collection, signature;
-	id client, nonce1, nonce2;
-	read_auth_cmd_payload(cmd.payload, role, collection, client, nonce1, nonce2, signature);
-	return process_auth_cmd(role, collection, client, nonce1, nonce2, signature);
+        protocol_role role;
+        string collection, signature;
+        id client, nonce1, nonce2;
+        read_auth_cmd_payload(cmd.payload, role, collection, client, nonce1, nonce2, signature);
+        return process_auth_cmd(role, collection, client, nonce1, nonce2, signature);
       }
       break;
 
@@ -2545,98 +2544,98 @@
       require(! authenticated, "confirm netcmd received when not authenticated");
       require(voice == client_voice, "confirm netcmd received in client voice");
       {
-	string signature;
-	read_confirm_cmd_payload(cmd.payload, signature);
-	return process_confirm_cmd(signature);
+        string signature;
+        read_confirm_cmd_payload(cmd.payload, signature);
+        return process_confirm_cmd(signature);
       }
       break;
 
     case refine_cmd:
       require(authenticated, "refine netcmd received when authenticated");
       {
-	merkle_node node;
-	read_refine_cmd_payload(cmd.payload, node);
-	map< netcmd_item_type, done_marker>::iterator i = done_refinements.find(node.type);
-	require(i != done_refinements.end(), "refinement netcmd refers to valid type");
-	require(i->second.tree_is_done == false, "refinement netcmd received when tree is live");
-	i->second.current_level_had_refinements = true;
-	return process_refine_cmd(node);
+        merkle_node node;
+        read_refine_cmd_payload(cmd.payload, node);
+        map< netcmd_item_type, done_marker>::iterator i = done_refinements.find(node.type);
+        require(i != done_refinements.end(), "refinement netcmd refers to valid type");
+        require(i->second.tree_is_done == false, "refinement netcmd received when tree is live");
+        i->second.current_level_had_refinements = true;
+        return process_refine_cmd(node);
       }
       break;
 
     case done_cmd:
       require(authenticated, "done netcmd received when authenticated");
       {
-	size_t level;
-	netcmd_item_type type;
-	read_done_cmd_payload(cmd.payload, level, type);
-	return process_done_cmd(level, type);
+        size_t level;
+        netcmd_item_type type;
+        read_done_cmd_payload(cmd.payload, level, type);
+        return process_done_cmd(level, type);
       }
       break;
 
     case send_data_cmd:
       require(authenticated, "send_data netcmd received when authenticated");
       require(role == source_role ||
-	      role == source_and_sink_role, 
-	      "send_data netcmd received in source or source/sink role");
+              role == source_and_sink_role, 
+              "send_data netcmd received in source or source/sink role");
       {
-	netcmd_item_type type;
-	id item;
-	read_send_data_cmd_payload(cmd.payload, type, item);
-	return process_send_data_cmd(type, item);
+        netcmd_item_type type;
+        id item;
+        read_send_data_cmd_payload(cmd.payload, type, item);
+        return process_send_data_cmd(type, item);
       }
       break;
 
     case send_delta_cmd:
       require(authenticated, "send_delta netcmd received when authenticated");
       require(role == source_role ||
-	      role == source_and_sink_role, 
-	      "send_delta netcmd received in source or source/sink role");
+              role == source_and_sink_role, 
+              "send_delta netcmd received in source or source/sink role");
       {
-	netcmd_item_type type;
-	id base, ident;
-	read_send_delta_cmd_payload(cmd.payload, type, base, ident);
-	return process_send_delta_cmd(type, base, ident);
+        netcmd_item_type type;
+        id base, ident;
+        read_send_delta_cmd_payload(cmd.payload, type, base, ident);
+        return process_send_delta_cmd(type, base, ident);
       }
 
     case data_cmd:
       require(authenticated, "data netcmd received when authenticated");
       require(role == sink_role ||
-	      role == source_and_sink_role, 
-	      "data netcmd received in source or source/sink role");
+              role == source_and_sink_role, 
+              "data netcmd received in source or source/sink role");
       {
-	netcmd_item_type type;
-	id item;
-	string dat;
-	read_data_cmd_payload(cmd.payload, type, item, dat);
-	return process_data_cmd(type, item, dat);
+        netcmd_item_type type;
+        id item;
+        string dat;
+        read_data_cmd_payload(cmd.payload, type, item, dat);
+        return process_data_cmd(type, item, dat);
       }
       break;
 
     case delta_cmd:
       require(authenticated, "delta netcmd received when authenticated");
       require(role == sink_role ||
-	      role == source_and_sink_role, 
-	      "delta netcmd received in source or source/sink role");
+              role == source_and_sink_role, 
+              "delta netcmd received in source or source/sink role");
       {
-	netcmd_item_type type;
-	id base, ident;
-	delta del;
-	read_delta_cmd_payload(cmd.payload, type, base, ident, del);
-	return process_delta_cmd(type, base, ident, del);
+        netcmd_item_type type;
+        id base, ident;
+        delta del;
+        read_delta_cmd_payload(cmd.payload, type, base, ident, del);
+        return process_delta_cmd(type, base, ident, del);
       }
-      break;	  
+      break;      
 
     case nonexistant_cmd:
       require(authenticated, "nonexistant netcmd received when authenticated");
       require(role == sink_role ||
-	      role == source_and_sink_role, 
-	      "nonexistant netcmd received in sink or source/sink role");
+              role == source_and_sink_role, 
+              "nonexistant netcmd received in sink or source/sink role");
       {
-	netcmd_item_type type;
-	id item;
-	read_nonexistant_cmd_payload(cmd.payload, type, item);
-	return process_nonexistant_cmd(type, item);
+        netcmd_item_type type;
+        id item;
+        read_nonexistant_cmd_payload(cmd.payload, type, item);
+        return process_nonexistant_cmd(type, item);
       }
       break;
     }
@@ -2670,10 +2669,10 @@
   if (!armed)
     {
       if (read_netcmd(inbuf, cmd))
-	{
-	  inbuf.erase(0, cmd.encoded_size());	  
-	  armed = true;
-	}
+        {
+          inbuf.erase(0, cmd.encoded_size());     
+          armed = true;
+        }
     }
   return armed;
 }      
@@ -2683,14 +2682,14 @@
   try 
     {      
       if (!arm())
-	return true;
+        return true;
       
       transaction_guard guard(app.db);
       armed = false;
       L(F("processing %d byte input buffer from peer %s\n") % inbuf.size() % peer_id);
       bool ret = dispatch_payload(cmd);
       if (inbuf.size() >= constants::netcmd_maxsz)
-	W(F("input buffer for peer %s is overfull after netcmd dispatch\n") % peer_id);
+        W(F("input buffer for peer %s is overfull after netcmd dispatch\n") % peer_id);
       guard.commit();
       maybe_say_goodbye();
       return ret;
@@ -2705,12 +2704,12 @@
 
 static void 
 call_server(protocol_role role,
-	    vector<utf8> const & collections,
-	    set<string> const & all_collections,
-	    app_state & app,
-	    utf8 const & address,
-	    Netxx::port_type default_port,
-	    unsigned long timeout_seconds)
+            vector<utf8> const & collections,
+            set<string> const & all_collections,
+            app_state & app,
+            utf8 const & address,
+            Netxx::port_type default_port,
+            unsigned long timeout_seconds)
 {
   Netxx::Probe probe;
   Netxx::Timeout timeout(static_cast<long>(timeout_seconds)), instant(0,1);
@@ -2720,7 +2719,7 @@
   P(F("connecting to %s\n") % address());
   Netxx::Stream server(address().c_str(), default_port, timeout); 
   session sess(role, client_voice, collections, all_collections, app, 
-	       address(), server.get_socketfd(), timeout);
+               address(), server.get_socketfd(), timeout);
 
   ticker input("bytes in", ">", 256), output("bytes out", "<", 256);
   sess.in_ticker = &input;
@@ -2730,15 +2729,15 @@
     {       
       bool armed = false;
       try 
-	{
-	  armed = sess.arm();
-	}
+        {
+          armed = sess.arm();
+        }
       catch (bad_decode & bd)
-	{
-	  W(F("caught bad_decode exception decoding input from peer %s: '%s'\n") 
-	    % sess.peer_id % bd.what);
-	  return;	  
-	}
+        {
+          W(F("caught bad_decode exception decoding input from peer %s: '%s'\n") 
+            % sess.peer_id % bd.what);
+          return;         
+        }
 
       probe.clear();
       probe.add(sess.str, sess.which_events());
@@ -2747,99 +2746,99 @@
       Netxx::socket_type fd = res.first;
       
       if (fd == -1 && !armed) 
-	{
-	  P(F("timed out waiting for I/O with peer %s, disconnecting\n") % sess.peer_id);
-	  return;
-	}
+        {
+          P(F("timed out waiting for I/O with peer %s, disconnecting\n") % sess.peer_id);
+          return;
+        }
       
       if (event & Netxx::Probe::ready_read)
-	{
-	  if (sess.read_some())
-	    {
-	      try 
-		{
-		  armed = sess.arm();
-		}
-	      catch (bad_decode & bd)
-		{
-		  W(F("caught bad_decode exception decoding input from peer %s: '%s'\n") 
-		    % sess.peer_id % bd.what);
-		  return;	  
-		}
-	    }
-	  else
-	    {	      
-	      if (sess.sent_goodbye)
-		P(F("read from fd %d (peer %s) closed OK after goodbye\n") % fd % sess.peer_id);
-	      else
-		P(F("read from fd %d (peer %s) failed, disconnecting\n") % fd % sess.peer_id);
-	      return;
-	    }
-	}
+        {
+          if (sess.read_some())
+            {
+              try 
+                {
+                  armed = sess.arm();
+                }
+              catch (bad_decode & bd)
+                {
+                  W(F("caught bad_decode exception decoding input from peer %s: '%s'\n") 
+                    % sess.peer_id % bd.what);
+                  return;         
+                }
+            }
+          else
+            {         
+              if (sess.sent_goodbye)
+                P(F("read from fd %d (peer %s) closed OK after goodbye\n") % fd % sess.peer_id);
+              else
+                P(F("read from fd %d (peer %s) failed, disconnecting\n") % fd % sess.peer_id);
+              return;
+            }
+        }
       
       if (event & Netxx::Probe::ready_write)
-	{
-	  if (! sess.write_some())
-	    {
-	      if (sess.sent_goodbye)
-		P(F("write on fd %d (peer %s) closed OK after goodbye\n") % fd % sess.peer_id);
-	      else
-		P(F("write on fd %d (peer %s) failed, disconnecting\n") % fd % sess.peer_id);
-	      return;
-	    }
-	}
+        {
+          if (! sess.write_some())
+            {
+              if (sess.sent_goodbye)
+                P(F("write on fd %d (peer %s) closed OK after goodbye\n") % fd % sess.peer_id);
+              else
+                P(F("write on fd %d (peer %s) failed, disconnecting\n") % fd % sess.peer_id);
+              return;
+            }
+        }
       
       if (event & Netxx::Probe::ready_oobd)
-	{
-	  P(F("got OOB data on fd %d (peer %s), disconnecting\n") 
-	    % fd % sess.peer_id);
-	  return;
-	}      
+        {
+          P(F("got OOB data on fd %d (peer %s), disconnecting\n") 
+            % fd % sess.peer_id);
+          return;
+        }      
 
       if (armed)
-	{
-	  if (!sess.process())
-	    {
-	      P(F("terminated exchange with %s\n") 
-		% sess.peer_id);
-	      return;
-	    }
-	}
+        {
+          if (!sess.process())
+            {
+              P(F("terminated exchange with %s\n") 
+                % sess.peer_id);
+              return;
+            }
+        }
 
       if (sess.sent_goodbye && sess.outbuf.empty() && sess.received_goodbye)
-	{
-	  P(F("successful exchange with %s\n") 
-	    % sess.peer_id);
-	  return;
-	}	  
+        {
+          P(F("successful exchange with %s\n") 
+            % sess.peer_id);
+          return;
+        }         
     }  
 }
 
 static void 
 arm_sessions_and_calculate_probe(Netxx::Probe & probe,
-				 map<Netxx::socket_type, shared_ptr<session> > & sessions,
-				 set<Netxx::socket_type> & armed_sessions)
+                                 map<Netxx::socket_type, shared_ptr<session> > & sessions,
+                                 set<Netxx::socket_type> & armed_sessions)
 {
   set<Netxx::socket_type> arm_failed;
   for (map<Netxx::socket_type, 
-	 shared_ptr<session> >::const_iterator i = sessions.begin();
+         shared_ptr<session> >::const_iterator i = sessions.begin();
        i != sessions.end(); ++i)
     {
       try 
-	{
-	  if (i->second->arm())
-	    {
-	      L(F("fd %d is armed\n") % i->first);
-	      armed_sessions.insert(i->first);
-	    }
-	  probe.add(i->second->str, i->second->which_events());
-	}
+        {
+          if (i->second->arm())
+            {
+              L(F("fd %d is armed\n") % i->first);
+              armed_sessions.insert(i->first);
+            }
+          probe.add(i->second->str, i->second->which_events());
+        }
       catch (bad_decode & bd)
-	{
-	  W(F("caught bad_decode exception decoding input from peer %s: '%s', marking as bad\n") 
-	    % i->second->peer_id % bd.what);
-	  arm_failed.insert(i->first);
-	}	  
+        {
+          W(F("caught bad_decode exception decoding input from peer %s: '%s', marking as bad\n") 
+            % i->second->peer_id % bd.what);
+          arm_failed.insert(i->first);
+        }         
     }
   for (set<Netxx::socket_type>::const_iterator i = arm_failed.begin();
        i != arm_failed.end(); ++i)
@@ -2850,13 +2849,13 @@
 
 static void
 handle_new_connection(Netxx::Address & addr,
-		      Netxx::StreamServer & server,
-		      Netxx::Timeout & timeout,
-		      protocol_role role,
-		      vector<utf8> const & collections,
-		      set<string> const & all_collections,		      
-		      map<Netxx::socket_type, shared_ptr<session> > & sessions,
-		      app_state & app)
+                      Netxx::StreamServer & server,
+                      Netxx::Timeout & timeout,
+                      protocol_role role,
+                      vector<utf8> const & collections,
+                      set<string> const & all_collections,                    
+                      map<Netxx::socket_type, shared_ptr<session> > & sessions,
+                      app_state & app)
 {
   L(F("accepting new connection on %s : %d\n") 
     % addr.get_name() % addr.get_port());
@@ -2870,9 +2869,9 @@
     {
       P(F("accepted new client connection from %s\n") % client);      
       shared_ptr<session> sess(new session(role, server_voice, collections, 
-					   all_collections, app,
-					   lexical_cast<string>(client), 
-					   client.get_socketfd(), timeout));
+                                           all_collections, app,
+                                           lexical_cast<string>(client), 
+                                           client.get_socketfd(), timeout));
       sess->begin_service();
       sessions.insert(make_pair(client.get_socketfd(), sess));
     }
@@ -2880,30 +2879,30 @@
 
 static void 
 handle_read_available(Netxx::socket_type fd,
-		      shared_ptr<session> sess,
-		      map<Netxx::socket_type, shared_ptr<session> > & sessions,
-		      set<Netxx::socket_type> & armed_sessions,
-		      bool & live_p)
+                      shared_ptr<session> sess,
+                      map<Netxx::socket_type, shared_ptr<session> > & sessions,
+                      set<Netxx::socket_type> & armed_sessions,
+                      bool & live_p)
 {
   if (sess->read_some())
     {
       try
-	{
-	  if (sess->arm())
-	    armed_sessions.insert(fd);
-	}
+        {
+          if (sess->arm())
+            armed_sessions.insert(fd);
+        }
       catch (bad_decode & bd)
-	{
-	  W(F("caught bad_decode exception decoding input from peer %s: '%s', disconnecting\n") 
-	    % sess->peer_id % bd.what);
-	  sessions.erase(fd);
-	  live_p = false;
-	}
+        {
+          W(F("caught bad_decode exception decoding input from peer %s: '%s', disconnecting\n") 
+            % sess->peer_id % bd.what);
+          sessions.erase(fd);
+          live_p = false;
+        }
     }
   else
     {
       P(F("fd %d (peer %s) read failed, disconnecting\n") 
-	% fd % sess->peer_id);
+        % fd % sess->peer_id);
       sessions.erase(fd);
       live_p = false;
     }
@@ -2912,14 +2911,14 @@
 
 static void 
 handle_write_available(Netxx::socket_type fd,
-		       shared_ptr<session> sess,
-		       map<Netxx::socket_type, shared_ptr<session> > & sessions,
-		       bool & live_p)
+                       shared_ptr<session> sess,
+                       map<Netxx::socket_type, shared_ptr<session> > & sessions,
+                       bool & live_p)
 {
   if (! sess->write_some())
     {
       P(F("fd %d (peer %s) write failed, disconnecting\n") 
-	% fd % sess->peer_id);
+        % fd % sess->peer_id);
       sessions.erase(fd);
       live_p = false;
     }
@@ -2927,7 +2926,7 @@
 
 static void
 process_armed_sessions(map<Netxx::socket_type, shared_ptr<session> > & sessions,
-		       set<Netxx::socket_type> & armed_sessions)
+                       set<Netxx::socket_type> & armed_sessions)
 {
   for (set<Netxx::socket_type>::const_iterator i = armed_sessions.begin();
        i != armed_sessions.end(); ++i)
@@ -2935,24 +2934,24 @@
       map<Netxx::socket_type, shared_ptr<session> >::iterator j;
       j = sessions.find(*i);
       if (j == sessions.end())
-	continue;
+        continue;
       else
-	{
-	  Netxx::socket_type fd = j->first;
-	  shared_ptr<session> sess = j->second;
-	  if (!sess->process())
-	    {
-	      P(F("fd %d (peer %s) processing finished, disconnecting\n") 
-		% fd % sess->peer_id);
-	      sessions.erase(j);
-	    }
-	}
+        {
+          Netxx::socket_type fd = j->first;
+          shared_ptr<session> sess = j->second;
+          if (!sess->process())
+            {
+              P(F("fd %d (peer %s) processing finished, disconnecting\n") 
+                % fd % sess->peer_id);
+              sessions.erase(j);
+            }
+        }
     }
 }
 
 static void
 reap_dead_sessions(map<Netxx::socket_type, shared_ptr<session> > & sessions,
-		   unsigned long timeout_seconds)
+                   unsigned long timeout_seconds)
 {
   // kill any clients which haven't done any i/o inside the timeout period
   // or who have said goodbye and flushed their output buffers
@@ -2962,18 +2961,18 @@
        i != sessions.end(); ++i)
     {
       if (static_cast<unsigned long>(i->second->last_io_time + timeout_seconds) 
-	  < static_cast<unsigned long>(now))
-	{
-	  P(F("fd %d (peer %s) has been idle too long, disconnecting\n") 
-	    % i->first % i->second->peer_id);
-	  dead_clients.insert(i->first);
-	}
+          < static_cast<unsigned long>(now))
+        {
+          P(F("fd %d (peer %s) has been idle too long, disconnecting\n") 
+            % i->first % i->second->peer_id);
+          dead_clients.insert(i->first);
+        }
       if (i->second->sent_goodbye && i->second->outbuf.empty() && i->second->received_goodbye)
-	{
-	  P(F("fd %d (peer %s) exchanged goodbyes and flushed output, disconnecting\n") 
-	    % i->first % i->second->peer_id);
-	  dead_clients.insert(i->first);
-	}
+        {
+          P(F("fd %d (peer %s) exchanged goodbyes and flushed output, disconnecting\n") 
+            % i->first % i->second->peer_id);
+          dead_clients.insert(i->first);
+        }
     }
   for (set<Netxx::socket_type>::const_iterator i = dead_clients.begin();
        i != dead_clients.end(); ++i)
@@ -2984,13 +2983,13 @@
 
 static void 
 serve_connections(protocol_role role,
-		  vector<utf8> const & collections,
-		  set<string> const & all_collections,
-		  app_state & app,
-		  utf8 const & address,
-		  Netxx::port_type default_port,
-		  unsigned long timeout_seconds,
-		  unsigned long session_limit)
+                  vector<utf8> const & collections,
+                  set<string> const & all_collections,
+                  app_state & app,
+                  utf8 const & address,
+                  Netxx::port_type default_port,
+                  unsigned long timeout_seconds,
+                  unsigned long session_limit)
 {
   Netxx::Probe probe;  
 
@@ -3015,59 +3014,59 @@
       armed_sessions.clear();
 
       if (sessions.size() >= session_limit)
-	W(F("session limit %d reached, some connections will be refused\n") % session_limit);
+        W(F("session limit %d reached, some connections will be refused\n") % session_limit);
       else
-	probe.add(server);
+        probe.add(server);
 
       arm_sessions_and_calculate_probe(probe, sessions, armed_sessions);
 
       L(F("i/o probe with %d armed\n") % armed_sessions.size());      
       Netxx::Probe::result_type res = probe.ready(sessions.empty() ? forever 
-					   : (armed_sessions.empty() ? timeout 
-					      : instant));
+                                           : (armed_sessions.empty() ? timeout 
+                                              : instant));
       Netxx::Probe::ready_type event = res.second;
       Netxx::socket_type fd = res.first;
       
       if (fd == -1)
-	{
-	  if (armed_sessions.empty()) 
-	    L(F("timed out waiting for I/O (listening on %s : %d)\n") 
-	      % addr.get_name() % addr.get_port());
-	}
+        {
+          if (armed_sessions.empty()) 
+            L(F("timed out waiting for I/O (listening on %s : %d)\n") 
+              % addr.get_name() % addr.get_port());
+        }
       
       // we either got a new connection
       else if (fd == server)
-	handle_new_connection(addr, server, timeout, role, 
-			      collections, all_collections, sessions, app);
+        handle_new_connection(addr, server, timeout, role, 
+                              collections, all_collections, sessions, app);
       
       // or an existing session woke up
       else
-	{
-	  map<Netxx::socket_type, shared_ptr<session> >::iterator i;
-	  i = sessions.find(fd);
-	  if (i == sessions.end())
-	    {
-	      L(F("got woken up for action on unknown fd %d\n") % fd);
-	    }
-	  else
-	    {
-	      shared_ptr<session> sess = i->second;
-	      bool live_p = true;
-
-	      if (event & Netxx::Probe::ready_read)
-		handle_read_available(fd, sess, sessions, armed_sessions, live_p);
-		
-	      if (live_p && (event & Netxx::Probe::ready_write))
-		handle_write_available(fd, sess, sessions, live_p);
-		
-	      if (live_p && (event & Netxx::Probe::ready_oobd))
-		{
-		  P(F("got some OOB data on fd %d (peer %s), disconnecting\n") 
-		    % fd % sess->peer_id);
-		  sessions.erase(i);
-		}
-	    }
-	}
+        {
+          map<Netxx::socket_type, shared_ptr<session> >::iterator i;
+          i = sessions.find(fd);
+          if (i == sessions.end())
+            {
+              L(F("got woken up for action on unknown fd %d\n") % fd);
+            }
+          else
+            {
+              shared_ptr<session> sess = i->second;
+              bool live_p = true;
+
+              if (event & Netxx::Probe::ready_read)
+                handle_read_available(fd, sess, sessions, armed_sessions, live_p);
+                
+              if (live_p && (event & Netxx::Probe::ready_write))
+                handle_write_available(fd, sess, sessions, live_p);
+                
+              if (live_p && (event & Netxx::Probe::ready_oobd))
+                {
+                  P(F("got some OOB data on fd %d (peer %s), disconnecting\n") 
+                    % fd % sess->peer_id);
+                  sessions.erase(i);
+                }
+            }
+        }
       process_armed_sessions(sessions, armed_sessions);
       reap_dead_sessions(sessions, timeout_seconds);
     }
@@ -3082,7 +3081,7 @@
 
 void 
 rebuild_merkle_trees(app_state & app,
-		     utf8 const & collection)
+                     utf8 const & collection)
 {
   transaction_guard guard(app.db);
 
@@ -3127,54 +3126,54 @@
     app.db.get_revision_certs(branch_cert_name, certs);
     for (size_t i = 0; i < certs.size(); ++i)
       {
-	cert_value name;
-	decode_base64(idx(certs, i).inner().value, name);
-	if (name().find(collection()) == 0)
-	  {
-	    if (branchnames.find(name()) == branchnames.end())
-	      P(F("including branch %s\n") % name());
-	    branchnames.insert(name());
-	    revision_ids.insert(revision_id(idx(certs, i).inner().ident));
-	  }
+        cert_value name;
+        decode_base64(idx(certs, i).inner().value, name);
+        if (name().find(collection()) == 0)
+          {
+            if (branchnames.find(name()) == branchnames.end())
+              P(F("including branch %s\n") % name());
+            branchnames.insert(name());
+            revision_ids.insert(revision_id(idx(certs, i).inner().ident));
+          }
       }
 
     // insert all certs and keys reachable via these revisions
     for (set<revision_id>::const_iterator rev = revision_ids.begin();
-	 rev != revision_ids.end(); ++rev)
+         rev != revision_ids.end(); ++rev)
       {
-	app.db.get_revision_certs(*rev, certs);
-	for (size_t i = 0; i < certs.size(); ++i)
-	  {
-	    hexenc<id> certhash;
-	    id raw_id;
-	    cert_hash_code(idx(certs, i).inner(), certhash);
-	    decode_hexenc(certhash, raw_id);
-	    insert_into_merkle_tree(app, true, rcert_item, collection, raw_id(), 0);
-	    ++rcerts;
-	    rsa_keypair_id const & k = idx(certs, i).inner().key;
-	    if (inserted_keys.find(k) == inserted_keys.end())
-	      {
-		if (app.db.public_key_exists(k))
-		  {
-		    base64<rsa_pub_key> pub_encoded;
-		    app.db.get_key(k, pub_encoded);
-		    hexenc<id> keyhash;
-		    key_hash_code(k, pub_encoded, keyhash);
-		    decode_hexenc(keyhash, raw_id);
-		    insert_into_merkle_tree(app, true, key_item, collection, raw_id(), 0);
-		    ++keys;
-		  }
-		inserted_keys.insert(k);
-	      }
-	  }
+        app.db.get_revision_certs(*rev, certs);
+        for (size_t i = 0; i < certs.size(); ++i)
+          {
+            hexenc<id> certhash;
+            id raw_id;
+            cert_hash_code(idx(certs, i).inner(), certhash);
+            decode_hexenc(certhash, raw_id);
+            insert_into_merkle_tree(app, true, rcert_item, collection, raw_id(), 0);
+            ++rcerts;
+            rsa_keypair_id const & k = idx(certs, i).inner().key;
+            if (inserted_keys.find(k) == inserted_keys.end())
+              {
+                if (app.db.public_key_exists(k))
+                  {
+                    base64<rsa_pub_key> pub_encoded;
+                    app.db.get_key(k, pub_encoded);
+                    hexenc<id> keyhash;
+                    key_hash_code(k, pub_encoded, keyhash);
+                    decode_hexenc(keyhash, raw_id);
+                    insert_into_merkle_tree(app, true, key_item, collection, raw_id(), 0);
+                    ++keys;
+                  }
+                inserted_keys.insert(k);
+              }
+          }
       }
   }  
   guard.commit();
 }
-			
+                        
 static void 
 ensure_merkle_tree_ready(app_state & app,
-			 utf8 const & collection)
+                         utf8 const & collection)
 {
   string mcert_item_str, fcert_item_str, key_item_str;
   netcmd_item_type_to_string(mcert_item, mcert_item_str);
@@ -3182,8 +3181,8 @@
   netcmd_item_type_to_string(mcert_item, key_item_str);
 
 //   if (! (app.db.merkle_node_exists(mcert_item_str, collection, 0, get_root_prefix().val)
-// 	 && app.db.merkle_node_exists(fcert_item_str, collection, 0, get_root_prefix().val)
-// 	 && app.db.merkle_node_exists(key_item_str, collection, 0, get_root_prefix().val)))
+//       && app.db.merkle_node_exists(fcert_item_str, collection, 0, get_root_prefix().val)
+//       && app.db.merkle_node_exists(key_item_str, collection, 0, get_root_prefix().val)))
 //     {
 
   // FIXME: for now we always rebuild merkle trees. that's a bit coarse but it 
@@ -3200,10 +3199,10 @@
 
 void 
 run_netsync_protocol(protocol_voice voice, 
-		     protocol_role role, 
-		     utf8 const & addr, 
-		     vector<utf8> collections,
-		     app_state & app)
+                     protocol_role role, 
+                     utf8 const & addr, 
+                     vector<utf8> collections,
+                     app_state & app)
 {  
   for (vector<utf8>::const_iterator i = collections.begin();
        i != collections.end(); ++i)
@@ -3224,36 +3223,36 @@
       cert_value name;
       decode_base64(i->inner().value, name);
       for (vector<utf8>::const_iterator j = collections.begin(); 
-	   j != collections.end(); ++j)
-	{	
-	  if ((*j)().find(name()) == 0 
-	      && all_collections.find(name()) == all_collections.end())
-	    {
-	      if (name() != (*j)())
-		P(F("%s included in collection %s\n") % (*j) % name);
-	      all_collections.insert(name());
-	    }
-	}
+           j != collections.end(); ++j)
+        {       
+          if ((*j)().find(name()) == 0 
+              && all_collections.find(name()) == all_collections.end())
+            {
+              if (name() != (*j)())
+                P(F("%s included in collection %s\n") % (*j) % name);
+              all_collections.insert(name());
+            }
+        }
     }
 
   try 
     {
       if (voice == server_voice)
-	{
-	  serve_connections(role, collections, all_collections, app,
-			    addr, static_cast<Netxx::port_type>(constants::netsync_default_port), 
-			    static_cast<unsigned long>(constants::netsync_timeout_seconds), 
-			    static_cast<unsigned long>(constants::netsync_connection_limit));
-	}
+        {
+          serve_connections(role, collections, all_collections, app,
+                            addr, static_cast<Netxx::port_type>(constants::netsync_default_port), 
+                            static_cast<unsigned long>(constants::netsync_timeout_seconds), 
+                            static_cast<unsigned long>(constants::netsync_connection_limit));
+        }
       else    
-	{
-	  I(voice == client_voice);
-	  transaction_guard guard(app.db);
-	  call_server(role, collections, all_collections, app, 
-		      addr, static_cast<Netxx::port_type>(constants::netsync_default_port), 
-		      static_cast<unsigned long>(constants::netsync_timeout_seconds));
-	  guard.commit();
-	}
+        {
+          I(voice == client_voice);
+          transaction_guard guard(app.db);
+          call_server(role, collections, all_collections, app, 
+                      addr, static_cast<Netxx::port_type>(constants::netsync_default_port), 
+                      static_cast<unsigned long>(constants::netsync_timeout_seconds));
+          guard.commit();
+        }
     }
   catch (Netxx::Exception & e)
     {      
diff -ru monotone-0.15/revision.cc monotone-0.15-patched/revision.cc
--- monotone-0.15/revision.cc	Sun Oct 24 13:39:47 2004
+++ monotone-0.15-patched/revision.cc	Tue Dec  7 20:32:51 2004
@@ -57,9 +57,9 @@
 
 static void 
 ensure_parents_loaded(ctx child,
-		      std::map<ctx, shared_bitmap> & parents,
-		      interner<ctx> & intern,
-		      app_state & app)
+                      std::map<ctx, shared_bitmap> & parents,
+                      interner<ctx> & intern,
+                      app_state & app)
 {
   if (parents.find(child) != parents.end())
     return;
@@ -68,6 +68,16 @@
 
   std::set<revision_id> imm_parents;
   app.db.get_revision_parents(revision_id(intern.lookup(child)), imm_parents);
+
+  // The null revision is not a parent for purposes of finding common
+  // ancestors.
+  for (std::set<revision_id>::iterator p = imm_parents.begin();
+       p != imm_parents.end(); ++p)
+    {
+      if (null_id(*p))
+        imm_parents.erase(p);
+    }
+              
   shared_bitmap bits = shared_bitmap(new bitmap(parents.size()));
   
   for (std::set<revision_id>::const_iterator p = imm_parents.begin();
@@ -76,7 +86,7 @@
       ctx pn = intern.intern(p->inner()());
       L(F("parent %s -> node %d\n") % *p % pn);
       if (pn >= bits->size()) 
-	bits->resize(pn+1);
+        bits->resize(pn+1);
       bits->set(pn);
     }
     
@@ -85,9 +95,9 @@
 
 static bool 
 expand_dominators(std::map<ctx, shared_bitmap> & parents,
-		  std::map<ctx, shared_bitmap> & dominators,
-		  interner<ctx> & intern,
-		  app_state & app)
+                  std::map<ctx, shared_bitmap> & dominators,
+                  interner<ctx> & intern,
+                  app_state & app)
 {
   bool something_changed = false;
   std::vector<ctx> nodes;
@@ -106,7 +116,7 @@
       shared_bitmap bits = dominators[*n];
       bitmap saved(*bits);
       if (bits->size() <= *n)
-	bits->resize(*n + 1);
+        bits->resize(*n + 1);
       bits->set(*n);
       
       ensure_parents_loaded(*n, parents, intern, app);
@@ -116,34 +126,34 @@
       
       bool first = true;
       for (unsigned long parent = 0; 
-	   parent != n_parents->size(); ++parent)
-	{
-	  if (! n_parents->test(parent))
-	    continue;
-
-	  if (dominators.find(parent) == dominators.end())
-	    dominators.insert(std::make_pair(parent, 
-					     shared_bitmap(new bitmap())));
-	  shared_bitmap pbits = dominators[parent];
-
-	  if (bits->size() > pbits->size())
-	    pbits->resize(bits->size());
-
-	  if (pbits->size() > bits->size())
-	    bits->resize(pbits->size());
-
-	  if (first)
-	    {
-	      intersection = (*pbits);
-	      first = false;
-	    }
-	  else
-	    intersection &= (*pbits);
-	}
+           parent != n_parents->size(); ++parent)
+        {
+          if (! n_parents->test(parent))
+            continue;
+
+          if (dominators.find(parent) == dominators.end())
+            dominators.insert(std::make_pair(parent, 
+                                             shared_bitmap(new bitmap())));
+          shared_bitmap pbits = dominators[parent];
+
+          if (bits->size() > pbits->size())
+            pbits->resize(bits->size());
+
+          if (pbits->size() > bits->size())
+            bits->resize(pbits->size());
+
+          if (first)
+            {
+              intersection = (*pbits);
+              first = false;
+            }
+          else
+            intersection &= (*pbits);
+        }
 
       (*bits) |= intersection;
       if (*bits != saved)
-	something_changed = true;
+        something_changed = true;
     }
   return something_changed;
 }
@@ -151,9 +161,9 @@
 
 static bool 
 expand_ancestors(std::map<ctx, shared_bitmap> & parents,
-		 std::map<ctx, shared_bitmap> & ancestors,
-		 interner<ctx> & intern,
-		 app_state & app)
+                 std::map<ctx, shared_bitmap> & ancestors,
+                 interner<ctx> & intern,
+                 app_state & app)
 {
   bool something_changed = false;
   std::vector<ctx> nodes;
@@ -171,44 +181,44 @@
       shared_bitmap bits = ancestors[*n];
       bitmap saved(*bits);
       if (bits->size() <= *n)
-	bits->resize(*n + 1);
+        bits->resize(*n + 1);
       bits->set(*n);
 
       ensure_parents_loaded(*n, parents, intern, app);
       shared_bitmap n_parents = parents[*n];
       for (ctx parent = 0; parent != n_parents->size(); ++parent)
-	{
-	  if (! n_parents->test(parent))
-	    continue;
-
-	  if (bits->size() <= parent)
-	    bits->resize(parent + 1);
-	  bits->set(parent);
-
-	  if (ancestors.find(parent) == ancestors.end())
-	    ancestors.insert(make_pair(parent, 
-					shared_bitmap(new bitmap())));
-	  shared_bitmap pbits = ancestors[parent];
+        {
+          if (! n_parents->test(parent))
+            continue;
+
+          if (bits->size() <= parent)
+            bits->resize(parent + 1);
+          bits->set(parent);
+
+          if (ancestors.find(parent) == ancestors.end())
+            ancestors.insert(make_pair(parent, 
+                                        shared_bitmap(new bitmap())));
+          shared_bitmap pbits = ancestors[parent];
 
-	  if (bits->size() > pbits->size())
-	    pbits->resize(bits->size());
+          if (bits->size() > pbits->size())
+            pbits->resize(bits->size());
 
-	  if (pbits->size() > bits->size())
-	    bits->resize(pbits->size());
+          if (pbits->size() > bits->size())
+            bits->resize(pbits->size());
 
-	  (*bits) |= (*pbits);
-	}
+          (*bits) |= (*pbits);
+        }
       if (*bits != saved)
-	something_changed = true;
+        something_changed = true;
     }
   return something_changed;
 }
 
 static bool 
 find_intersecting_node(bitmap & fst, 
-		       bitmap & snd, 
-		       interner<ctx> const & intern, 
-		       revision_id & anc)
+                       bitmap & snd, 
+                       interner<ctx> const & intern, 
+                       revision_id & anc)
 {
   
   if (fst.size() > snd.size())
@@ -221,20 +231,20 @@
     {
       L(F("found %d intersecting nodes\n") % intersection.count());
       for (ctx i = 0; i < intersection.size(); ++i)
-	{
-	  if (intersection.test(i))
-	    {
-	      anc = revision_id(intern.lookup(i));
-	      return true;
-	    }
-	}
+        {
+          if (intersection.test(i))
+            {
+              anc = revision_id(intern.lookup(i));
+              return true;
+            }
+        }
     }
   return false;
 }
 
 //  static void
 //  dump_bitset_map(string const & hdr,
-//  		std::map< ctx, shared_bitmap > const & mm)
+//              std::map< ctx, shared_bitmap > const & mm)
 //  {
 //    L(F("dumping [%s] (%d entries)\n") % hdr % mm.size());
 //    for (std::map< ctx, shared_bitmap >::const_iterator i = mm.begin();
@@ -246,9 +256,9 @@
 
 bool 
 find_common_ancestor(revision_id const & left,
-		     revision_id const & right,
-		     revision_id & anc,
-		     app_state & app)
+                     revision_id const & right,
+                     revision_id & anc,
+                     app_state & app)
 {
   interner<ctx> intern;
   std::map< ctx, shared_bitmap > 
@@ -270,24 +280,24 @@
   L(F("searching for common ancestor, left=%s right=%s\n") % left % right);
   
   while (expand_ancestors(parents, ancestors, intern, app) ||
-	 expand_dominators(parents, dominators, intern, app))
+         expand_dominators(parents, dominators, intern, app))
     {
       L(F("common ancestor scan [par=%d,anc=%d,dom=%d]\n") % 
-	parents.size() % ancestors.size() % dominators.size());
+        parents.size() % ancestors.size() % dominators.size());
 
       if (find_intersecting_node(*lanc, *rdom, intern, anc))
-	{
-	  L(F("found node %d, ancestor of left %s and dominating right %s\n")
-	    % anc % left % right);
-	  return true;
-	}
+        {
+          L(F("found node %d, ancestor of left %s and dominating right %s\n")
+            % anc % left % right);
+          return true;
+        }
       
       else if (find_intersecting_node(*ranc, *ldom, intern, anc))
-	{
-	  L(F("found node %d, ancestor of right %s and dominating left %s\n")
-	    % anc % right % left);
-	  return true;
-	}
+        {
+          L(F("found node %d, ancestor of right %s and dominating left %s\n")
+            % anc % right % left);
+          return true;
+        }
     }
 //      dump_bitset_map("ancestors", ancestors);
 //      dump_bitset_map("dominators", dominators);
@@ -314,11 +324,11 @@
 
 static bool 
 calculate_change_sets_recursive(revision_id const & ancestor,
-				revision_id const & child,
-				app_state & app,
-				change_set & cumulative_cset,
-				std::map<revision_id, boost::shared_ptr<change_set> > & partial_csets,
-				std::set<revision_id> & visited_nodes)
+                                revision_id const & child,
+                                app_state & app,
+                                change_set & cumulative_cset,
+                                std::map<revision_id, boost::shared_ptr<change_set> > & partial_csets,
+                                std::set<revision_id> & visited_nodes)
 {
 
   if (ancestor == child)
@@ -340,43 +350,43 @@
       revision_id curr_parent = edge_old_revision(i);
 
       if (curr_parent.inner()().empty())
-	continue;
+        continue;
 
       change_set cset_to_curr_parent;
 
       L(F("considering parent %s of %s\n") % curr_parent % child);
 
       std::map<revision_id, boost::shared_ptr<change_set> >::const_iterator j = 
-	partial_csets.find(curr_parent);
+        partial_csets.find(curr_parent);
       if (j != partial_csets.end()) 
-	{
-	  // a recursive call has traversed this parent before and built an
-	  // existing cset. just reuse that rather than re-traversing
-	  cset_to_curr_parent = *(j->second);
-	  relevant_parent = true;
-	}
+        {
+          // a recursive call has traversed this parent before and built an
+          // existing cset. just reuse that rather than re-traversing
+          cset_to_curr_parent = *(j->second);
+          relevant_parent = true;
+        }
       else if (visited_nodes.find(curr_parent) != visited_nodes.end())
-	{
-	  // a recursive call has traversed this parent, but there was no
-	  // path from it to the root, so the parent is irrelevant. skip.
-	  relevant_parent = false;
-	}
+        {
+          // a recursive call has traversed this parent, but there was no
+          // path from it to the root, so the parent is irrelevant. skip.
+          relevant_parent = false;
+        }
       else
-	relevant_parent = calculate_change_sets_recursive(ancestor, curr_parent, app, 
-							  cset_to_curr_parent, 
-							  partial_csets,
-							  visited_nodes);
+        relevant_parent = calculate_change_sets_recursive(ancestor, curr_parent, app, 
+                                                          cset_to_curr_parent, 
+                                                          partial_csets,
+                                                          visited_nodes);
 
       if (relevant_parent)
-	{
-	  L(F("revision %s is relevant, composing with edge to %s\n") 
-	    % curr_parent % child);
-	  concatenate_change_sets(cset_to_curr_parent, edge_changes(i), cumulative_cset);
-	  relevant_child = true;
-	  break;
-	}
+        {
+          L(F("revision %s is relevant, composing with edge to %s\n") 
+            % curr_parent % child);
+          concatenate_change_sets(cset_to_curr_parent, edge_changes(i), cumulative_cset);
+          relevant_child = true;
+          break;
+        }
       else
-	L(F("parent %s of %s is not relevant\n") % curr_parent % child);
+        L(F("parent %s of %s is not relevant\n") % curr_parent % child);
     }
 
   // store the partial edge from ancestor -> child, so that if anyone
@@ -384,17 +394,17 @@
   // cache.
   if (relevant_child)
     partial_csets.insert(std::make_pair(child, 
-					boost::shared_ptr<change_set>
-					(new change_set(cumulative_cset))));
+                                        boost::shared_ptr<change_set>
+                                        (new change_set(cumulative_cset))));
   
   return relevant_child;
 }
 
 void 
 calculate_composite_change_set(revision_id const & ancestor,
-			       revision_id const & child,
-			       app_state & app,
-			       change_set & composed)
+                               revision_id const & child,
+                               app_state & app,
+                               change_set & composed)
 {
   L(F("calculating composite changeset between %s and %s\n")
     % ancestor % child);
@@ -410,9 +420,9 @@
 
 static void 
 analyze_manifest_changes(app_state & app,
-			 manifest_id const & parent, 
-			 manifest_id const & child, 
-			 change_set & cs)
+                         manifest_id const & parent, 
+                         manifest_id const & child, 
+                         change_set & cs)
 {
   manifest_map m_parent, m_child;
   app.db.get_manifest(parent, m_parent);
@@ -423,29 +433,29 @@
     {
       manifest_map::const_iterator j = m_child.find(manifest_entry_path(i));
       if (j == m_child.end())
-	cs.delete_file(manifest_entry_path(i));
+        cs.delete_file(manifest_entry_path(i));
       else if (! (manifest_entry_id(i) == manifest_entry_id(j)))
-	{
-	  cs.apply_delta(manifest_entry_path(i),
-			 manifest_entry_id(i), 
-			 manifest_entry_id(j));
-	}	
+        {
+          cs.apply_delta(manifest_entry_path(i),
+                         manifest_entry_id(i), 
+                         manifest_entry_id(j));
+        }       
     }
   for (manifest_map::const_iterator i = m_child.begin(); 
        i != m_child.end(); ++i)
     {
       manifest_map::const_iterator j = m_parent.find(manifest_entry_path(i));
       if (j == m_parent.end())
-	cs.add_file(manifest_entry_path(i),
-		    manifest_entry_id(i));
+        cs.add_file(manifest_entry_path(i),
+                    manifest_entry_id(i));
     }
 }
 
 static revision_id
 construct_revisions(app_state & app,
-		    manifest_id const & child,
-		    std::multimap< manifest_id, manifest_id > const & ancestry,
-		    std::map<manifest_id, revision_id> & mapped)
+                    manifest_id const & child,
+                    std::multimap< manifest_id, manifest_id > const & ancestry,
+                    std::map<manifest_id, revision_id> & mapped)
 {
   revision_set rev;
   typedef std::multimap< manifest_id, manifest_id >::const_iterator ci;
@@ -457,18 +467,18 @@
       std::map<manifest_id, revision_id>::const_iterator j = mapped.find(parent);
 
       if (j != mapped.end())
-	parent_rid = j->second;
+        parent_rid = j->second;
       else
-	{
-	  parent_rid = construct_revisions(app, parent, ancestry, mapped);
-	  P(F("inserting mapping %d : %s -> %s\n") % mapped.size() % parent % parent_rid);;
-	  mapped.insert(std::make_pair(parent, parent_rid));
-	}
+        {
+          parent_rid = construct_revisions(app, parent, ancestry, mapped);
+          P(F("inserting mapping %d : %s -> %s\n") % mapped.size() % parent % parent_rid);;
+          mapped.insert(std::make_pair(parent, parent_rid));
+        }
       
       change_set cs;
       analyze_manifest_changes(app, parent, child, cs);
       rev.edges.insert(std::make_pair(parent_rid,
-				      std::make_pair(parent, cs)));
+                                      std::make_pair(parent, cs)));
     } 
 
   revision_id rid;
@@ -508,13 +518,13 @@
        i != tmp.end(); ++i)
     {
       if (cnames.find(i->inner().name) == cnames.end())
-	continue;
+        continue;
       cert new_cert;
       cert_value tv;
       decode_base64(i->inner().value, tv);
       make_simple_cert(rid.inner(), i->inner().name, tv, app, new_cert);
       if (! app.db.revision_cert_exists(revision<cert>(new_cert)))
-	app.db.put_revision_cert(revision<cert>(new_cert));
+        app.db.put_revision_cert(revision<cert>(new_cert));
     }
   return rid;  
 }
@@ -576,7 +586,7 @@
 
 void 
 print_edge(basic_io::printer & printer,
-	   edge_entry const & e)
+           edge_entry const & e)
 {       
   basic_io::stanza st;
   st.push_hex_pair(syms::old_revision, edge_old_revision(e).inner()());
@@ -588,7 +598,7 @@
 
 void 
 print_revision(basic_io::printer & printer,
-	       revision_set const & rev)
+               revision_set const & rev)
 {
   basic_io::stanza st; 
   st.push_hex_pair(syms::new_manifest, rev.new_manifest.inner()());
@@ -601,7 +611,7 @@
 
 void 
 parse_edge(basic_io::parser & parser,
-	   edge_map & es)
+           edge_map & es)
 {
   change_set cs;
   manifest_id old_man;
@@ -624,7 +634,7 @@
 
 void 
 parse_revision(basic_io::parser & parser,
-	       revision_set & rev)
+               revision_set & rev)
 {
   rev.edges.clear();
   std::string tmp;
@@ -637,7 +647,7 @@
 
 void 
 read_revision_set(data const & dat,
-		  revision_set & rev)
+                  revision_set & rev)
 {
   std::istringstream iss(dat());
   basic_io::input_source src(iss);
@@ -648,7 +658,7 @@
 
 void 
 read_revision_set(revision_data const & dat,
-		  revision_set & rev)
+                  revision_set & rev)
 {
   data unpacked;
   unpack(dat.inner(), unpacked);
@@ -657,7 +667,7 @@
 
 void
 write_revision_set(revision_set const & rev,
-		   data & dat)
+                   data & dat)
 {
   std::ostringstream oss;
   basic_io::printer pr(oss);
@@ -667,7 +677,7 @@
 
 void
 write_revision_set(revision_set const & rev,
-		   revision_data & dat)
+                   revision_data & dat)
 {
   data d;
   write_revision_set(rev, d);
diff -ru monotone-0.15/sanity.cc monotone-0.15-patched/sanity.cc
--- monotone-0.15/sanity.cc	Sun Oct 10 11:17:59 2004
+++ monotone-0.15-patched/sanity.cc	Tue Dec  7 20:32:51 2004
@@ -49,7 +49,7 @@
 	ui.inform("failed to write debugging log to " + filename + "\n");
     }
   else
-    ui.inform("discarding debug log\n");
+    ui.inform(string("discarding debug log\n"));
 }
 
 void 
diff -ru monotone-0.15/tests/t_netsync.at monotone-0.15-patched/tests/t_netsync.at
--- monotone-0.15/tests/t_netsync.at	Sun Oct 10 00:05:00 2004
+++ monotone-0.15-patched/tests/t_netsync.at	Tue Dec  7 20:32:51 2004
@@ -1,40 +1,27 @@
 #  -*- Autoconf -*-
 
 AT_SETUP([exchanging work via netsync])
+AT_KEYWORDS([netsync])
 
 MONOTONE_SETUP
-AT_CHECK(cp test.db test2.db)
-
-AT_DATA(netsync.lua, [
-function get_netsync_read_permitted(collection, identity)
-	return true
-end
-
-function get_netsync_write_permitted(collection, identity)
-	return true
-end
-])
+NETSYNC_SETUP
 
 AT_DATA(testfile, [version 0 of test file
 ])
 AT_CHECK(MONOTONE add testfile, [], [ignore], [ignore])
-AT_CHECK(MONOTONE --branch=testbranch --rcfile=netsync.lua commit blah-blah, [], [ignore], [ignore])
+AT_CHECK(MONOTONE --branch=testbranch commit blah-blah, [], [ignore], [ignore])
 F_VER0=`SHA1(testfile)`
 VER0=`BASE_REVISION`
 
 AT_DATA(testfile, [version 1 of test file
 ])
-AT_CHECK(MONOTONE --rcfile=netsync.lua commit blah-blah, [], [ignore], [ignore])
+AT_CHECK(MONOTONE commit blah-blah, [], [ignore], [ignore])
 F_VER1=`SHA1(testfile)`
 VER1=`BASE_REVISION`
 
-killall -q -KILL monotone
-         MONOTONE --rcfile=netsync.lua               serve 127.0.0.1:5555 testbranch &
-sleep 5
-AT_CHECK(MONOTONE --rcfile=netsync.lua --db=test2.db pull 127.0.0.1:5555 testbranch, [], [ignore], [ignore])
-killall -q -KILL monotone
+RUN_NETSYNC(pull, testbranch)
 
-AT_CHECK(MONOTONE --db=test2.db ls certs $VER0, [], [stdout])
+AT_CHECK(MONOTONE2 ls certs $VER0, [], [stdout])
 AT_CHECK(mv stdout certs, [], [ignore])
 AT_CHECK(grep date certs, [], [ignore])
 AT_CHECK(grep author certs, [], [ignore])
@@ -42,7 +29,7 @@
 AT_CHECK(grep changelog certs, [], [ignore])
 AT_CHECK(grep bad certs, [1], [ignore])
 
-AT_CHECK(MONOTONE --db=test2.db ls certs $VER1, [], [stdout])
+AT_CHECK(MONOTONE2 ls certs $VER1, [], [stdout])
 AT_CHECK(mv stdout certs, [], [ignore])
 AT_CHECK(grep date certs, [], [ignore])
 AT_CHECK(grep author certs, [], [ignore])
@@ -50,25 +37,25 @@
 AT_CHECK(grep changelog certs, [], [ignore])
 AT_CHECK(grep bad certs, [1], [ignore])
 
-AT_CHECK(MONOTONE --db=test2.db cat revision $VER0, [], [stdout])
+AT_CHECK(MONOTONE2 cat revision $VER0, [], [stdout])
 CHK=`SHA1(stdout)`
 AT_CHECK(test $CHK == $VER0)
 
-AT_CHECK(MONOTONE --db=test2.db cat revision $VER1, [], [stdout])
+AT_CHECK(MONOTONE2 cat revision $VER1, [], [stdout])
 CHK=`SHA1(stdout)`
 AT_CHECK(test $CHK == $VER1)
 
-AT_CHECK(MONOTONE --db=test2.db cat file $F_VER0, [], [stdout])
+AT_CHECK(MONOTONE2 cat file $F_VER0, [], [stdout])
 CHK=`SHA1(stdout)`
 AT_CHECK(test $CHK == $F_VER0)
 
-AT_CHECK(MONOTONE --db=test2.db cat file $F_VER1, [], [stdout])
+AT_CHECK(MONOTONE2 cat file $F_VER1, [], [stdout])
 CHK=`SHA1(stdout)`
 AT_CHECK(test $CHK == $F_VER1)
 
 AT_CHECK(MONOTONE db info, [], [stdout])
 INFO1=`SHA1(stdout)`
-AT_CHECK(MONOTONE --db=test2.db db info, [], [stdout])
+AT_CHECK(MONOTONE2 db info, [], [stdout])
 INFO2=`SHA1(stdout)`
 AT_CHECK(test $INFO1 == $INFO2)
 
diff -ru monotone-0.15/testsuite.at monotone-0.15-patched/testsuite.at
--- monotone-0.15/testsuite.at	Thu Oct 28 21:19:07 2004
+++ monotone-0.15-patched/testsuite.at	Tue Dec  7 20:32:51 2004
@@ -110,6 +110,13 @@
 AT_CHECK(rm test_keys)
 ])
 
+# run as CHECK_SAME_STDOUT(command1, command2)
+m4_define([CHECK_SAME_STDOUT], [
+AT_CHECK($1, [], [stdout], [ignore])
+AT_CHECK(mv stdout expout)
+AT_CHECK($2, [], [expout], [ignore])
+])
+
 # run as PROBE_NODE(filename, rsha, fsha)
 m4_define([PROBE_NODE], [ 
 AT_CHECK(rm MT/revision)
@@ -128,6 +135,56 @@
 AT_CHECK(test $PROBE_R_SHA == $1)
 ])
 
+# run as ADD_FILE(filename, data)
+m4_define([ADD_FILE], [
+AT_DATA($1, $2)
+AT_CHECK(MONOTONE add $1, [], [ignore], [ignore])
+])
+
+# run as SET_FILE(filename, data)
+m4_define([SET_FILE], [
+AT_DATA($1, $2)
+])
+
+# run as COMMIT(branch)
+m4_define([COMMIT], [
+AT_CHECK(MONOTONE --branch=$1 commit blah-blah, [], [ignore],
+[ignore])
+])
+
+# netsync helpers
+# NETSYNC_SETUP sets up 2 databases; RUN_NETSYNC netsyncs between
+# them, MONOTONE2 operates on the second one.
+
+m4_define([NETSYNC_SETUP], [
+
+AT_CHECK(cp test.db test2.db)
+AT_DATA(netsync.lua, [
+function get_netsync_read_permitted(collection, identity)
+	return true
+end
+
+function get_netsync_write_permitted(collection, identity)
+	return true
+end
+])
+
+])
+
+m4_define([MONOTONE2], MONOTONE --db=test2.db)
+
+# run as RUN_NETSYNC(push|pull|sync, collection name)
+# It is the second database that is always the client; take this into
+# account when choosing push|pull|sync.
+m4_define([RUN_NETSYNC], [
+killall -q -KILL monotone
+MONOTONE --rcfile=netsync.lua serve 127.0.0.1:5555 $2 &
+sleep 5
+AT_CHECK(MONOTONE2 --rcfile=netsync.lua $1 127.0.0.1:5555 $2, [], [ignore], [ignore])
+killall -q -KILL monotone
+])
+
+
 
 # include all the sub-tests we're going to use
 
@@ -141,6 +198,10 @@
 m4_include(tests/t_fork.at)
 m4_include(tests/t_update.at)
 m4_include(tests/t_merge.at)
+m4_include(tests/t_merge_add.at)
+m4_include(tests/t_related_merge2_data.at)
+m4_include(tests/t_merge2_add.at)
+m4_include(tests/t_merge2_data.at)
 m4_include(tests/t_unidiff2.at)
 m4_include(tests/t_cwork.at)
 m4_include(tests/t_revert.at)
@@ -155,10 +216,13 @@
 m4_include(tests/t_i18n_file.at)
 m4_include(tests/t_fmerge.at)
 m4_include(tests/t_netsync.at)
+m4_include(tests/t_netsync_single.at)
+m4_include(tests/t_netsync_pubkey.at)
+m4_include(tests/t_netsync_repeated.at)
+m4_include(tests/t_netsync_unrelated.at)
 m4_include(tests/t_disapprove.at)
 m4_include(tests/t_testresult.at)
 m4_include(tests/t_singlecvs.at)
-m4_include(tests/t_singlenetsync.at)
 m4_include(tests/t_ls_missing.at)
 m4_include(tests/t_attributes.at)
 m4_include(tests/t_single_char_filenames.at)
@@ -166,3 +230,5 @@
 m4_include(tests/t_movedel.at)
 m4_include(tests/t_remerge.at)
 m4_include(tests/t_update_missing.at)
+m4_include(tests/t_heads.at)
+m4_include(tests/t_heads_discontinuous_branch.at)
diff -ru monotone-0.15/views.sql monotone-0.15-patched/views.sql
--- monotone-0.15/views.sql	Wed Oct 13 20:14:52 2004
+++ monotone-0.15-patched/views.sql	Tue Dec  7 20:32:51 2004
@@ -45,22 +45,25 @@
 	WHERE trust == 1
 	;
 
-CREATE VIEW trusted_parents_in_branch AS
-	SELECT id, value
-	FROM trusted_revision_certs
-	WHERE name = "branch" AND id IN
-		(SELECT parent FROM revision_ancestry)
-	;
+CREATE VIEW trusted_branch_members AS 
+        SELECT id, value FROM trusted_revision_certs
+        WHERE name = "branch"
+        ;
 
-CREATE VIEW trusted_children_in_branch AS
-	SELECT id, value
-	FROM trusted_revision_certs
-	WHERE name = "branch" AND id IN
-		(SELECT child FROM revision_ancestry)
-	;
+-- (id, value) in this table means that id is the parent of some child
+-- that is in branch 'value'.  It does not mean anything about the
+-- branch that 'id' is in!
+CREATE VIEW trusted_branch_parents AS
+        SELECT parent, value FROM trusted_branch_members, revision_ancestry
+        WHERE child = id
+        ;
 
+-- Because sqlite 2 does not support naming the columns in a view,
+-- this view has columns (parent, value).  This is confusing and
+-- should be fixed when sqlite starts supporting 'CREATE VIEW name (columns)'
+-- syntax.
 CREATE VIEW branch_heads AS
-	SELECT id, value FROM trusted_children_in_branch
-	EXCEPT
-	SELECT id, value FROM trusted_parents_in_branch
-	;
+        SELECT id, value FROM trusted_branch_members
+        EXCEPT
+        SELECT parent, value FROM trusted_branch_parents
+        ;
