diff -u -Naur gnupg-1.3.4/aclocal.m4 gnupg-1.3.4.fink/aclocal.m4
--- gnupg-1.3.4/aclocal.m4	Thu Aug 21 15:49:09 2003
+++ gnupg-1.3.4.fink/aclocal.m4	Fri Aug 22 15:27:10 2003
@@ -521,7 +521,7 @@
 aix*)
   ac_symcode='[BCDTU]'
   ;;
-freebsd* | netbsd* | openbsd* | bsdi* | sunos* | cygwin32* | mingw32*)
+freebsd* | netbsd* | openbsd* | bsdi* | sunos* | cygwin32* | mingw32* | darwin*)
   ac_sympat='_\([_A-Za-z][_A-Za-z0-9]*\)'
   ac_symxfrm='_\1 \1'
   ;;
diff -u -Naur gnupg-1.3.4/configure gnupg-1.3.4.fink/configure
--- gnupg-1.3.4/configure	Thu Aug 21 15:50:00 2003
+++ gnupg-1.3.4.fink/configure	Fri Aug 22 15:27:10 2003
@@ -4424,6 +4424,9 @@
             CFLAGS="$CFLAGS -Ae -D_HPUX_SOURCE"
         fi
         ;;
+    *-darwin*)
+        CFLAGS="$CFLAGS -no-cpp-precomp"
+        ;;
     *-dec-osf4*)
         if test -z "$GCC" ; then
             # Suppress all warnings
@@ -4524,7 +4527,7 @@
 aix*)
   ac_symcode='[BCDTU]'
   ;;
-freebsd* | netbsd* | openbsd* | bsdi* | sunos* | cygwin32* | mingw32*)
+freebsd* | netbsd* | openbsd* | bsdi* | sunos* | cygwin32* | mingw32* | darwin*)
   ac_sympat='_\([_A-Za-z][_A-Za-z0-9]*\)'
   ac_symxfrm='_\1 \1'
   ;;
@@ -4677,7 +4680,7 @@
 
 tmp_do_check="no"
 case "${target}" in
-    i386-emx-os2 | i345686-pc-os2*emx | i386-pc-msdosdjgpp)
+    i386-emx-os2 | i345686-pc-os2*emx | i386-pc-msdosdjgpp | powerpc-apple-darwin*)
         ac_cv_sys_symbol_underscore=yes
         ;;
     *)
@@ -14539,7 +14542,7 @@
          if test "$gnupg_cv_have_broken_mlock" = "yes"; then
 
 cat >>confdefs.h <<\_ACEOF
-#define HAVE_BROKEN_MLOCK 1
+#define HAVE_BROKEN_MLOCK 0
 _ACEOF
 
              echo "$as_me:$LINENO: result: yes" >&5
diff -u -Naur gnupg-1.3.4/mpi/config.links gnupg-1.3.4.fink/mpi/config.links
--- gnupg-1.3.4/mpi/config.links	Thu Apr 24 07:15:58 2003
+++ gnupg-1.3.4.fink/mpi/config.links	Fri Aug 22 15:27:10 2003
@@ -221,6 +221,15 @@
 	path="powerpc32"
 	;;
 
+    powerpc-apple-darwin*)
+       echo '/* configured Darwin on powerpc */' >>./mpi/asm-syntax.h
+       echo '#define NEXT_SYNTAX'                 >>./mpi/asm-syntax.h
+       echo '#define USE_PPC_PATCHES'            >>./mpi/asm-syntax.h
+       cat   $srcdir/mpi/powerpc32/syntax.h	 >>./mpi/asm-syntax.h
+       mpi_sflags="-Wa,-mppc"
+       path="powerpc32"
+       ;;
+
     powerpc*-*-netbsd* | powerpc*-*-openbsd*)
        echo '/* configured for {Open,Net}BSD on powerpc */' >>./mpi/asm-syntax.h
        echo '#define ELF_SYNTAX'                 >>./mpi/asm-syntax.h
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-add1.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-add1.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-add1.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-add1.S	Fri Aug 22 15:27:10 2003
@@ -95,41 +95,41 @@
 
 EALIGN(mpihelp_add_n,3,0)
 /* Set up for loop below.  */
-       mtcrf 0x01,%r6
-       srwi. %r7,%r6,1
-       li    %r10,0
-       mtctr %r7
+       mtcrf 0x01,R(r6)
+       srwi. R(r7),R(r6),1
+       li    R(r10),0
+       mtctr R(r7)
        bt    31,2f
 
 /* Clear the carry.  */
-       addic %r0,%r0,0
+       addic R(r0),R(r0),0
 /* Adjust pointers for loop.  */
-       addi  %r3,%r3,-4
-       addi  %r4,%r4,-4
-       addi  %r5,%r5,-4
+       addi  R(r3),R(r3),-4
+       addi  R(r4),R(r4),-4
+       addi  R(r5),R(r5),-4
        b     0f
 
-2:     lwz  %r7,0(%r5)
-       lwz  %r6,0(%r4)
-       addc %r6,%r6,%r7
-       stw  %r6,0(%r3)
+2:     lwz  R(r7),0(R(r5))
+       lwz  R(r6),0(R(r4))
+       addc R(r6),R(r6),R(r7)
+       stw  R(r6),0(R(r3))
 	beq  1f
 
 /* The loop.  */
 
 /* Align start of loop to an odd word boundary to guarantee that the
    last two words can be fetched in one access (for 601).  */
-0:     lwz  %r9,4(%r4)
-       lwz  %r8,4(%r5)
-       lwzu %r6,8(%r4)
-       lwzu %r7,8(%r5)
-       adde %r8,%r9,%r8
-       stw  %r8,4(%r3)
-       adde %r6,%r6,%r7
-       stwu %r6,8(%r3)
+0:     lwz  R(r9),4(R(r4))
+       lwz  R(r8),4(R(r5))
+       lwzu R(r6),8(R(r4))
+       lwzu R(r7),8(R(r5))
+       adde R(r8),R(r9),R(r8)
+       stw  R(r8),4(R(r3))
+       adde R(r6),R(r6),R(r7)
+       stwu R(r6),8(R(r3))
        bdnz 0b
 /* Return the carry.  */
-1:     addze %r3,%r10
+1:     addze R(r3),R(r10)
        blr
 END(mpihelp_add_n)
 #endif
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-lshift.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-lshift.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-lshift.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-lshift.S	Fri Aug 22 15:27:10 2003
@@ -97,69 +97,69 @@
 			unsigned int cnt)  */
 
 EALIGN(mpihelp_lshift,3,0)
-       mtctr   %r5	       # copy size into CTR
-       cmplwi  %cr0,%r5,16     # is size < 16
-       slwi    %r0,%r5,2
-       add     %r7,%r3,%r0     # make r7 point at end of res
-       add     %r4,%r4,%r0     # make r4 point at end of s1
-       lwzu    %r11,-4(%r4)    # load first s1 limb
-       subfic  %r8,%r6,32
-       srw     %r3,%r11,%r8    # compute function return value
-       bge     %cr0,L(big)     # branch if size >= 16
+       mtctr   R(r5)	           /* copy size into CTR */
+       cmplwi  R(cr0),R(r5),16     /* is size < 16 */
+       slwi    R(r0),R(r5),2
+       add     R(r7),R(r3),R(r0)   /* make r7 point at end of res */
+       add     R(r4),R(r4),R(r0)   /* make r4 point at end of s1  */
+       lwzu    R(r11),-4(R(r4))    /* load first s1 limb */
+       subfic  R(r8),R(r6),32
+       srw     R(r3),R(r11),R(r8)  /* compute function return value */
+       bge     R(cr0),L(big)       /* branch if size >= 16 */
 
        bdz     L(end1)
 
-0:     lwzu    %r10,-4(%r4)
-       slw     %r9,%r11,%r6
-       srw     %r12,%r10,%r8
-       or      %r9,%r9,%r12
-       stwu    %r9,-4(%r7)
+0:     lwzu    R(r10),-4(R(r4))
+       slw     R(r9),R(r11),R(r6)
+       srw     R(r12),R(r10),R(r8)
+       or      R(r9),R(r9),R(r12)
+       stwu    R(r9),-4(R(r7))
        bdz     L(end2)
-       lwzu    %r11,-4(%r4)
-       slw     %r9,%r10,%r6
-       srw     %r12,%r11,%r8
-       or      %r9,%r9,%r12
-       stwu    %r9,-4(%r7)
+       lwzu    R(r11),-4(R(r4))
+       slw     R(r9),R(r10),R(r6)
+       srw     R(r12),R(r11),R(r8)
+       or      R(r9),R(r9),R(r12)
+       stwu    R(r9),-4(R(r7))
        bdnz    0b
 
-L(end1):slw    %r0,%r11,%r6
-       stw     %r0,-4(%r7)
+L(end1):slw    R(r0),R(r11),R(r6)
+       stw     R(r0),-4(R(r7))
        blr
 
 
 /* Guaranteed not to succeed.  */
-L(boom): tweq	 %r0,%r0
+L(boom): tweq	 R(r0),R(r0)
 
 /* We imitate a case statement, by using (yuk!) fixed-length code chunks,
    of size 4*12 bytes.	We have to do this (or something) to make this PIC.  */
-L(big):        mflr    %r9
-       bltl-   %cr0,L(boom)    # Never taken, only used to set LR.
-       slwi    %r10,%r6,4
-       mflr    %r12
-       add     %r10,%r12,%r10
-       slwi    %r8,%r6,5
-       add     %r10,%r8,%r10
-       mtctr   %r10
-       addi    %r5,%r5,-1
-       mtlr    %r9
+L(big):        mflr    R(r9)
+       bltl-   R(cr0),L(boom)    /* Never taken, only used to set LR. */
+       slwi    R(r10),R(r6),4
+       mflr    R(r12)
+       add     R(r10),R(r12),R(r10)
+       slwi    R(r8),R(r6),5
+       add     R(r10),R(r8),R(r10)
+       mtctr   R(r10)
+       addi    R(r5),R(r5),-1
+       mtlr    R(r9)
        bctr
 
-L(end2):slw    %r0,%r10,%r6
-       stw     %r0,-4(%r7)
+L(end2):slw    R(r0),R(r10),R(r6)
+       stw     R(r0),-4(R(r7))
        blr
 
 #define DO_LSHIFT(n) \
-       mtctr   %r5;						       \
-0:     lwzu    %r10,-4(%r4);					       \
-       slwi    %r9,%r11,n;					       \
-       inslwi  %r9,%r10,n,32-n; 				       \
-       stwu    %r9,-4(%r7);					       \
-       bdz-    L(end2); 					       \
-       lwzu    %r11,-4(%r4);					       \
-       slwi    %r9,%r10,n;					       \
-       inslwi  %r9,%r11,n,32-n; 				       \
-       stwu    %r9,-4(%r7);					       \
-       bdnz    0b;						       \
+       mtctr   R(r5)                 NEW_LINE \
+0:     lwzu    R(r10),-4(R(r4))      NEW_LINE \
+       slwi    R(r9),R(r11),n        NEW_LINE \
+       inslwi  R(r9),R(r10),n,(32-n) NEW_LINE \
+       stwu    R(r9),-4(R(r7))       NEW_LINE \
+       bdz-    L(end2)               NEW_LINE \
+       lwzu    R(r11),-4(R(r4))      NEW_LINE \
+       slwi    R(r9),R(r10),n        NEW_LINE \
+       inslwi  R(r9),R(r11),n,(32-n) NEW_LINE \
+       stwu    R(r9),-4(R(r7))       NEW_LINE \
+       bdnz    0b                    NEW_LINE \
        b       L(end1)
 
        DO_LSHIFT(1)
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-mul1.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-mul1.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-mul1.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-mul1.S	Fri Aug 22 15:27:10 2003
@@ -41,8 +41,8 @@
  * The code trivially generalizes to 64 bit limbs for the PC620.
  */
 
-	.toc
-	.csect .mpihelp_mul_1[PR]
+	/* .toc
+	.csect .mpihelp_mul_1[PR] */
 	.align 2
 	.globl mpihelp_mul_1
 	.globl .mpihelp_mul_1
@@ -97,24 +97,24 @@
    Calculate s1*s2 and put result in res_ptr; return carry.  */
 
 ENTRY(mpihelp_mul_1)
-       mtctr   %r5
+       mtctr   R(r5)
 
-       lwz     %r0,0(%r4)
-       mullw   %r7,%r0,%r6
-       mulhwu  %r10,%r0,%r6
-       addi    %r3,%r3,-4	       # adjust res_ptr
-       addic   %r5,%r5,0	       # clear cy with dummy insn
+       lwz     R(r0),0(R(r4))
+       mullw   R(r7),R(r0),R(r6)
+       mulhwu  R(r10),R(r0),R(r6)
+       addi    R(r3),R(r3),-4	       /* adjust res_ptr */
+       addic   R(r5),R(r5),0	       /* clear cy with dummy insn */
        bdz     1f
 
-0:     lwzu    %r0,4(%r4)
-       stwu    %r7,4(%r3)
-       mullw   %r8,%r0,%r6
-       adde    %r7,%r8,%r10
-       mulhwu  %r10,%r0,%r6
+0:     lwzu    R(r0),4(R(r4))
+       stwu    R(r7),4(R(r3))
+       mullw   R(r8),R(r0),R(r6)
+       adde    R(r7),R(r8),R(r10)
+       mulhwu  R(r10),R(r0),R(r6)
        bdnz    0b
 
-1:     stw     %r7,4(%r3)
-       addze   %r3,%r10
+1:     stw     R(r7),4(R(r3))
+       addze   R(r3),R(r10)
        blr
 END(mpihelp_mul_1)
 #endif
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-mul2.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-mul2.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-mul2.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-mul2.S	Fri Aug 22 15:27:10 2003
@@ -100,28 +100,28 @@
 			   mp_size_t s1_size, mp_limb_t s2_limb)
    Calculate res+s1*s2 and put result back in res; return carry.  */
 ENTRY(mpihelp_addmul_1)
-       mtctr   %r5
+       mtctr   R(r5)
 
-       lwz     %r0,0(%r4)
-       mullw   %r7,%r0,%r6
-       mulhwu  %r10,%r0,%r6
-       lwz     %r9,0(%r3)
-       addc    %r8,%r7,%r9
-       addi    %r3,%r3,-4	       /* adjust res_ptr */
+       lwz     R(r0),0(R(r4))
+       mullw   R(r7),R(r0),R(r6)
+       mulhwu  R(r10),R(r0),R(r6)
+       lwz     R(r9),0(R(r3))
+       addc    R(r8),R(r7),R(r9)
+       addi    R(r3),R(r3),-4	       /* adjust res_ptr */
        bdz     1f
 
-0:     lwzu    %r0,4(%r4)
-       stwu    %r8,4(%r3)
-       mullw   %r8,%r0,%r6
-       adde    %r7,%r8,%r10
-       mulhwu  %r10,%r0,%r6
-       lwz     %r9,4(%r3)
-       addze   %r10,%r10
-       addc    %r8,%r7,%r9
+0:     lwzu    R(r0),4(R(r4))
+       stwu    R(r8),4(R(r3))
+       mullw   R(r8),R(r0),R(r6)
+       adde    R(r7),R(r8),R(r10)
+       mulhwu  R(r10),R(r0),R(r6)
+       lwz     R(r9),4(R(r3))
+       addze   R(r10),R(r10)
+       addc    R(r8),R(r7),R(r9)
        bdnz    0b
 
-1:     stw     %r8,4(%r3)
-       addze   %r3,%r10
+1:     stw     R(r8),4(R(r3))
+       addze   R(r3),R(r10)
        blr
 END(mpihelp_addmul_1)
 #endif
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-mul3.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-mul3.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-mul3.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-mul3.S	Fri Aug 22 15:27:10 2003
@@ -101,30 +101,30 @@
    Calculate res-s1*s2 and put result back in res; return carry.  */
 
 ENTRY(mpihelp_submul_1)
-       mtctr   %r5
+       mtctr   R(r5)
 
-       lwz     %r0,0(%r4)
-       mullw   %r7,%r0,%r6
-       mulhwu  %r10,%r0,%r6
-       lwz     %r9,0(%r3)
-       subf    %r8,%r7,%r9
-       addc    %r7,%r7,%r8	       # invert cy (r7 is junk)
-       addi    %r3,%r3,-4	       # adjust res_ptr
+       lwz     R(r0),0(R(r4))
+       mullw   R(r7),R(r0),R(r6)
+       mulhwu  R(r10),R(r0),R(r6)
+       lwz     R(r9),0(R(r3))
+       subf    R(r8),R(r7),R(r9)
+       addc    R(r7),R(r7),R(r8)       /* invert cy (r7 is junk) */
+       addi    R(r3),R(r3),-4	       /* adjust res_ptr         */
        bdz     1f
 
-0:     lwzu    %r0,4(%r4)
-       stwu    %r8,4(%r3)
-       mullw   %r8,%r0,%r6
-       adde    %r7,%r8,%r10
-       mulhwu  %r10,%r0,%r6
-       lwz     %r9,4(%r3)
-       addze   %r10,%r10
-       subf    %r8,%r7,%r9
-       addc    %r7,%r7,%r8	       # invert cy (r7 is junk)
+0:     lwzu    R(r0),4(R(r4))
+       stwu    R(r8),4(R(r3))
+       mullw   R(r8),R(r0),R(r6)
+       adde    R(r7),R(r8),R(r10)
+       mulhwu  R(r10),R(r0),R(r6)
+       lwz     R(r9),4(R(r3))
+       addze   R(r10),R(r10)
+       subf    R(r8),R(r7),R(r9)
+       addc    R(r7),R(r7),R(r8)	 /* invert cy (r7 is junk) */
        bdnz    0b
 
-1:     stw     %r8,4(%r3)
-       addze   %r3,%r10
+1:     stw     R(r8),4(R(r3))
+       addze   R(r3),R(r10)
        blr
 END(mpihelp_submul_1)
 #endif
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-rshift.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-rshift.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-rshift.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-rshift.S	Fri Aug 22 15:27:10 2003
@@ -100,32 +100,32 @@
    cnt	       r6  */
 
 ENTRY(mpihelp_rshift)
-       mtctr   5	       # copy size into CTR
-       addi    7,3,-4	       # move adjusted res_ptr to free return reg
-       subfic  8,6,32
-       lwz     11,0(4)	       # load first s1 limb
-       slw     3,11,8	       # compute function return value
+       mtctr   R(r5)	       /* copy size into CTR */
+       addi    R(r7),R(r3),-4	       /* move adjusted res_ptr to free return reg */
+       subfic  R(r8),R(r6),32
+       lwz     R(r11),0(R(r4))	       /* load first s1 limb */
+       slw     R(r3),R(r11),R(r8)	       /* compute function return value */
        bdz     1f
 
-0:     lwzu    10,4(4)
-       srw     9,11,6
-       slw     12,10,8
-       or      9,9,12
-       stwu    9,4(7)
+0:     lwzu    R(r10),4(R(r4))
+       srw     R(r9),R(r11),R(r6)
+       slw     R(r12),R(r10),R(r8)
+       or      R(r9),R(r9),R(r12)
+       stwu    R(r9),4(R(r7))
        bdz     2f
-       lwzu    11,4(4)
-       srw     9,10,6
-       slw     12,11,8
-       or      9,9,12
-       stwu    9,4(7)
+       lwzu    R(r11),4(R(r4))
+       srw     R(r9),R(r10),R(r6)
+       slw     R(r12),R(r11),R(r8)
+       or      R(r9),R(r9),R(r12)
+       stwu    R(r9),4(R(r7))
        bdnz    0b
 
-1:     srw     0,11,6
-       stw     0,4(7)
+1:     srw     R(r0),R(r11),R(r6)
+       stw     R(r0),4(R(r7))
        blr
 
-2:     srw     0,10,6
-       stw     0,4(7)
+2:     srw     R(r0),R(r10),R(r6)
+       stw     R(r0),4(R(r7))
        blr
 END(mpihelp_rshift)
 #endif
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/mpih-sub1.S gnupg-1.3.4.fink/mpi/powerpc32/mpih-sub1.S
--- gnupg-1.3.4/mpi/powerpc32/mpih-sub1.S	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/mpih-sub1.S	Fri Aug 22 15:27:10 2003
@@ -92,41 +92,41 @@
 
 EALIGN(mpihelp_sub_n,3,1)
 /* Set up for loop below.  */
-       mtcrf 0x01,%r6
-       srwi. %r7,%r6,1
-       mtctr %r7
+       mtcrf 0x01,R(r6)
+       srwi. R(r7),R(r6),1
+       mtctr R(r7)
        bt    31,2f
 
 /* Set the carry (clear the borrow).  */
-       subfc %r0,%r0,%r0
+       subfc R(r0),R(r0),R(r0)
 /* Adjust pointers for loop.  */
-       addi  %r3,%r3,-4
-       addi  %r4,%r4,-4
-       addi  %r5,%r5,-4
+       addi  R(r3),R(r3),-4
+       addi  R(r4),R(r4),-4
+       addi  R(r5),R(r5),-4
        b     0f
 
-2:     lwz   %r7,0(%r5)
-       lwz   %r6,0(%r4)
-       subfc %r6,%r7,%r6
-       stw   %r6,0(%r3)
+2:     lwz   R(r7),0(R(r5))
+       lwz   R(r6),0(R(r4))
+       subfc R(r6),R(r7),R(r6)
+       stw   R(r6),0(R(r3))
 	beq   1f
 
 /* Align start of loop to an odd word boundary to guarantee that the
    last two words can be fetched in one access (for 601).  This turns
    out to be important.  */
 0:
-       lwz   %r9,4(%r4)
-       lwz   %r8,4(%r5)
-       lwzu  %r6,8(%r4)
-       lwzu  %r7,8(%r5)
-       subfe %r8,%r8,%r9
-       stw   %r8,4(%r3)
-       subfe %r6,%r7,%r6
-       stwu  %r6,8(%r3)
+       lwz   R(r9),4(R(r4))
+       lwz   R(r8),4(R(r5))
+       lwzu  R(r6),8(R(r4))
+       lwzu  R(r7),8(R(r5))
+       subfe R(r8),R(r8),R(r9)
+       stw   R(r8),4(R(r3))
+       subfe R(r6),R(r7),R(r6)
+       stwu  R(r6),8(R(r3))
        bdnz  0b
 /* Return the borrow. */
-1:     subfe %r3,%r3,%r3
-       neg   %r3,%r3
+1:     subfe R(r3),R(r3),R(r3)
+       neg   R(r3),R(r3)
        blr
 END(mpihelp_sub_n)
 #endif
diff -u -Naur gnupg-1.3.4/mpi/powerpc32/syntax.h gnupg-1.3.4.fink/mpi/powerpc32/syntax.h
--- gnupg-1.3.4/mpi/powerpc32/syntax.h	Sat Jun 29 10:14:10 2002
+++ gnupg-1.3.4.fink/mpi/powerpc32/syntax.h	Fri Aug 22 15:27:10 2003
@@ -20,12 +20,27 @@
    Boston, MA 02111-1307, USA.	*/
 
 
-#define USE_PPC_PATCHES 1
+/* Define the syntax for specifying a CPU register */
+#if defined(BSD_SYNTAX) || defined(ELF_SYNTAX)
+#ifdef __STDC__
+# define R(reg) %##reg
+#else
+# define R(reg) %/**/reg
+#endif
+#elif defined(NEXT_SYNTAX)
+# define R(reg) reg
+#endif
 
 /* This seems to always be the case on PPC.  */
 #define ALIGNARG(log2) log2
+
 /* For ELF we need the `.type' directive to make shared libs work right.  */
+#if defined(BSD_SYNTAX) || defined(ELF_SYNTAX)
 #define ASM_TYPE_DIRECTIVE(name,typearg) .type name,typearg;
+#elif defined(NEXT_SYNTAX)
+#define ASM_TYPE_DIRECTIVE(name,typearg) 
+#endif
+
 #define ASM_SIZE_DIRECTIVE(name) .size name,.-name
 #define ASM_GLOBAL_DIRECTIVE   .globl
 
@@ -41,35 +56,45 @@
 # define L(body) .L/**/body
 #endif
 
+/* How to begin a new line of assembly */
+#if defined(BSD_SYNTAX) || defined(ELF_SYNTAX)
+#define	NEW_LINE ;
+#elif defined(NEXT_SYNTAX)
+#define NEW_LINE @
+#endif
+
 /* No profiling of gmp's assembly for now... */
 #define CALL_MCOUNT /* no profiling */
 
-#define        ENTRY(name)				    \
-  ASM_GLOBAL_DIRECTIVE C_SYMBOL_NAME(name);		    \
-  ASM_TYPE_DIRECTIVE (C_SYMBOL_NAME(name),@function)	    \
-  .align ALIGNARG(2);					    \
-  C_LABEL(name) 					    \
+#define        ENTRY(name)                                    \
+  ASM_GLOBAL_DIRECTIVE C_SYMBOL_NAME(name) NEW_LINE           \
+  ASM_TYPE_DIRECTIVE (C_SYMBOL_NAME(name),@function) NEW_LINE \
+  .align ALIGNARG(2) NEW_LINE                                 \
+  C_LABEL(name)                                               \
   CALL_MCOUNT
 
 #define EALIGN_W_0  /* No words to insert.  */
 #define EALIGN_W_1  nop
-#define EALIGN_W_2  nop;nop
-#define EALIGN_W_3  nop;nop;nop
-#define EALIGN_W_4  EALIGN_W_3;nop
-#define EALIGN_W_5  EALIGN_W_4;nop
-#define EALIGN_W_6  EALIGN_W_5;nop
-#define EALIGN_W_7  EALIGN_W_6;nop
+#define EALIGN_W_2  nop NEW_LINE nop
+#define EALIGN_W_3  nop NEW_LINE nop NEW_LINE nop
+#define EALIGN_W_4  EALIGN_W_3 NEW_LINE nop
+#define EALIGN_W_5  EALIGN_W_4 NEW_LINE nop
+#define EALIGN_W_6  EALIGN_W_5 NEW_LINE nop
+#define EALIGN_W_7  EALIGN_W_6 NEW_LINE nop
 
 /* EALIGN is like ENTRY, but does alignment to 'words'*4 bytes
    past a 2^align boundary.  */
-#define EALIGN(name, alignt, words)			\
-  ASM_GLOBAL_DIRECTIVE C_SYMBOL_NAME(name);		\
-  ASM_TYPE_DIRECTIVE (C_SYMBOL_NAME(name),@function)	\
-  .align ALIGNARG(alignt);				\
-  EALIGN_W_##words;					\
+#define EALIGN(name, alignt, words)                     \
+  ASM_GLOBAL_DIRECTIVE C_SYMBOL_NAME(name) NEW_LINE     \
+  ASM_TYPE_DIRECTIVE (C_SYMBOL_NAME(name),@function)    \
+  .align ALIGNARG(alignt) NEW_LINE                      \
+  EALIGN_W_##words NEW_LINE                             \
   C_LABEL(name)
 
 #undef END
-#define END(name)		     \
-  ASM_SIZE_DIRECTIVE(name)
+#if defined(BSD_SYNTAX) || defined(ELF_SYNTAX)
+#define END(name)	ASM_SIZE_DIRECTIVE(name)
+#elif defined(NEXT_SYNTAX)
+#define END(name)
+#endif
 
